# PS D:\æ¯”èµ›\intel\intel> wmic path win32_videocontroller get name
# Name
# Intel(R) Iris(R) Xe Graphics

# PS D:\æ¯”èµ›\intel\intel> D:\anaconda_download\anaconda3\python.exe -m streamlit run app.py


def create_openai_client_safe(api_key, base_url, timeout=60.0):
    """å®‰å…¨åˆ›å»º OpenAI å®¢æˆ·ç«¯ï¼Œå…¼å®¹ä¸åŒç‰ˆæœ¬çš„ OpenAI åº“"""
    try:
        from openai import OpenAI
        
        # æ£€æŸ¥æ˜¯å¦æ”¯æŒ http_client å‚æ•°
        import inspect
        sig = inspect.signature(OpenAI.__init__)
        supports_http_client = 'http_client' in sig.parameters
        
        if supports_http_client:
            try:
                import httpx
                # å°è¯•ä½¿ç”¨ http_client å‚æ•°ï¼ˆæ–°ç‰ˆæœ¬ï¼‰
                return OpenAI(
                    api_key=api_key,
                    base_url=base_url,
                    http_client=httpx.Client(proxies={}),
                    timeout=timeout
                )
            except Exception:
                # å¦‚æœ httpx æœ‰é—®é¢˜ï¼Œå›é€€åˆ°åŸºç¡€ç‰ˆæœ¬
                pass
        
        # ä½¿ç”¨åŸºç¡€ç‰ˆæœ¬ï¼ˆå…¼å®¹æ—§ç‰ˆæœ¬ï¼‰
        return OpenAI(
            api_key=api_key,
            base_url=base_url,
            timeout=timeout
        )
        
    except ImportError:
        raise ImportError("è¯·å®‰è£… OpenAI åº“: pip install openai>=1.0.0")


import streamlit as st
import pandas as pd
import time
import psutil
import os
import logging
from rag_engine import IntelRAG
from agent_core import Text2SQLAgent
from utils import load_config, save_config, load_history, create_new_session, delete_session, update_session_messages

# é…ç½®æ—¥å¿—è®°å½•
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')
from visualization_engine import viz_engine
from recommendation_engine import recommendation_engine
from export_manager import export_manager
from performance_monitor import performance_monitor
from data_filter import data_filter
from anomaly_detector import anomaly_detector
from chart_key_utils import generate_sidebar_chart_key, generate_history_chart_key, generate_query_chart_key, create_chart_with_key

# é€šç”¨ç¡¬ä»¶ä¼˜åŒ–ç³»ç»Ÿé›†æˆ
try:
    from universal_hardware_optimizer import (
        get_optimization_status, 
        optimize_query_performance, 
        universal_optimizer,
        HardwareVendor
    )
    HARDWARE_OPTIMIZATION_AVAILABLE = True
    hw_status = get_optimization_status()
    if hw_status['enabled']:
        vendor = hw_status.get('vendor', 'Unknown')
        print(f"âœ… {vendor}ç¡¬ä»¶ä¼˜åŒ–ç³»ç»Ÿå·²åŠ è½½")
    else:
        print("âš ï¸ ç¡¬ä»¶ä¼˜åŒ–ç³»ç»Ÿä¸å¯ç”¨")
except ImportError as e:
    HARDWARE_OPTIMIZATION_AVAILABLE = False
    print(f"âš ï¸ ç¡¬ä»¶ä¼˜åŒ–ç³»ç»Ÿä¸å¯ç”¨: {e}")

# ğŸ§  Promptæ¨¡æ¿ç³»ç»Ÿé›†æˆ
try:
    from prompt_template_system import PromptTemplateManager, PromptMode, LLMProvider
    from prompt_config_ui import PromptConfigUI
    from prompt_integration import EnhancedPromptBuilder
    PROMPT_TEMPLATE_AVAILABLE = True
    print("âœ… Promptæ¨¡æ¿ç³»ç»Ÿå·²åŠ è½½")
except ImportError as e:
    PROMPT_TEMPLATE_AVAILABLE = False
    print(f"âš ï¸ Promptæ¨¡æ¿ç³»ç»Ÿä¸å¯ç”¨: {e}")

# ğŸ§  ä¸Šä¸‹æ–‡è®°å¿†ç³»ç»Ÿé›†æˆ
try:
    from context_memory_integration import (
        get_context_integration, 
        integrate_with_messages, 
        update_context_after_response,
        render_context_ui
    )
    CONTEXT_MEMORY_AVAILABLE = True
    print("âœ… ä¸Šä¸‹æ–‡è®°å¿†ç³»ç»Ÿå·²åŠ è½½")
except ImportError as e:
    CONTEXT_MEMORY_AVAILABLE = False
    print(f"âš ï¸ ä¸Šä¸‹æ–‡è®°å¿†ç³»ç»Ÿä¸å¯ç”¨: {e}")

# æŠ€æœ¯å“è¶Šæ€§é›†æˆç³»ç»Ÿ - åç«¯åŠŸèƒ½å¯ç”¨ï¼Œå‰ç«¯UIç¦ç”¨
try:
    from technical_excellence_integration import (
        get_technical_excellence_manager,
        optimize_operation,
        render_technical_excellence_ui,
        get_technical_recommendations
    )
    TECHNICAL_EXCELLENCE_AVAILABLE = True
    tech_manager = get_technical_excellence_manager()
    tech_status = tech_manager.get_technical_status()
    # æŠ€æœ¯å“è¶Šæ€§åç«¯ç³»ç»Ÿå·²åŠ è½½ï¼Œè¯„åˆ†: {tech_status.overall_score:.1f}% ({tech_status.maturity_level})
except ImportError as e:
    TECHNICAL_EXCELLENCE_AVAILABLE = False
    print(f"âš ï¸ æŠ€æœ¯å“è¶Šæ€§ç³»ç»Ÿä¸å¯ç”¨: {e}")

# ç‹¬ç«‹æ§åˆ¶å‰ç«¯UIæ˜¾ç¤º
TECHNICAL_EXCELLENCE_UI_ENABLED = False  # å‰ç«¯UIé¢æ¿ç¦ç”¨

# æ€§èƒ½ä¼˜åŒ–é…ç½®
st.set_page_config(
    page_title="IntelÂ® DeepInsight", 
    layout="wide", 
    page_icon="assets/å›¢é˜ŸLogo.png",
    initial_sidebar_state="expanded",
    menu_items={
        'Get Help': None,
        'Report a bug': None,
        'About': "IntelÂ® DeepInsight - åŸºäºOpenVINOâ„¢çš„æ™ºèƒ½é›¶å”®å†³ç­–ç³»ç»Ÿ"
    }
)

# ç¼“å­˜ä¼˜åŒ– - å¢åŠ TTLå’Œæ›´å¤§çš„ç¼“å­˜
@st.cache_data(ttl=3600, max_entries=50)
def load_cached_data(file_path):
    """ç¼“å­˜æ•°æ®åŠ è½½"""
    if os.path.exists(file_path):
        return pd.read_csv(file_path)
    return None

@st.cache_data(ttl=1800, max_entries=20)
def get_chart_recommendations(df_shape, columns):
    """ç¼“å­˜å›¾è¡¨æ¨è"""
    return viz_engine.get_chart_options_cached(df_shape, columns)

# --- CSS ç¾åŒ–ä¸æ ·å¼å®šä¹‰ (å·²ä¿®å¤æŒ‰é’®é«˜åº¦é—®é¢˜ + ç§»åŠ¨ç«¯ä¼˜åŒ–) ---
st.markdown("""
<style>
    /* å…¨å±€èƒŒæ™¯ */
    .stApp { background-color: #f8f9fa; }
    
    /* ä¸»å†…å®¹åŒºåŸŸä¼˜åŒ– */
    .main .block-container {
        padding-top: 1rem !important;
        max-width: 1200px !important;
    }
    
    /* èŠå¤©æ°”æ³¡ä¼˜åŒ– */
    .stChatMessage { 
        padding: 1.2rem; 
        border-radius: 15px; 
        border: 1px solid #eef0f3; 
        background: white; 
        box-shadow: 0 2px 6px rgba(0,0,0,0.02);
        margin-bottom: 10px;
    }
    
    /* æ ‡é¢˜æ ·å¼å¢å¼º */
    h5 {
        color: #0068B5; 
        font-weight: 600; 
        margin-top: 20px !important; 
        margin-bottom: 10px !important;
        display: flex;
        align-items: center;
    }
    
    /* ä¸Šä¸‹æ–‡è®°å¿†çŠ¶æ€æŒ‡ç¤ºå™¨ */
    .context-status {
        background: linear-gradient(135deg, #e8f5e8 0%, #d4edda 100%);
        padding: 8px 12px;
        border-radius: 8px;
        border-left: 4px solid #28a745;
        margin: 10px 0;
        font-size: 0.85em;
        color: #155724;
    }
    
    .context-disabled {
        background: linear-gradient(135deg, #fff3cd 0%, #ffeaa7 100%);
        border-left-color: #ffc107;
        color: #856404;
    }
    
    /* æ€ç»´é“¾æŒä¹…åŒ–æ ·å¼ - å¢å¼ºç‰ˆ */
    .thought-persist {
        background: linear-gradient(135deg, #f0f7ff 0%, #e8f4fd 100%); 
        padding: 16px 20px; 
        border-radius: 12px; 
        font-family: 'SF Mono', 'Monaco', 'Inconsolata', 'Roboto Mono', monospace; 
        font-size: 0.88em; 
        border-left: 5px solid #0068B5; 
        margin-bottom: 18px;
        color: #2c3e50;
        white-space: pre-wrap;
        line-height: 1.6;
        box-shadow: 0 3px 10px rgba(0,104,181,0.1);
        position: relative;
    }
    
    .thought-persist::before {
        content: "ğŸ§  AIæ€è€ƒè¿‡ç¨‹";
        position: absolute;
        top: -8px;
        left: 15px;
        background: #0068B5;
        color: white;
        padding: 2px 8px;
        border-radius: 4px;
        font-size: 0.7em;
        font-weight: 600;
    }
    
    /* å®æ—¶æ€è€ƒæµæ ·å¼ - å¢å¼ºç‰ˆ */
    .thought-box {
        background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%); 
        padding: 14px 16px; 
        border-radius: 10px; 
        font-family: 'SF Mono', 'Monaco', 'Inconsolata', 'Roboto Mono', monospace; 
        font-size: 0.86em; 
        border-left: 4px solid #6c757d; 
        margin: 12px 0;
        white-space: pre-wrap; 
        color: #495057;
        line-height: 1.5;
        box-shadow: 0 2px 6px rgba(108,117,125,0.1);
        animation: fadeInUp 0.3s ease-out;
    }
    
    @keyframes fadeInUp {
        from { opacity: 0; transform: translateY(10px); }
        to { opacity: 1; transform: translateY(0); }
    }
    
    /* åŠ è½½çŠ¶æ€ä¼˜åŒ– */
    .stStatus > div {
        border-radius: 10px !important;
        box-shadow: 0 4px 12px rgba(0,0,0,0.1) !important;
    }
    
    /* æˆåŠŸåé¦ˆåŠ¨ç”» */
    .success-feedback {
        animation: successPulse 0.6s ease-out;
    }
    
    @keyframes successPulse {
        0% { transform: scale(1); }
        50% { transform: scale(1.05); background-color: #d4edda; }
        100% { transform: scale(1); }
    }
    
    /* æ“ä½œç¡®è®¤æ ·å¼ */
    .confirm-action {
        background: #fff3cd !important;
        border: 2px solid #ffc107 !important;
        border-radius: 8px !important;
        animation: confirmShake 0.5s ease-out;
    }
    
    @keyframes confirmShake {
        0%, 100% { transform: translateX(0); }
        25% { transform: translateX(-2px); }
        75% { transform: translateX(2px); }
    }

    /* ä¾§è¾¹æ ç›‘æ§å¡ç‰‡ */
    .monitor-box {
        background: white; padding: 15px; border-radius: 10px; border: 1px solid #eee;
        font-size: 0.85rem; margin-top: 20px; line-height: 1.8;
        box-shadow: 0 2px 8px rgba(0,0,0,0.05);
    }
    
    .metric-row { display: flex; justify-content: space-between; border-bottom: 1px dashed #eee; padding-bottom: 6px; margin-bottom: 6px; }
    .metric-val { font-weight: bold; font-family: monospace; }
    
    #MainMenu {visibility: hidden;}

    /* ==================================================================== */
    /* ğŸ”¥ã€æ ¸å¿ƒä¿®å¤ã€‘å¼ºåˆ¶ç»Ÿä¸€ç¤ºä¾‹é—®é¢˜æŒ‰é’®çš„é«˜åº¦ä¸æ¢è¡Œ ğŸ”¥ */
    /* ==================================================================== */
    section.main div[data-testid="column"] button {
        height: 100px !important;        /* å¼ºåˆ¶å›ºå®šé«˜åº¦ï¼Œç¡®ä¿æ‰€æœ‰å¡ç‰‡ä¸€æ ·é«˜ */
        min-height: 100px !important;    /* æœ€å°é«˜åº¦ä¿æŠ¤ */
        white-space: normal !important;  /* å¼ºåˆ¶å…è®¸æ–‡å­—æ¢è¡Œ */
        word-wrap: break-word !important; /*é˜²æ­¢é•¿å•è¯æº¢å‡º */
        display: flex !important;
        align-items: center !important;
        justify-content: center !important;
        line-height: 1.4 !important;     /* è°ƒæ•´è¡Œé«˜ï¼Œè®©å¤šè¡Œæ–‡å­—ä¸æ‹¥æŒ¤ */
        padding: 5px 10px !important;    /* å†…éƒ¨è¾¹è· */
    }
    
    /* é¼ æ ‡æ‚¬åœæ—¶çš„å¾®æ•ˆ */
    section.main div[data-testid="column"] button:hover {
        border-color: #0068B5 !important;
        color: #0068B5 !important;
        background-color: #f0f7ff !important;
    }
    
    /* ==================================================================== */
    /* ğŸ“± ç§»åŠ¨ç«¯å“åº”å¼ä¼˜åŒ– - å¢å¼ºç‰ˆ */
    /* ==================================================================== */
    
    /* å¤§å±è®¾å¤‡ (1920px+) */
    @media screen and (min-width: 1920px) {
        .main .block-container {
            max-width: 1400px !important;
        }
    }
    
    /* å¹³æ¿è®¾å¤‡ (768px - 1024px) */
    @media screen and (max-width: 1024px) {
        .stSidebar {
            width: 280px !important;
        }
        
        .main .block-container {
            max-width: 100% !important;
            padding-left: 1.5rem !important;
            padding-right: 1.5rem !important;
        }
        
        .monitor-box {
            font-size: 0.8rem;
            padding: 12px;
        }
        
        section.main div[data-testid="column"] button {
            height: 90px !important;
            min-height: 90px !important;
            font-size: 0.9em !important;
        }
        
        /* å›¾è¡¨å®¹å™¨é€‚é… */
        .js-plotly-plot {
            max-width: 100% !important;
        }
        
        /* è¾“å…¥æ¡†ä¼˜åŒ– */
        .stTextInput input, .stTextArea textarea {
            font-size: 16px !important; /* é˜²æ­¢iOSè‡ªåŠ¨ç¼©æ”¾ */
        }
    }
    
    /* ç§»åŠ¨è®¾å¤‡ (æœ€å¤§å®½åº¦ 768px) */
    @media screen and (max-width: 768px) {
        /* ä¾§è¾¹æ ç§»åŠ¨ç«¯ä¼˜åŒ– */
        .stSidebar {
            width: 85% !important;
            max-width: 320px !important;
            position: fixed !important;
            left: 0 !important;
            top: 0 !important;
            height: 100vh !important;
            z-index: 999999 !important;
            box-shadow: 2px 0 10px rgba(0,0,0,0.3) !important;
            transition: transform 0.3s cubic-bezier(0.4, 0, 0.2, 1) !important;
        }
        
        /* ä¾§è¾¹æ æ”¶èµ·çŠ¶æ€ */
        .stSidebar[aria-expanded="false"] {
            transform: translateX(-100%) !important;
        }
        
        /* ä¾§è¾¹æ å±•å¼€çŠ¶æ€ */
        .stSidebar[aria-expanded="true"] {
            transform: translateX(0) !important;
        }
        
        /* ä¾§è¾¹æ é®ç½©å±‚ */
        .stSidebar::before {
            content: '';
            position: fixed;
            top: 0;
            left: 0;
            width: 100vw;
            height: 100vh;
            background: rgba(0, 0, 0, 0.5);
            z-index: -1;
            opacity: 0;
            transition: opacity 0.3s ease;
            pointer-events: none;
        }
        
        .stSidebar[aria-expanded="true"]::before {
            opacity: 1;
            pointer-events: auto;
        }
        
        /* å±•å¼€æŒ‰é’®ä¼˜åŒ– */
        [data-testid="collapsedControl"] {
            position: fixed !important;
            left: 10px !important;
            top: 10px !important;
            z-index: 999997 !important;
            background: white !important;
            box-shadow: 0 2px 8px rgba(0,0,0,0.15) !important;
            border-radius: 8px !important;
            padding: 10px !important;
            width: 44px !important;
            height: 44px !important;
        }
        
        [data-testid="collapsedControl"]:active {
            transform: scale(0.95) !important;
        }
        
        /* ä¸»å†…å®¹åŒºåŸŸ */
        .main .block-container {
            padding-left: 0.75rem !important;
            padding-right: 0.75rem !important;
            padding-top: 0.5rem !important;
            max-width: 100% !important;
        }
        
        /* ç§»åŠ¨ç«¯æŒ‰é’®ä¼˜åŒ– */
        section.main div[data-testid="column"] button {
            height: 75px !important;
            min-height: 75px !important;
            font-size: 0.85em !important;
            padding: 8px !important;
            margin-bottom: 8px !important;
        }
        
        /* èŠå¤©æ¶ˆæ¯ä¼˜åŒ– */
        .stChatMessage {
            padding: 0.9rem !important;
            margin-bottom: 8px !important;
            border-radius: 12px !important;
        }
        
        /* èŠå¤©è¾“å…¥æ¡†ä¼˜åŒ– */
        .stChatInput {
            position: sticky !important;
            bottom: 0 !important;
            background: white !important;
            padding: 10px 0 !important;
            z-index: 100 !important;
        }
        
        .stChatInput input {
            font-size: 16px !important; /* é˜²æ­¢iOSè‡ªåŠ¨ç¼©æ”¾ */
        }
        
        /* ç›‘æ§é¢æ¿ç§»åŠ¨ç«¯ä¼˜åŒ– */
        .monitor-box {
            font-size: 0.75rem;
            padding: 10px;
            margin-top: 15px;
        }
        
        .metric-row {
            padding-bottom: 4px;
            margin-bottom: 4px;
            font-size: 0.85em;
        }
        
        /* è¡¨æ ¼å“åº”å¼ */
        .dataframe {
            font-size: 0.75em !important;
            overflow-x: auto !important;
            display: block !important;
        }
        
        .dataframe table {
            min-width: 100% !important;
        }
        
        /* å›¾è¡¨å®¹å™¨ä¼˜åŒ– */
        .js-plotly-plot {
            width: 100% !important;
            height: auto !important;
            min-height: 300px !important;
        }
        
        /* æ ‡é¢˜ä¼˜åŒ– */
        h1 {
            font-size: 1.5rem !important;
            line-height: 1.3 !important;
        }
        
        h2 {
            font-size: 1.3rem !important;
        }
        
        h3 {
            font-size: 1.1rem !important;
        }
        
        /* å±•å¼€å™¨ä¼˜åŒ– */
        .streamlit-expanderHeader {
            font-size: 0.9em !important;
            padding: 10px !important;
        }
        
        /* é€‰æ‹©æ¡†ä¼˜åŒ– */
        .stSelectbox, .stMultiSelect {
            font-size: 0.9em !important;
        }
        
        /* æ»‘å—ä¼˜åŒ– */
        .stSlider {
            padding: 10px 0 !important;
        }
    }
    
    /* å°å±æ‰‹æœº (æœ€å¤§å®½åº¦ 480px) */
    @media screen and (max-width: 480px) {
        /* ä¸»å†…å®¹åŒºåŸŸ */
        .main .block-container {
            padding-left: 0.5rem !important;
            padding-right: 0.5rem !important;
            padding-top: 0.25rem !important;
        }
        
        /* è¶…å°å±æŒ‰é’® */
        section.main div[data-testid="column"] button {
            height: 65px !important;
            min-height: 65px !important;
            font-size: 0.8em !important;
            padding: 6px !important;
            margin-bottom: 6px !important;
        }
        
        /* åˆ—å¸ƒå±€ä¼˜åŒ– - å¼ºåˆ¶å•åˆ— */
        .row-widget.stColumns {
            flex-direction: column !important;
            gap: 0 !important;
        }
        
        .row-widget.stColumns > div {
            width: 100% !important;
            margin-bottom: 8px !important;
            padding: 0 !important;
        }
        
        /* æ ‡é¢˜å­—ä½“ç¼©å° */
        h1 {
            font-size: 1.3rem !important;
            margin-bottom: 0.5rem !important;
        }
        
        h2 {
            font-size: 1.15rem !important;
        }
        
        h3, h4, h5 {
            font-size: 1rem !important;
        }
        
        /* æ€ç»´é“¾æ ·å¼ç§»åŠ¨ç«¯ä¼˜åŒ– */
        .thought-persist, .thought-box {
            font-size: 0.7em !important;
            padding: 8px 10px !important;
            margin: 8px 0 !important;
            line-height: 1.4 !important;
        }
        
        .thought-persist::before {
            font-size: 0.65em !important;
            padding: 1px 6px !important;
        }
        
        /* èŠå¤©æ¶ˆæ¯ç´§å‡‘åŒ– */
        .stChatMessage {
            padding: 0.75rem !important;
            margin-bottom: 6px !important;
        }
        
        /* ç›‘æ§å¡ç‰‡ç´§å‡‘åŒ– */
        .monitor-box {
            font-size: 0.7rem;
            padding: 8px;
            margin-top: 10px;
        }
        
        /* å›¾è¡¨é«˜åº¦è°ƒæ•´ */
        .js-plotly-plot {
            min-height: 250px !important;
        }
        
        /* è¾“å…¥æ¡†å­—ä½“å¤§å° */
        input, textarea, select {
            font-size: 16px !important; /* é˜²æ­¢iOSè‡ªåŠ¨ç¼©æ”¾ */
        }
        
        /* æŒ‰é’®æ–‡å­—å¤§å° */
        button {
            font-size: 0.85em !important;
        }
        
        /* ä¾§è¾¹æ å®½åº¦ */
        .stSidebar {
            width: 90% !important;
            max-width: 280px !important;
        }
    }
    
    /* è¶…å°å±æ‰‹æœº (æœ€å¤§å®½åº¦ 360px) */
    @media screen and (max-width: 360px) {
        .main .block-container {
            padding-left: 0.25rem !important;
            padding-right: 0.25rem !important;
        }
        
        section.main div[data-testid="column"] button {
            height: 60px !important;
            min-height: 60px !important;
            font-size: 0.75em !important;
        }
        
        h1 {
            font-size: 1.2rem !important;
        }
        
        .stChatMessage {
            padding: 0.6rem !important;
        }
        
        .thought-persist, .thought-box {
            font-size: 0.65em !important;
            padding: 6px 8px !important;
        }
    }
    
    /* è§¦æ‘¸è®¾å¤‡ä¼˜åŒ– */
    @media (hover: none) and (pointer: coarse) {
        /* å¢å¤§è§¦æ‘¸ç›®æ ‡ */
        button, .stSelectbox, .stTextInput, a {
            min-height: 44px !important;
            min-width: 44px !important;
        }
        
        /* è§¦æ‘¸åé¦ˆ */
        button:active {
            transform: scale(0.96);
            transition: transform 0.1s ease;
            background-color: rgba(0, 104, 181, 0.1) !important;
        }
        
        /* æ»šåŠ¨ä¼˜åŒ– */
        .main, .stSidebar {
            -webkit-overflow-scrolling: touch;
            overflow-y: auto;
        }
        
        /* ç¦ç”¨æ‚¬åœæ•ˆæœ */
        button:hover {
            transform: none !important;
        }
        
        /* é“¾æ¥è§¦æ‘¸ä¼˜åŒ– */
        a {
            padding: 8px !important;
            display: inline-block !important;
        }
    }
    
    /* æ¨ªå±æ¨¡å¼ä¼˜åŒ– */
    @media screen and (max-height: 500px) and (orientation: landscape) {
        .stSidebar {
            width: 250px !important;
        }
        
        .main .block-container {
            padding-top: 0.5rem !important;
        }
        
        section.main div[data-testid="column"] button {
            height: 55px !important;
            min-height: 55px !important;
        }
        
        .monitor-box {
            padding: 6px;
            font-size: 0.7rem;
            margin-top: 8px;
        }
        
        .stChatMessage {
            padding: 0.6rem !important;
        }
        
        /* ç´§å‡‘åŒ–é—´è· */
        h1, h2, h3, h4, h5 {
            margin-top: 0.5rem !important;
            margin-bottom: 0.5rem !important;
        }
    }
    
    /* æš—è‰²æ¨¡å¼æ”¯æŒ (å¯é€‰) */
    @media (prefers-color-scheme: dark) {
        .stApp {
            background-color: #1a1a1a !important;
        }
        
        .stChatMessage {
            background: #2d2d2d !important;
            border-color: #404040 !important;
            color: #e0e0e0 !important;
        }
        
        .monitor-box {
            background: #2d2d2d !important;
            border-color: #404040 !important;
            color: #e0e0e0 !important;
        }
    }
    
    /* æ‰“å°æ ·å¼ä¼˜åŒ– */
    @media print {
        .stSidebar {
            display: none !important;
        }
        
        .main .block-container {
            max-width: 100% !important;
            padding: 0 !important;
        }
        
        button {
            display: none !important;
        }
        
        .stChatMessage {
            page-break-inside: avoid !important;
        }
    }
    }

    /* ==================================================================== */
    /* âŒ¨ï¸ é”®ç›˜å¿«æ·é”®æ”¯æŒ */
    /* ==================================================================== */
    
    /* å¿«æ·é”®æç¤º */
    .keyboard-hint {
        position: fixed;
        bottom: 20px;
        right: 20px;
        background: rgba(0,0,0,0.8);
        color: white;
        padding: 8px 12px;
        border-radius: 6px;
        font-size: 0.75em;
        z-index: 1000;
        opacity: 0;
        transition: opacity 0.3s ease;
    }
    
    .keyboard-hint.show {
        opacity: 1;
    }
    
    /* èšç„¦è¾“å…¥æ¡†æ ·å¼ */
    .stChatInput input:focus {
        border-color: #0068B5 !important;
        box-shadow: 0 0 0 2px rgba(0,104,181,0.2) !important;
    }
    
    /* æŒ‰é’®èšç„¦æ ·å¼ */
    button:focus {
        outline: 2px solid #0068B5 !important;
        outline-offset: 2px !important;
    }
    
    /* ==================================================================== */
    /* ğŸ¯ äº¤äº’åé¦ˆå¢å¼º */
    /* ==================================================================== */
    
    /* æŒ‰é’®ç‚¹å‡»åé¦ˆ */
    button:active {
        transform: scale(0.98);
        transition: transform 0.1s ease;
    }
    
    /* æ‚¬åœæ•ˆæœå¢å¼º */
    button:hover {
        transform: translateY(-1px);
        box-shadow: 0 4px 8px rgba(0,0,0,0.15) !important;
        transition: all 0.2s ease;
    }
    
    /* æ•°æ®è¡¨æ ¼äº¤äº’å¢å¼º */
    .dataframe tbody tr:hover {
        background-color: #f8f9fa !important;
        transform: scale(1.01);
        transition: all 0.2s ease;
    }
    
    /* å±•å¼€å™¨åŠ¨ç”» */
    .streamlit-expanderHeader {
        transition: all 0.3s ease !important;
    }
    
    .streamlit-expanderHeader:hover {
        background-color: #f0f7ff !important;
    }
    
    /* è¿›åº¦æ¡ç¾åŒ– */
    .stProgress > div > div {
        background: linear-gradient(90deg, #0068B5, #00a8ff) !important;
        border-radius: 10px !important;
    }

</style>

<!-- ç§»åŠ¨ç«¯ä¾§è¾¹æ æ§åˆ¶å’Œé”®ç›˜å¿«æ·é”®JavaScript -->
<script>
(function() {
    'use strict';
    
    let hintTimeout;
    
    // ========================================
    // ğŸ“± ç§»åŠ¨ç«¯ä¾§è¾¹æ æ§åˆ¶ - ç®€åŒ–ç‰ˆ
    // ========================================
    function setupMobileSidebar() {
        const isMobile = window.innerWidth <= 768;
        
        if (!isMobile) return;
        
        // ç­‰å¾…Streamlitå®Œå…¨åŠ è½½
        setTimeout(function() {
            const sidebar = document.querySelector('[data-testid="stSidebar"]');
            const collapseButton = document.querySelector('[data-testid="collapsedControl"]');
            
            if (!sidebar) return;
            
            // åˆ›å»ºé®ç½©å±‚ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            let overlay = document.getElementById('mobile-sidebar-overlay');
            if (!overlay) {
                overlay = document.createElement('div');
                overlay.id = 'mobile-sidebar-overlay';
                overlay.style.cssText = `
                    position: fixed;
                    top: 0;
                    left: 0;
                    width: 100vw;
                    height: 100vh;
                    background: rgba(0, 0, 0, 0.5);
                    z-index: 999998;
                    display: none;
                    opacity: 0;
                    transition: opacity 0.3s ease;
                `;
                document.body.appendChild(overlay);
            }
            
            // æ£€æŸ¥ä¾§è¾¹æ çŠ¶æ€
            function isSidebarOpen() {
                const sidebarContent = sidebar.querySelector('[data-testid="stSidebarContent"]');
                return sidebarContent && window.getComputedStyle(sidebarContent).display !== 'none';
            }
            
            // å…³é—­ä¾§è¾¹æ 
            function closeSidebar() {
                // æŸ¥æ‰¾å¹¶ç‚¹å‡»ä¾§è¾¹æ å†…çš„æ”¶èµ·æŒ‰é’®
                const closeBtn = sidebar.querySelector('button[kind="header"]');
                if (closeBtn) {
                    closeBtn.click();
                }
                
                // éšè—é®ç½©å±‚
                overlay.style.display = 'none';
                overlay.style.opacity = '0';
                document.body.style.overflow = '';
            }
            
            // æ‰“å¼€ä¾§è¾¹æ 
            function openSidebar() {
                // æ˜¾ç¤ºé®ç½©å±‚
                overlay.style.display = 'block';
                setTimeout(() => {
                    overlay.style.opacity = '1';
                }, 10);
                document.body.style.overflow = 'hidden';
            }
            
            // ç›‘å¬é®ç½©å±‚ç‚¹å‡»
            overlay.onclick = closeSidebar;
            
            // ç›‘å¬å±•å¼€æŒ‰é’®ç‚¹å‡»
            if (collapseButton) {
                collapseButton.addEventListener('click', function() {
                    setTimeout(openSidebar, 100);
                });
            }
            
            // ç›‘å¬ä¾§è¾¹æ å†…çš„æ”¶èµ·æŒ‰é’®
            const sidebarCloseBtn = sidebar.querySelector('button[kind="header"]');
            if (sidebarCloseBtn) {
                sidebarCloseBtn.addEventListener('click', function() {
                    setTimeout(closeSidebar, 100);
                });
            }
            
            // ç›‘å¬ä¾§è¾¹æ å†…çš„é“¾æ¥å’Œé€‰é¡¹ç‚¹å‡»ï¼ˆç‚¹å‡»åè‡ªåŠ¨å…³é—­ï¼‰
            sidebar.addEventListener('click', function(e) {
                const target = e.target;
                if (target.tagName === 'A' || 
                    target.closest('[role="option"]') ||
                    target.closest('button[kind="secondary"]')) {
                    setTimeout(closeSidebar, 300);
                }
            });
            
            // åˆå§‹çŠ¶æ€æ£€æŸ¥
            if (isSidebarOpen()) {
                openSidebar();
            } else {
                closeSidebar();
            }
            
            // ç›‘å¬ä¾§è¾¹æ çŠ¶æ€å˜åŒ–
            const sidebarObserver = new MutationObserver(function() {
                if (isSidebarOpen()) {
                    openSidebar();
                } else {
                    overlay.style.display = 'none';
                    overlay.style.opacity = '0';
                }
            });
            
            const sidebarContent = sidebar.querySelector('[data-testid="stSidebarContent"]');
            if (sidebarContent) {
                sidebarObserver.observe(sidebarContent, {
                    attributes: true,
                    attributeFilter: ['style']
                });
            }
        }, 500);
    }
    
    // åˆå§‹åŒ–
    if (document.readyState === 'loading') {
        document.addEventListener('DOMContentLoaded', setupMobileSidebar);
    } else {
        setupMobileSidebar();
    }
    
    // ç›‘å¬çª—å£å¤§å°å˜åŒ–
    let resizeTimer;
    window.addEventListener('resize', function() {
        clearTimeout(resizeTimer);
        resizeTimer = setTimeout(setupMobileSidebar, 250);
    });
    
    // ç›‘å¬Streamlité‡æ–°æ¸²æŸ“
    window.addEventListener('load', function() {
        setTimeout(setupMobileSidebar, 1000);
    });
    
    // ========================================
    // âŒ¨ï¸ é”®ç›˜å¿«æ·é”®
    // ========================================
    
    // æ˜¾ç¤ºå¿«æ·é”®æç¤º
    function showKeyboardHint(text) {
        let hint = document.querySelector('.keyboard-hint');
        if (!hint) {
            hint = document.createElement('div');
            hint.className = 'keyboard-hint';
            document.body.appendChild(hint);
        }
        hint.textContent = text;
        hint.classList.add('show');
        
        clearTimeout(hintTimeout);
        hintTimeout = setTimeout(() => {
            hint.classList.remove('show');
        }, 2000);
    }
    
    // é”®ç›˜äº‹ä»¶ç›‘å¬
    document.addEventListener('keydown', function(e) {
        // Ctrl/Cmd + Enter: å‘é€æ¶ˆæ¯
        if ((e.ctrlKey || e.metaKey) && e.key === 'Enter') {
            const chatInput = document.querySelector('.stChatInput input');
            if (chatInput && chatInput.value.trim()) {
                const submitBtn = document.querySelector('.stChatInput button');
                if (submitBtn) {
                    submitBtn.click();
                    showKeyboardHint('æ¶ˆæ¯å·²å‘é€ (Ctrl+Enter)');
                }
            }
        }
        
        // Ctrl/Cmd + N: æ–°å»ºä¼šè¯
        if ((e.ctrlKey || e.metaKey) && e.key === 'n') {
            e.preventDefault();
            const newSessionBtn = document.querySelector('button[title*="æ–°å»º"]');
            if (newSessionBtn) {
                newSessionBtn.click();
                showKeyboardHint('æ–°å»ºä¼šè¯ (Ctrl+N)');
            }
        }
        
        // Ctrl/Cmd + /: èšç„¦æœç´¢
        if ((e.ctrlKey || e.metaKey) && e.key === '/') {
            e.preventDefault();
            const chatInput = document.querySelector('.stChatInput input');
            if (chatInput) {
                chatInput.focus();
                showKeyboardHint('èšç„¦è¾“å…¥æ¡† (Ctrl+/)');
            }
        }
        
        // Esc: æ¸…é™¤è¾“å…¥
        if (e.key === 'Escape') {
            const chatInput = document.querySelector('.stChatInput input');
            if (chatInput && chatInput.value) {
                chatInput.value = '';
                showKeyboardHint('è¾“å…¥å·²æ¸…é™¤ (Esc)');
            }
        }
        
        // F1: æ˜¾ç¤ºå¿«æ·é”®å¸®åŠ©
        if (e.key === 'F1') {
            e.preventDefault();
            showKeyboardHint('å¿«æ·é”®: Ctrl+Enterå‘é€, Ctrl+Næ–°å»º, Ctrl+/èšç„¦, Escæ¸…é™¤');
        }
    });
    
    // æ·»åŠ æˆåŠŸåé¦ˆåŠ¨ç”»
    function addSuccessFeedback(element) {
        element.classList.add('success-feedback');
        setTimeout(() => {
            element.classList.remove('success-feedback');
        }, 600);
    }
    
    // ç›‘å¬æŒ‰é’®ç‚¹å‡»ï¼Œæ·»åŠ åé¦ˆ
    document.addEventListener('click', function(e) {
        if (e.target.tagName === 'BUTTON') {
            addSuccessFeedback(e.target);
        }
    });
});
</script>
""", unsafe_allow_html=True)

# --- çŠ¶æ€ç®¡ç† ---
if "config" not in st.session_state: st.session_state.config = load_config()
if "history" not in st.session_state: st.session_state.history = load_history()
if "last_total_latency" not in st.session_state: st.session_state.last_total_latency = 0.0
if "last_rag_latency" not in st.session_state: st.session_state.last_rag_latency = 0.0
if "prompt_trigger" not in st.session_state: st.session_state.prompt_trigger = None
if "agent_loaded" not in st.session_state: st.session_state.agent_loaded = False

# ğŸ§  Promptæ¨¡æ¿ç³»ç»ŸçŠ¶æ€åˆå§‹åŒ–
if PROMPT_TEMPLATE_AVAILABLE:
    if "prompt_mode" not in st.session_state:
        st.session_state.prompt_mode = "flexible"
    if "show_advanced_prompt_config" not in st.session_state:
        st.session_state.show_advanced_prompt_config = False

# ğŸ§  åˆå§‹åŒ–ä¸Šä¸‹æ–‡è®°å¿†è®¾ç½® - ä»é…ç½®æ–‡ä»¶åŠ è½½
if CONTEXT_MEMORY_AVAILABLE:
    try:
        # é¦–å…ˆç¡®ä¿åŸºæœ¬çš„ session_state å±æ€§å­˜åœ¨
        if 'context_memory_enabled' not in st.session_state:
            st.session_state.context_memory_enabled = True
        if 'context_memory_depth' not in st.session_state:
            st.session_state.context_memory_depth = 5
        if 'context_memory_strength' not in st.session_state:
            st.session_state.context_memory_strength = 0.7
        if 'context_auto_clean' not in st.session_state:
            st.session_state.context_auto_clean = True
        if 'context_persist_memory' not in st.session_state:
            st.session_state.context_persist_memory = False
        if 'context_privacy_mode' not in st.session_state:
            st.session_state.context_privacy_mode = False
            
        # ç„¶ååˆå§‹åŒ–ä¸Šä¸‹æ–‡é›†æˆï¼ˆè¿™ä¼šä»é…ç½®æ–‡ä»¶åŠ è½½å¹¶è¦†ç›–é»˜è®¤å€¼ï¼‰
        context_integration = get_context_integration()
        # è¿™ä¼šè‡ªåŠ¨åŠ è½½ä¿å­˜çš„è®¾ç½®åˆ° session_state
    except Exception as e:
        print(f"ä¸Šä¸‹æ–‡è®°å¿†è®¾ç½®åŠ è½½å¤±è´¥: {e}")
        # ä½¿ç”¨é»˜è®¤è®¾ç½®
        if 'context_memory_enabled' not in st.session_state:
            st.session_state.context_memory_enabled = True

# ç¡®ä¿æœ‰å½“å‰ä¼šè¯ID
# ä¿®æ”¹ä¼˜åŒ–ï¼šç³»ç»Ÿå¯åŠ¨æˆ–åˆ·æ–°æ—¶ï¼Œå¼ºåˆ¶åˆ›å»ºä¸€ä¸ªæ–°ä¼šè¯ï¼Œç¡®ä¿æ˜¾ç¤ºâ€œæ¬¢è¿é¡µâ€
if "current_session_id" not in st.session_state or st.session_state.current_session_id not in st.session_state.history:
    # ç›´æ¥è°ƒç”¨æ–°å»ºä¼šè¯é€»è¾‘
    sid, hist = create_new_session(st.session_state.history)
    st.session_state.history = hist
    st.session_state.current_session_id = sid

# ğŸ§  å¤„ç†é«˜çº§Prompté…ç½®é¡µé¢
if PROMPT_TEMPLATE_AVAILABLE and st.session_state.get('show_advanced_prompt_config', False):
    st.markdown("## ğŸ”§ Promptæ¨¡æ¿é«˜çº§é…ç½®")
    
    # è¿”å›æŒ‰é’®
    if st.button("ğŸ”™ è¿”å›ä¸»ç•Œé¢", key="back_to_main"):
        st.session_state.show_advanced_prompt_config = False
        st.rerun()
    
    # æ¸²æŸ“é«˜çº§é…ç½®ç•Œé¢
    try:
        config_ui = st.session_state.prompt_config_ui
        
        # æ ‡ç­¾é¡µ
        tab1, tab2, tab3, tab4 = st.tabs([
            "ğŸ“ ä¸šåŠ¡ä¸Šä¸‹æ–‡", "ğŸ“š æœ¯è¯­è¯å…¸", "ğŸ’¡ ç¤ºä¾‹æŸ¥è¯¢", "ğŸ‘ï¸ Prompté¢„è§ˆ"
        ])
        
        with tab1:
            config_ui.render_business_context_config()
        
        with tab2:
            config_ui.render_term_dictionary_config()
        
        with tab3:
            config_ui.render_example_queries_config()
        
        with tab4:
            config_ui.render_prompt_preview()
    
    except Exception as e:
        st.error(f"é«˜çº§é…ç½®ç•Œé¢é”™è¯¯: {e}")
        if st.button("ğŸ”™ è¿”å›ä¸»ç•Œé¢", key="back_to_main_error"):
            st.session_state.show_advanced_prompt_config = False
            st.rerun()
    
    # åœæ­¢æ‰§è¡Œï¼Œä¸æ˜¾ç¤ºæ­£å¸¸çš„ä¸»ç•Œé¢
    st.stop()

# --- ä¾§è¾¹æ é…ç½® ---
with st.sidebar:
    # Intel Logo å’Œå“ç‰Œæ ‡è¯†
    if os.path.exists("assets/intel.svg"):
        st.image("assets/intel.svg", width=120)
    else:
        st.markdown("### IntelÂ® DeepInsight")
    
    # ğŸ§  æ¸²æŸ“ä¸Šä¸‹æ–‡è®°å¿†UI
    # ğŸ§  ç¾åŒ–åçš„ä¸Šä¸‹æ–‡è®°å¿†ç³»ç»ŸUI
    if CONTEXT_MEMORY_AVAILABLE:
        with st.expander("ğŸ§  ä¸Šä¸‹æ–‡è®°å¿†ç³»ç»Ÿ", expanded=False):
            st.markdown("""
            <style>
                
                .context-status-badge {
                    display: inline-block;
                    padding: 4px 10px;
                    border-radius: 20px;
                    font-size: 0.8em;
                    font-weight: 600;
                    margin-right: 8px;
                    margin-bottom: 8px;
                }
                .context-status-enabled {
                    background: linear-gradient(135deg, #d4edda 0%, #c3e6cb 100%);
                    color: #155724;
                    border: 1px solid #b1dfbb;
                }
                .context-status-disabled {
                    background: linear-gradient(135deg, #f8d7da 0%, #f5c6cb 100%);
                    color: #721c24;
                    border: 1px solid #f1b0b7;
                }
                .context-setting-label {
                    font-weight: 600;
                    font-size: 0.9em;
                    color: #495057;
                    margin-bottom: 5px;
                    display: flex;
                    align-items: center;
                }
                .context-setting-label i {
                    margin-right: 8px;
                    color: #0068B5;
                }
                .context-tooltip {
                    font-size: 0.85em;
                    color: #6c757d;
                    margin-top: 4px;
                    line-height: 1.4;
                    font-style: italic;
                }
            </style>
            """, unsafe_allow_html=True)
            
            # å†…å­˜çŠ¶æ€å¡ç‰‡
            
            
            # æ˜¾ç¤ºå½“å‰çŠ¶æ€
            col_status, col_actions = st.columns([3, 2])
            with col_status:
                st.markdown("**ğŸ“Š å½“å‰çŠ¶æ€**")
                
                # è·å–å½“å‰çŠ¶æ€ - ç¡®ä¿ä»session_stateè·å–æœ€æ–°å€¼
                memory_enabled = st.session_state.get('context_memory_enabled', True)
                
                # çŠ¶æ€æ ‡ç­¾ - ä½¿ç”¨åŠ¨æ€æ›´æ–°
                if memory_enabled:
                    st.markdown('<span class="context-status-badge context-status-enabled">âœ… å·²å¯ç”¨</span>', unsafe_allow_html=True)
                    st.caption("AIå°†è®°ä½å¯¹è¯å†å²ï¼Œæä¾›æ›´æ™ºèƒ½çš„å›å¤")
                else:
                    st.markdown('<span class="context-status-badge context-status-disabled">â¸ï¸ å·²ç¦ç”¨</span>', unsafe_allow_html=True)
                    st.caption("AIå°†ä¸ä¼šè®°ä½å¯¹è¯å†å²")
            
            with col_actions:
                st.markdown("**âš™ï¸ æ“ä½œ**")
                
                # åˆ‡æ¢å¼€å…³ - ä½¿ç”¨å½“å‰çŠ¶æ€
                current_memory_enabled = st.session_state.get('context_memory_enabled', True)
                toggle_label = "ç¦ç”¨è®°å¿†" if current_memory_enabled else "å¯ç”¨è®°å¿†"
                toggle_icon = "â¸ï¸" if current_memory_enabled else "â–¶ï¸"
                
                if st.button(f"{toggle_icon} {toggle_label}", 
                            use_container_width=True,
                            key="toggle_memory_btn"):
                    # åˆ‡æ¢çŠ¶æ€
                    new_state = not current_memory_enabled
                    st.session_state.context_memory_enabled = new_state
                    
                    # ç«‹å³ä¿å­˜è®¾ç½®åˆ°é…ç½®æ–‡ä»¶
                    if CONTEXT_MEMORY_AVAILABLE:
                        try:
                            context_integration = get_context_integration()
                            context_integration._save_memory_settings()
                            
                            # æ˜¾ç¤ºæ“ä½œåé¦ˆ
                            if new_state:
                                st.success("âœ… ä¸Šä¸‹æ–‡è®°å¿†å·²å¯ç”¨")
                            else:
                                st.info("â¸ï¸ ä¸Šä¸‹æ–‡è®°å¿†å·²ç¦ç”¨")
                                
                        except Exception as e:
                            st.error(f"ä¿å­˜è®¾ç½®å¤±è´¥: {e}")
                    
                    # å¼ºåˆ¶åˆ·æ–°é¡µé¢ä»¥æ›´æ–°æ‰€æœ‰UIç»„ä»¶
                    time.sleep(0.5)  # çŸ­æš‚å»¶è¿Ÿç¡®ä¿è®¾ç½®å·²ä¿å­˜
                    st.rerun()
            
            st.markdown('</div>', unsafe_allow_html=True)
            
            # é…ç½®è®¾ç½®
            
            st.markdown("**ğŸ”§ è®°å¿†é…ç½®**")
            
            # è®°å¿†æ·±åº¦è®¾ç½®
            st.markdown('<div class="context-setting-label"><i>ğŸ“</i> è®°å¿†æ·±åº¦</div>', unsafe_allow_html=True)
            
            # è·å–æˆ–åˆå§‹åŒ–è®°å¿†æ·±åº¦è®¾ç½®
            if "context_memory_depth" not in st.session_state:
                st.session_state.context_memory_depth = 5
            
            memory_depth = st.slider(
                "ä¿ç•™çš„å¯¹è¯è½®æ•°",
                min_value=1,
                max_value=20,
                value=st.session_state.context_memory_depth,
                key="memory_depth_slider",
                label_visibility="collapsed",
                help="è®¾ç½®AIèƒ½å¤Ÿè®°ä½çš„æœ€è¿‘å¯¹è¯è½®æ•°ã€‚è¾ƒå¤§çš„å€¼ä¼šè®©AIè®°ä½æ›´å¤šå†å²ï¼Œä½†å¯èƒ½å½±å“å“åº”é€Ÿåº¦ã€‚æ¨èå€¼ï¼š3-8è½®"
            )
            if memory_depth != st.session_state.context_memory_depth:
                st.session_state.context_memory_depth = memory_depth
                # ä¿å­˜è®¾ç½®
                if CONTEXT_MEMORY_AVAILABLE:
                    try:
                        context_integration = get_context_integration()
                        context_integration._save_memory_settings()
                    except Exception:
                        pass
            
            st.markdown('<div class="context-tooltip">ğŸ’¡ <strong>ç®—æ³•è¯´æ˜</strong>: ç³»ç»Ÿä½¿ç”¨æ»‘åŠ¨çª—å£ç®—æ³•ä¿ç•™æœ€è¿‘Nè½®å¯¹è¯ï¼Œè¶…å‡ºèŒƒå›´çš„å¯¹è¯å°†è¢«è‡ªåŠ¨æ¸…ç†ã€‚è¾ƒå¤§çš„å€¼æä¾›æ›´å¥½çš„ä¸Šä¸‹æ–‡è¿è´¯æ€§ï¼Œä½†ä¼šå¢åŠ è®¡ç®—å¼€é”€ã€‚</div>', unsafe_allow_html=True)
            st.markdown('</div>', unsafe_allow_html=True)
            
            # è®°å¿†å¼ºåº¦è®¾ç½®
            st.markdown('<div class="context-setting-label"><i>ğŸ’ª</i> è®°å¿†å¼ºåº¦</div>', unsafe_allow_html=True)
            
            # è·å–æˆ–åˆå§‹åŒ–è®°å¿†å¼ºåº¦è®¾ç½®
            if "context_memory_strength" not in st.session_state:
                st.session_state.context_memory_strength = 0.7
            
            memory_strength = st.slider(
                "è®°å¿†å½±å“åŠ›æƒé‡",
                min_value=0.0,
                max_value=1.0,
                value=st.session_state.context_memory_strength,
                step=0.1,
                key="memory_strength_slider",
                label_visibility="collapsed",
                help="è®¾ç½®å†å²å¯¹è¯å¯¹å½“å‰å›ç­”çš„å½±å“ç¨‹åº¦ã€‚0.0è¡¨ç¤ºå®Œå…¨å¿½ç•¥å†å²ï¼Œ1.0è¡¨ç¤ºå®Œå…¨ä¾èµ–å†å²ã€‚æ¨èå€¼ï¼š0.5-0.8"
            )
            if memory_strength != st.session_state.context_memory_strength:
                st.session_state.context_memory_strength = memory_strength
                # ä¿å­˜è®¾ç½®
                if CONTEXT_MEMORY_AVAILABLE:
                    try:
                        context_integration = get_context_integration()
                        context_integration._save_memory_settings()
                    except Exception:
                        pass
            
            st.markdown('<div class="context-tooltip">ğŸ’¡ <strong>ç®—æ³•è¯´æ˜</strong>: ä½¿ç”¨åŠ æƒèåˆç®—æ³•ï¼Œå°†å†å²ä¸Šä¸‹æ–‡ä¸å½“å‰è¾“å…¥æŒ‰æ­¤æƒé‡æ¯”ä¾‹æ··åˆã€‚æƒé‡è¶Šé«˜ï¼ŒAIè¶Šå€¾å‘äºåŸºäºå†å²ä¿¡æ¯å›ç­”ï¼›æƒé‡è¶Šä½ï¼ŒAIè¶Šä¸“æ³¨äºå½“å‰é—®é¢˜ã€‚</div>', unsafe_allow_html=True)
            st.markdown('</div>', unsafe_allow_html=True)
            
            # é«˜çº§è®¾ç½®
            with st.expander("âš¡ é«˜çº§è®¾ç½®", expanded=False):
                # è‡ªåŠ¨æ¸…ç†é€‰é¡¹
                auto_clean = st.checkbox(
                    "è‡ªåŠ¨æ¸…ç†è¿‡æœŸè®°å¿†",
                    value=st.session_state.get('context_auto_clean', True),
                    help="è‡ªåŠ¨æ¸…ç†è¶…è¿‡24å°æ—¶çš„æ—§è®°å¿†ï¼Œä¿æŒç³»ç»Ÿæ€§èƒ½",
                    key="auto_clean_checkbox"
                )
                if auto_clean != st.session_state.get('context_auto_clean', True):
                    st.session_state.context_auto_clean = auto_clean
                    if CONTEXT_MEMORY_AVAILABLE:
                        try:
                            context_integration = get_context_integration()
                            context_integration._save_memory_settings()
                            if auto_clean:
                                context_integration.auto_cleanup_expired_memory()
                                st.success("âœ… å·²å¯ç”¨è‡ªåŠ¨æ¸…ç†å¹¶æ‰§è¡Œäº†ä¸€æ¬¡æ¸…ç†")
                        except Exception as e:
                            st.error(f"è®¾ç½®è‡ªåŠ¨æ¸…ç†å¤±è´¥: {e}")
                
                # è®°å¿†æŒä¹…åŒ–é€‰é¡¹
                persist_memory = st.checkbox(
                    "æŒä¹…åŒ–è®°å¿†åˆ°ç£ç›˜",
                    value=st.session_state.get('context_persist_memory', False),
                    help="å°†å¯¹è¯è®°å¿†ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶ï¼Œä¸‹æ¬¡å¯åŠ¨æ—¶æ¢å¤ï¼ˆå½“å‰ç‰ˆæœ¬å·²é»˜è®¤å¯ç”¨SQLiteæŒä¹…åŒ–ï¼‰",
                    key="persist_memory_checkbox"
                )
                if persist_memory != st.session_state.get('context_persist_memory', False):
                    st.session_state.context_persist_memory = persist_memory
                    if CONTEXT_MEMORY_AVAILABLE:
                        try:
                            context_integration = get_context_integration()
                            context_integration._save_memory_settings()
                            if persist_memory:
                                st.info("ğŸ’¾ è®°å¿†æŒä¹…åŒ–å·²å¯ç”¨ï¼Œå¯¹è¯æ•°æ®å°†ä¿å­˜åˆ° streamlit_context_memory.db")
                            else:
                                st.info("âš ï¸ æ³¨æ„ï¼šç¦ç”¨æŒä¹…åŒ–ä¸ä¼šåˆ é™¤å·²ä¿å­˜çš„æ•°æ®ï¼Œåªæ˜¯ä¸å†ä¿å­˜æ–°çš„å¯¹è¯")
                        except Exception as e:
                            st.error(f"è®¾ç½®æŒä¹…åŒ–å¤±è´¥: {e}")
                
                # éšç§æ¨¡å¼
                privacy_mode = st.checkbox(
                    "éšç§æ¨¡å¼ï¼ˆä¸ä¿å­˜æ•æ„Ÿä¿¡æ¯ï¼‰",
                    value=st.session_state.get('context_privacy_mode', False),
                    help="å¯ç”¨åï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è¿‡æ»¤é‚®ç®±ã€ç”µè¯ã€èº«ä»½è¯ç­‰æ•æ„Ÿä¿¡æ¯",
                    key="privacy_mode_checkbox"
                )
                if privacy_mode != st.session_state.get('context_privacy_mode', False):
                    st.session_state.context_privacy_mode = privacy_mode
                    if CONTEXT_MEMORY_AVAILABLE:
                        try:
                            context_integration = get_context_integration()
                            context_integration._save_memory_settings()
                            if privacy_mode:
                                st.success("ğŸ”’ éšç§æ¨¡å¼å·²å¯ç”¨ï¼Œæ•æ„Ÿä¿¡æ¯å°†è¢«è‡ªåŠ¨è¿‡æ»¤")
                            else:
                                st.info("ğŸ”“ éšç§æ¨¡å¼å·²ç¦ç”¨ï¼Œå¯¹è¯å†…å®¹å°†å®Œæ•´ä¿å­˜")
                        except Exception as e:
                            st.error(f"è®¾ç½®éšç§æ¨¡å¼å¤±è´¥: {e}")
            
            st.markdown('</div>', unsafe_allow_html=True)
            
            # è®°å¿†ç»Ÿè®¡ä¿¡æ¯ - ä½¿ç”¨å½“å‰çŠ¶æ€
            current_memory_enabled = st.session_state.get('context_memory_enabled', True)
            if current_memory_enabled:
                
                st.markdown("**ğŸ“ˆ è®°å¿†ç»Ÿè®¡**")
                
                # è·å–å®é™…çš„ç»Ÿè®¡ä¿¡æ¯
                if CONTEXT_MEMORY_AVAILABLE:
                    try:
                        context_integration = get_context_integration()
                        stats = context_integration.get_context_stats()
                        
                        col_stat1, col_stat2, col_stat3 = st.columns(3)
                        with col_stat1:
                            saved_conversations = stats.get('saved_conversations', 0)
                            st.metric("å·²ä¿å­˜å¯¹è¯", f"{saved_conversations}è½®", 
                                    delta=f"+{min(2, saved_conversations)}" if saved_conversations > 0 else None)
                        with col_stat2:
                            memory_capacity = stats.get('memory_capacity_percent', 0)
                            st.metric("è®°å¿†å®¹é‡", f"{memory_capacity}%", 
                                    delta=f"+{min(5, memory_capacity//10)}%" if memory_capacity > 0 else None)
                        with col_stat3:
                            association_accuracy = stats.get('association_accuracy_percent', 0)
                            st.metric("å…³è”ç²¾åº¦", f"{association_accuracy}%", 
                                    delta=f"+{min(3, association_accuracy//20)}%" if association_accuracy > 0 else None)
                        
                    except Exception as e:
                        # é™çº§æ˜¾ç¤º
                        col_stat1, col_stat2, col_stat3 = st.columns(3)
                        with col_stat1:
                            st.metric("å·²ä¿å­˜å¯¹è¯", "0è½®")
                        with col_stat2:
                            st.metric("è®°å¿†å®¹é‡", "0%")
                        with col_stat3:
                            st.metric("å…³è”ç²¾åº¦", "0%")
                        st.caption(f"âš ï¸ ç»Ÿè®¡æ•°æ®è·å–å¤±è´¥: {e}")
                else:
                    # æ¨¡æ‹Ÿç»Ÿè®¡ä¿¡æ¯
                    col_stat1, col_stat2, col_stat3 = st.columns(3)
                    with col_stat1:
                        st.metric("å·²ä¿å­˜å¯¹è¯", "0è½®")
                    with col_stat2:
                        st.metric("è®°å¿†å®¹é‡", "0%")
                    with col_stat3:
                        st.metric("å…³è”ç²¾åº¦", "0%")
                
                # æ¸…ç†è®°å¿†æŒ‰é’®
                if st.button("ğŸ—‘ï¸ æ¸…ç†æ‰€æœ‰è®°å¿†", use_container_width=True, type="secondary"):
                    # ä½¿ç”¨ç¡®è®¤å¯¹è¯æ¡†
                    if 'confirm_clear_memory' not in st.session_state:
                        st.session_state.confirm_clear_memory = False
                    
                    if not st.session_state.confirm_clear_memory:
                        st.session_state.confirm_clear_memory = True
                        st.rerun()
                
                # æ˜¾ç¤ºç¡®è®¤å¯¹è¯æ¡†
                if st.session_state.get('confirm_clear_memory', False):
                    st.warning("âš ï¸ ç¡®å®šè¦æ¸…ç†æ‰€æœ‰å¯¹è¯è®°å¿†å—ï¼Ÿæ­¤æ“ä½œä¸å¯æ’¤é”€ã€‚")
                    col_confirm1, col_confirm2 = st.columns(2)
                    with col_confirm1:
                        if st.button("âœ… ç¡®è®¤æ¸…ç†", use_container_width=True, key="confirm_clear_btn"):
                            if CONTEXT_MEMORY_AVAILABLE:
                                try:
                                    context_integration = get_context_integration()
                                    success = context_integration.clear_all_memory()
                                    if success:
                                        st.success("âœ… æ‰€æœ‰è®°å¿†å·²æ¸…ç†")
                                        st.session_state.confirm_clear_memory = False
                                        time.sleep(1)
                                        st.rerun()
                                    else:
                                        st.error("âŒ æ¸…ç†å¤±è´¥")
                                except Exception as e:
                                    st.error(f"âŒ æ¸…ç†å¤±è´¥: {e}")
                            else:
                                st.error("âŒ è®°å¿†ç³»ç»Ÿä¸å¯ç”¨")
                            st.session_state.confirm_clear_memory = False
                    with col_confirm2:
                        if st.button("âŒ å–æ¶ˆ", use_container_width=True, key="cancel_clear_btn"):
                            st.session_state.confirm_clear_memory = False
                            st.rerun()
                
                st.markdown('</div>', unsafe_allow_html=True)
            
            # ä½¿ç”¨æç¤º
            st.info("ğŸ’¡ **ä½¿ç”¨æç¤º**: å¯ç”¨ä¸Šä¸‹æ–‡è®°å¿†å¯ä»¥è®©AIæ›´å¥½åœ°ç†è§£å¤šè½®å¯¹è¯çš„ä¸Šä¸‹æ–‡ï¼Œæä¾›æ›´è¿è´¯ã€æ›´å‡†ç¡®çš„å›ç­”ã€‚")
            
            # è°ƒç”¨åŸå§‹çš„render_context_uiå‡½æ•°ä»¥ç¡®ä¿åŠŸèƒ½å®Œæ•´æ€§
            # æ³¨æ„ï¼šæˆ‘ä»¬ä¿ç•™äº†åŸå§‹çš„åŠŸèƒ½è°ƒç”¨ï¼Œä½†å°†å…¶åŒ…è£…åœ¨éšè—çš„å®¹å™¨ä¸­
            # è¿™æ ·æ—¢ä¿ç•™äº†åŠŸèƒ½ï¼Œåˆæä¾›äº†ç¾è§‚çš„UI
            # with st.container():
            #     st.markdown('<div style="display: none;">', unsafe_allow_html=True)
            #     render_context_ui()
            #     st.markdown('</div>', unsafe_allow_html=True)
    else:
        # å¦‚æœä¸Šä¸‹æ–‡è®°å¿†ç³»ç»Ÿä¸å¯ç”¨ï¼Œæ˜¾ç¤ºå‹å¥½çš„æç¤º
        with st.expander("ğŸ§  ä¸Šä¸‹æ–‡è®°å¿†ç³»ç»Ÿ", expanded=False):
            st.warning("ä¸Šä¸‹æ–‡è®°å¿†ç³»ç»Ÿå½“å‰ä¸å¯ç”¨")
            st.info("è¦å¯ç”¨ä¸Šä¸‹æ–‡è®°å¿†åŠŸèƒ½ï¼Œè¯·ç¡®ä¿å·²æ­£ç¡®å®‰è£…å¹¶é…ç½®ç›¸å…³æ¨¡å—ã€‚")
    
    # ç›‘æ§é¢æ¿å ä½ç¬¦
    monitor_placeholder = st.empty()
    
    # ğŸ§  Promptæ¨¡æ¿é…ç½®é¢æ¿
    if PROMPT_TEMPLATE_AVAILABLE:
        with st.expander("ğŸ§  Promptæ¨¡æ¿é…ç½®", expanded=False):
            try:
                # åˆå§‹åŒ–Prompté…ç½®UI
                if 'prompt_config_ui' not in st.session_state:
                    st.session_state.prompt_config_ui = PromptConfigUI()
                
                config_ui = st.session_state.prompt_config_ui
                
                # è·å–é…ç½®æ‘˜è¦
                summary = config_ui.manager.get_config_summary()
                
                # åªåœ¨éœ€è¦æ—¶åˆ·æ–°ç»Ÿè®¡æ•°æ®ï¼Œä¸é‡æ–°åŠ è½½é…ç½®
                if st.session_state.get('prompt_config_updated', 0) > st.session_state.get('last_summary_update', 0):
                    # åªåˆ·æ–°ç»Ÿè®¡æ•°æ®ï¼Œä¸é‡æ–°åŠ è½½é…ç½®æ–‡ä»¶
                    summary = config_ui.manager.get_config_summary()
                    st.session_state.last_summary_update = time.time()
                
                # é…ç½®çŠ¶æ€æ˜¾ç¤º
                col1, col2 = st.columns(2)
                with col1:
                    st.metric(
                        "ä¸šåŠ¡ä¸Šä¸‹æ–‡", 
                        "å·²é…ç½®" if summary['business_context_configured'] else "æœªé…ç½®",
                        f"{summary['business_context_length']}/2000å­—ç¬¦"
                    )
                with col2:
                    st.metric("æœ¯è¯­è¯å…¸", f"{summary['term_dictionary_size']}ä¸ªæœ¯è¯­")
                
                st.metric("ç¤ºä¾‹æŸ¥è¯¢", f"{summary['example_queries_count']}ä¸ªç¤ºä¾‹")
                
                # å¿«é€Ÿé…ç½®é€‰é¡¹
                st.markdown("**âš™ï¸ å¿«é€Ÿé…ç½®**")
                
                # LLMæ¨¡å¼é€‰æ‹©
                current_mode = st.session_state.get('prompt_mode', 'flexible')
                prompt_mode = st.selectbox(
                    "æŸ¥è¯¢ç­–ç•¥",
                    options=['professional', 'flexible'],
                    index=0 if current_mode == 'professional' else 1,
                    format_func=lambda x: "æ ‡å‡†æŸ¥è¯¢ (ä¸¥æ ¼åŒ¹é…)" if x == 'professional' else "æ™ºèƒ½æŸ¥è¯¢ (è¯­ä¹‰ç†è§£)",
                    help="æ ‡å‡†æŸ¥è¯¢ï¼šä¸¥æ ¼æŒ‰ç…§æ•°æ®åº“ç»“æ„ç”Ÿæˆç²¾ç¡®SQLï¼›æ™ºèƒ½æŸ¥è¯¢ï¼šç†è§£ä¸šåŠ¡è¯­ä¹‰ï¼Œæä¾›æ›´çµæ´»çš„æŸ¥è¯¢æ–¹æ¡ˆ",
                    key="prompt_mode_select"
                )
                
                if prompt_mode != current_mode:
                    st.session_state.prompt_mode = prompt_mode
                    mode_name = "æ ‡å‡†æŸ¥è¯¢" if prompt_mode == 'professional' else "æ™ºèƒ½æŸ¥è¯¢"
                    st.success(f"âœ… å·²åˆ‡æ¢åˆ°{mode_name}ç­–ç•¥")
                
                # ä¸šåŠ¡ä¸Šä¸‹æ–‡å¿«é€Ÿé…ç½®
                st.markdown("**ğŸ“ ä¸šåŠ¡ä¸Šä¸‹æ–‡**")
                
                current_context = config_ui.manager.business_context
                
                # è¡Œä¸šæœ¯è¯­è¾“å…¥
                industry_terms = st.text_area(
                    "è¡Œä¸šæœ¯è¯­ (ç”¨é€—å·åˆ†éš”)",
                    value=current_context.industry_terms,
                    height=60,
                    placeholder="ä¾‹å¦‚ï¼šé›¶å”®ä¸šã€ç”µå•†ã€ä¾›åº”é“¾ã€åº“å­˜å‘¨è½¬ç‡ã€å®¢å•ä»·",
                    help="è¾“å…¥æ‚¨æ‰€åœ¨è¡Œä¸šçš„ä¸“ä¸šæœ¯è¯­ï¼Œç³»ç»Ÿä¼šè‡ªåŠ¨è¯†åˆ«å’Œè§£é‡Š"
                )
                
                # åˆ†æé‡ç‚¹
                analysis_focus = st.text_input(
                    "åˆ†æé‡ç‚¹",
                    value=current_context.analysis_focus,
                    placeholder="ä¾‹å¦‚ï¼šé”€å”®åˆ†æã€å®¢æˆ·åˆ†æã€äº§å“åˆ†æã€è¿è¥æ•ˆç‡",
                    help="æŒ‡æ˜æ‚¨æœ€å…³æ³¨çš„åˆ†æç»´åº¦"
                )
                
                # ä¿å­˜æŒ‰é’®
                col1, col2 = st.columns(2)
                with col1:
                    if st.button("ğŸ’¾ ä¿å­˜é…ç½®", use_container_width=True, key="save_prompt_config"):
                        try:
                            # ä¿å­˜æ—¶åªæ›´æ–°ç”¨æˆ·ä¿®æ”¹çš„å­—æ®µï¼Œä¿ç•™å…¶ä»–å­—æ®µçš„ç°æœ‰å€¼
                            config_ui.manager.update_business_context(
                                industry_terms=industry_terms,
                                analysis_focus=analysis_focus,
                                # ä¿ç•™ç°æœ‰çš„business_ruleså’Œdata_characteristics
                                business_rules=current_context.business_rules,
                                data_characteristics=current_context.data_characteristics
                            )
                            st.success("âœ… Prompté…ç½®å·²ä¿å­˜")
                            # å¼ºåˆ¶åˆ·æ–°ç»Ÿè®¡æ•°æ®
                            st.session_state.prompt_config_updated = time.time()
                            time.sleep(0.5)
                            st.rerun()
                        except Exception as e:
                            st.error(f"âŒ ä¿å­˜å¤±è´¥: {e}")
                
                with col2:
                    if st.button("ğŸ”§ é«˜çº§é…ç½®", use_container_width=True, key="advanced_prompt_config"):
                        st.session_state.show_advanced_prompt_config = True
                        st.rerun()
                
                # æœ¯è¯­è¯å…¸å¿«é€Ÿå¯¼å…¥
                st.markdown("**ğŸ“š æœ¯è¯­è¯å…¸**")
                uploaded_terms = st.file_uploader(
                    "ä¸Šä¼ æœ¯è¯­è¯å…¸ (CSVæ ¼å¼)",
                    type=['csv'],
                    help="CSVæ–‡ä»¶éœ€åŒ…å« 'term' å’Œ 'explanation' ä¸¤åˆ—",
                    key="terms_upload"
                )
                
                if uploaded_terms is not None:
                    try:
                        import pandas as pd
                        df = pd.read_csv(uploaded_terms)
                        
                        if 'term' in df.columns and 'explanation' in df.columns:
                            # ä½¿ç”¨å›ºå®šçš„æ–‡ä»¶åç¡®ä¿ä¸€è‡´æ€§
                            csv_path = "data/uploaded_terms_user_uploaded_terms.csv"
                            os.makedirs("data", exist_ok=True)
                            with open(csv_path, 'wb') as f:
                                f.write(uploaded_terms.getbuffer())
                            
                            config_ui.manager.load_term_dictionary(csv_path)
                            st.success(f"âœ… æˆåŠŸå¯¼å…¥ {len(df)} ä¸ªæœ¯è¯­")
                            # æ›´æ–°ç»Ÿè®¡æ•°æ®
                            st.session_state.prompt_config_updated = time.time()
                            time.sleep(0.5)
                            st.rerun()
                        else:
                            st.error("âŒ CSVæ–‡ä»¶å¿…é¡»åŒ…å« 'term' å’Œ 'explanation' åˆ—")
                    except Exception as e:
                        st.error(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
                
                # ç¤ºä¾‹æŸ¥è¯¢å¿«é€Ÿæ·»åŠ 
                st.markdown("**ğŸ’¡ ç¤ºä¾‹æŸ¥è¯¢**")
                col1, col2 = st.columns([3, 1])
                with col1:
                    new_example = st.text_input(
                        "æ·»åŠ ç¤ºä¾‹æŸ¥è¯¢",
                        placeholder="ä¾‹å¦‚ï¼šæŸ¥çœ‹é”€å”®é¢æœ€é«˜çš„äº§å“",
                        key="new_example_input"
                    )
                with col2:
                    example_category = st.selectbox(
                        "ç±»åˆ«",
                        ["é”€å”®åˆ†æ", "å®¢æˆ·åˆ†æ", "äº§å“åˆ†æ", "è¿è¥åˆ†æ", "è´¢åŠ¡åˆ†æ"],
                        key="example_category_select"
                    )
                
                if st.button("â• æ·»åŠ ç¤ºä¾‹", key="add_example_btn") and new_example:
                    config_ui.manager.add_example_query(
                        query=new_example,
                        category=example_category,
                        description=f"{example_category}ç¤ºä¾‹"
                    )
                    st.success("âœ… ç¤ºä¾‹æŸ¥è¯¢å·²æ·»åŠ ")
                    # æ›´æ–°ç»Ÿè®¡æ•°æ®
                    st.session_state.prompt_config_updated = time.time()
                    time.sleep(0.5)
                    st.rerun()
                
                # ä½¿ç”¨æç¤º
                st.info("ğŸ’¡ **ä½¿ç”¨æç¤º**: Promptæ¨¡æ¿ç³»ç»Ÿå¯ä»¥è®©AIæ›´å¥½åœ°ç†è§£æ‚¨çš„ä¸šåŠ¡éœ€æ±‚ï¼Œæä¾›æ›´å‡†ç¡®çš„åˆ†æç»“æœã€‚")
                
            except Exception as e:
                st.error(f"Promptæ¨¡æ¿é…ç½®é¢æ¿é”™è¯¯: {e}")
    else:
        with st.expander("ğŸ§  Promptæ¨¡æ¿é…ç½®", expanded=False):
            st.warning("Promptæ¨¡æ¿ç³»ç»Ÿå½“å‰ä¸å¯ç”¨")
            st.info("è¦å¯ç”¨Promptæ¨¡æ¿åŠŸèƒ½ï¼Œè¯·ç¡®ä¿å·²æ­£ç¡®å®‰è£…ç›¸å…³æ¨¡å—ã€‚")

    # ç¡¬ä»¶ä¼˜åŒ–é¢æ¿
    if HARDWARE_OPTIMIZATION_AVAILABLE:
        optimization_status = get_optimization_status()
        vendor = optimization_status.get('vendor', 'Unknown')
        
        # æ ¹æ®ç¡¬ä»¶å‚å•†æ˜¾ç¤ºä¸åŒçš„å›¾æ ‡å’Œæ ‡é¢˜
        if vendor == 'Intel':
            panel_title = "ğŸš€ Intelå¹³å°ä¼˜åŒ–"
            panel_icon = "ğŸ”§"
        elif vendor == 'NVIDIA':
            panel_title = "âš¡ NVIDIAå¹³å°ä¼˜åŒ–"
            panel_icon = "ğŸ®"
        elif vendor == 'AMD':
            panel_title = "ğŸ”¥ AMDå¹³å°ä¼˜åŒ–"
            panel_icon = "ğŸš€"
        else:
            panel_title = "ğŸ”§ ç¡¬ä»¶å¹³å°ä¼˜åŒ–"
            panel_icon = "âš™ï¸"
        
        with st.expander(panel_title, expanded=True):
            try:
                if optimization_status['enabled']:
                    if optimization_status['optimized']:
                        st.success(f"ğŸ¯ {vendor}ç³»ç»Ÿå·²ä¼˜åŒ–")
                        
                        # æ˜¾ç¤ºä¼˜åŒ–æŒ‡æ ‡
                        col1, col2 = st.columns(2)
                        with col1:
                            st.metric("CPUæå‡", optimization_status['cpu_gain'])
                            st.metric("æ€»ä½“åŠ é€Ÿ", optimization_status['overall_speedup'])
                        with col2:
                            st.metric("GPUåŠ é€Ÿ", optimization_status['gpu_speedup'])
                            st.metric("å†…å­˜æ•ˆç‡", optimization_status['memory_efficiency'])
                        
                        # æ˜¾ç¤ºä¼˜åŒ–æ¬¡æ•°
                        if 'optimization_count' in optimization_status:
                            st.caption(f"ğŸ”„ å·²ä¼˜åŒ–æŸ¥è¯¢: {optimization_status['optimization_count']} æ¬¡")
                        
                    else:
                        # æœªä¼˜åŒ–çŠ¶æ€ï¼šæ˜¾ç¤ºç¡¬ä»¶æ£€æµ‹ä¿¡æ¯ä½†ä¸æ˜¾ç¤ºæ€§èƒ½æŒ‡æ ‡
                        st.info(f"â³ {vendor}ç¡¬ä»¶å·²æ£€æµ‹ï¼Œç­‰å¾…æŸ¥è¯¢ä»¥è¿›è¡Œä¼˜åŒ–")
                        
                        # æ˜¾ç¤ºæ£€æµ‹åˆ°çš„ç¡¬ä»¶ä¿¡æ¯ï¼ˆä½†ä¸æ˜¾ç¤ºæ€§èƒ½æŒ‡æ ‡ï¼‰
                        hw_info = optimization_status.get('hardware_info', {})
                        if hw_info:
                            st.caption(f"ğŸ’» æ£€æµ‹åˆ°: {hw_info.get('cpu_model', 'Unknown')[:30]}...")
                            
                            # æ˜¾ç¤ºç¡¬ä»¶ç‰¹æ€§ï¼ˆæ£€æµ‹ç»“æœï¼‰
                            features = []
                            if hw_info.get('cpu_cores', 0) > 0:
                                features.append(f"{hw_info['cpu_cores']}æ ¸")
                            if hw_info.get('has_avx2'):
                                features.append("AVX2æ”¯æŒ")
                            
                            # GPUæ£€æµ‹ç»“æœ
                            gpu_features = []
                            if hw_info.get('has_intel_gpu'):
                                gpu_features.append("Intel GPU")
                            if hw_info.get('has_nvidia_gpu'):
                                gpu_features.append("NVIDIA GPU")
                            if hw_info.get('has_amd_gpu'):
                                gpu_features.append("AMD GPU")
                            if hw_info.get('has_cuda'):
                                gpu_features.append("CUDAæ”¯æŒ")
                            
                            if features:
                                st.caption(f"ğŸ”§ CPUç‰¹æ€§: {' | '.join(features)}")
                            if gpu_features:
                                st.caption(f"ğŸ® GPUç‰¹æ€§: {' | '.join(gpu_features)}")
                            
                            st.caption("ğŸ’¡ å¼€å§‹æŸ¥è¯¢åå°†æ˜¾ç¤ºå®é™…ä¼˜åŒ–æ•ˆæœ")
                    
                    # é€šç”¨ç¡¬ä»¶ä¿¡æ¯æ˜¾ç¤ºï¼ˆä¼˜åŒ–åçš„è¯¦ç»†ä¿¡æ¯ï¼‰
                    if optimization_status['optimized']:
                        hw_info = optimization_status.get('hardware_info', {})
                        
                        # æ ¹æ®ç¡¬ä»¶å‚å•†æ˜¾ç¤ºä¸åŒçš„ç‰¹æ€§
                        features = []
                        if hw_info.get('cpu_cores', 0) > 0:
                            features.append(f"{hw_info['cpu_cores']}æ ¸")
                        if hw_info.get('has_avx2'):
                            features.append("AVX2: âœ…")
                        else:
                            features.append("AVX2: âŒ")
                        
                        # GPUç‰¹æ€§æ˜¾ç¤º
                        gpu_features = []
                        if hw_info.get('has_intel_gpu'):
                            gpu_features.append("Intel GPU: âœ…")
                        if hw_info.get('has_nvidia_gpu'):
                            gpu_features.append("NVIDIA GPU: âœ…")
                        if hw_info.get('has_amd_gpu'):
                            gpu_features.append("AMD GPU: âœ…")
                        if hw_info.get('has_cuda'):
                            gpu_features.append("CUDA: âœ…")
                        
                        if features:
                            st.caption(f"ğŸ”§ {' | '.join(features)}")
                        if gpu_features:
                            st.caption(f"ğŸ® {' | '.join(gpu_features)}")
                            
                else:
                    st.warning(f"âš ï¸ {vendor}ä¼˜åŒ–å™¨æœªå¯ç”¨")
                    
            except Exception as e:
                st.error(f"ç¡¬ä»¶ä¼˜åŒ–é¢æ¿é”™è¯¯: {e}")
    else:
        with st.expander("âš ï¸ ç¡¬ä»¶ä¼˜åŒ–ä¸å¯ç”¨", expanded=False):
            st.warning("ç¡¬ä»¶ä¼˜åŒ–æ¨¡å—æœªæ­£ç¡®åŠ è½½ï¼Œè¯·æ£€æŸ¥ä¾èµ–é¡¹")
    
    # æŠ€æœ¯å“è¶Šæ€§é¢æ¿ - å‰ç«¯UIå·²ç¦ç”¨ï¼ˆç”¨æˆ·è¦æ±‚ç•Œé¢ç®€æ´ï¼‰
    if TECHNICAL_EXCELLENCE_AVAILABLE and TECHNICAL_EXCELLENCE_UI_ENABLED:
        with st.expander("ğŸ† æŠ€æœ¯å“è¶Šæ€§çŠ¶æ€", expanded=False):
            try:
                tech_status = tech_manager.get_technical_status()
                
                # æ€»ä½“çŠ¶æ€
                if tech_status.overall_score >= 80:
                    st.success(f"ğŸ¯ æŠ€æœ¯è¯„åˆ†: {tech_status.overall_score:.1f}% ({tech_status.maturity_level})")
                elif tech_status.overall_score >= 60:
                    st.info(f"ğŸ“Š æŠ€æœ¯è¯„åˆ†: {tech_status.overall_score:.1f}% ({tech_status.maturity_level})")
                else:
                    st.warning(f"âš ï¸ æŠ€æœ¯è¯„åˆ†: {tech_status.overall_score:.1f}% ({tech_status.maturity_level})")
                
                # æ¨¡å—çŠ¶æ€
                col1, col2 = st.columns(2)
                with col1:
                    intel_status = "âœ…" if tech_status.intel_integration else "âŒ"
                    st.caption(f"ğŸš€ Intelé›†æˆ: {intel_status}")
                    
                    arch_status = "âœ…" if tech_status.enterprise_architecture else "âŒ"
                    st.caption(f"ğŸ—ï¸ ä¼ä¸šæ¶æ„: {arch_status}")
                
                with col2:
                    perf_status = "âœ…" if tech_status.adaptive_performance else "âŒ"
                    st.caption(f"âš¡ æ€§èƒ½ä¼˜åŒ–: {perf_status}")
                    
                    st.caption(f"ğŸ”„ ä¼˜åŒ–æ¬¡æ•°: {tech_manager.operation_count}")
                
                # ä¼˜åŒ–å»ºè®®
                recommendations = get_technical_recommendations()
                if recommendations and len(recommendations) > 0:
                    st.caption("ğŸ’¡ ä¼˜åŒ–å»ºè®®:")
                    for rec in recommendations[:2]:  # åªæ˜¾ç¤ºå‰2ä¸ªå»ºè®®
                        st.caption(f"â€¢ {rec}")
                        
            except Exception as e:
                st.error(f"æŠ€æœ¯å“è¶Šæ€§é¢æ¿é”™è¯¯: {e}")
    # UIé¢æ¿è¢«ç¦ç”¨ï¼Œä½†åç«¯åŠŸèƒ½ç»§ç»­å·¥ä½œ
    
    # æ€§èƒ½è¶‹åŠ¿å›¾
    with st.expander("ğŸ“ˆ æ€§èƒ½è¶‹åŠ¿", expanded=False):
        trend_hours = st.selectbox("æ—¶é—´èŒƒå›´", [1, 3, 6, 12, 24], index=0, key="trend_hours")
        if st.button("åˆ·æ–°è¶‹åŠ¿å›¾", use_container_width=True):
            trend_fig = performance_monitor.create_performance_trend_chart(trend_hours)
            if trend_fig:
                # ç”Ÿæˆå”¯ä¸€çš„å›¾è¡¨keyï¼ŒåŒ…å«æ—¶é—´èŒƒå›´å‚æ•°
                chart_key = generate_sidebar_chart_key("performance_trend", f"{trend_hours}h")
                st.plotly_chart(trend_fig, use_container_width=True, key=chart_key)
            else:
                st.info("æš‚æ— è¶³å¤Ÿçš„å†å²æ•°æ®ç”Ÿæˆè¶‹åŠ¿å›¾")



    with st.expander("ğŸ§  æ¨¡å‹è®¾ç½®", expanded=False):
        st.markdown("**ğŸ”§ SQLç”ŸæˆAPIé…ç½®**")
        api_url = st.text_input("API URL", st.session_state.config["api_base"])
        api_key = st.text_input("API Key", st.session_state.config["api_key"], type="password")
        model = st.text_input("ç”Ÿæˆæ¨¡å‹ (LLM)", st.session_state.config["model_name"])
        
        st.markdown("**ğŸ¤– æ¨èå¼•æ“è®¾ç½®**")
        enable_ai_recommendations = st.checkbox(
            "å¯ç”¨AIæ™ºèƒ½æ¨è", 
            value=st.session_state.config.get("enable_ai_recommendations", True),
            help="å¯ç”¨åå¯ä»¥ä½¿ç”¨AIç”Ÿæˆæ™ºèƒ½é—®é¢˜æ¨è"
        )
        
        if enable_ai_recommendations:
            use_separate_api = st.checkbox(
                "ä½¿ç”¨ç‹¬ç«‹çš„æ¨èAPIé…ç½®",
                value=st.session_state.config.get("recommendation_use_separate_api", False),
                help="å¯ç”¨åæ¨èåŠŸèƒ½å°†ä½¿ç”¨ç‹¬ç«‹çš„APIé…ç½®ï¼Œå¦åˆ™ä¸SQLç”Ÿæˆå…±ç”¨ä¸Šè¿°API"
            )
            
            if use_separate_api:
                st.markdown("**ğŸ“¡ æ¨èAPIç‹¬ç«‹é…ç½®**")
                rec_api_url = st.text_input(
                    "æ¨èAPI URL", 
                    st.session_state.config.get("recommendation_api_base", "https://api.deepseek.com")
                )
                rec_api_key = st.text_input(
                    "æ¨èAPI Key", 
                    st.session_state.config.get("recommendation_api_key", ""), 
                    type="password"
                )
                rec_model = st.text_input(
                    "æ¨èæ¨¡å‹åç§°", 
                    st.session_state.config.get("recommendation_model_name", "deepseek-reasoner")
                )
            else:
                st.info("ğŸ’¡ æ¨èåŠŸèƒ½å°†ä½¿ç”¨ä¸Šè¿°SQLç”Ÿæˆçš„APIé…ç½®")
                rec_api_url = api_url
                rec_api_key = api_key
                rec_model = model
        else:
            st.info("ğŸ’¡ ç¦ç”¨åå°†ä½¿ç”¨åŸºäºè§„åˆ™çš„å¤‡ç”¨æ¨è")
            use_separate_api = False
            rec_api_url = ""
            rec_api_key = ""
            rec_model = ""
        
        st.markdown("**ğŸ“ RAGæ¨¡å‹é…ç½®**")
        rag_path = st.text_input("RAG æ¨¡å‹è·¯å¾„", st.session_state.config.get("model_path", "models/bge-small-ov"))

    with st.expander("ğŸ—„ï¸ æ•°æ®åº“è¿æ¥", expanded=False):
        # æ£€æµ‹æ•°æ®åº“ç±»å‹æ˜¯å¦å‘ç”Ÿå˜åŒ–
        current_db_type = st.session_state.config.get("db_type", "SQLite")
        db_type_options = ["SQLite", "MySQL"]
        current_index = db_type_options.index(current_db_type) if current_db_type in db_type_options else 0
        
        db_type = st.selectbox("ç±»å‹", db_type_options, index=current_index, key="db_type_selector")
        
        # æ£€æµ‹æ•°æ®åº“ç±»å‹åˆ‡æ¢
        if db_type != current_db_type:
            # æ•°æ®åº“ç±»å‹å‘ç”Ÿå˜åŒ–ï¼Œæ›´æ–°session_stateä»¥è§¦å‘ç•Œé¢åˆ·æ–°
            st.session_state.config["db_type"] = db_type
            st.rerun()
        
        final_uris = []
        db_path_val = ""
        
        if db_type == "SQLite":
            # ä»åˆ†ç¦»çš„SQLiteé…ç½®ä¸­è·å–é»˜è®¤å€¼
            sqlite_config = st.session_state.config.get("sqlite_config", {})
            default_sqlite_path = sqlite_config.get("db_path", "data/ecommerce.db")
            
            db_path_val = st.text_area("æ–‡ä»¶è·¯å¾„", value=default_sqlite_path)
            for p in db_path_val.split('\n'):
                if p.strip(): final_uris.append(f"sqlite:///{p.strip()}")
        else:
            # MySQLé…ç½® - ä»åˆ†ç¦»çš„MySQLé…ç½®ä¸­è·å–é»˜è®¤å€¼
            mysql_config = st.session_state.config.get("mysql_config", {})
            default_host = mysql_config.get("host", "localhost")
            default_port = mysql_config.get("port", "3306")
            default_user = mysql_config.get("user", "root")
            default_password = mysql_config.get("password", "")
            default_db_name = mysql_config.get("database", "ecommerce")
            
            c1, c2 = st.columns(2)
            host = c1.text_input("Host", value=default_host)
            port = c2.text_input("Port", value=default_port)
            user = c1.text_input("User", value=default_user)
            pwd = c2.text_input("Password", value=default_password, type="password")
            db_name = st.text_input("DB Name", value=default_db_name)
            
            # MySQLè¿æ¥æµ‹è¯•æŒ‰é’®
            if st.button("ğŸ”§ æµ‹è¯•MySQLè¿æ¥", use_container_width=True):
                if host and port and user and db_name:
                    with st.spinner("æ­£åœ¨æµ‹è¯•MySQLè¿æ¥..."):
                        try:
                            # å¯¼å…¥æµ‹è¯•å‡½æ•°
                            import sys
                            sys.path.append('.')
                            from test_mysql_connection import test_mysql_connection
                            
                            result = test_mysql_connection(host, int(port), user, pwd, db_name)
                            
                            if result["success"]:
                                st.success("âœ… MySQLè¿æ¥æµ‹è¯•æˆåŠŸï¼")
                                details = result["details"]
                                st.info(f"MySQLç‰ˆæœ¬: {details.get('mysql_version', 'N/A')}")
                                st.info(f"æ•°æ®åº“: {details.get('current_database', 'N/A')}")
                                st.info(f"è¡¨æ•°é‡: {details.get('table_count', 0)}")
                                if details.get('tables'):
                                    st.info(f"è¡¨åˆ—è¡¨: {', '.join(details['tables'][:5])}{'...' if len(details['tables']) > 5 else ''}")
                            else:
                                st.error(f"âŒ MySQLè¿æ¥å¤±è´¥: {result['message']}")
                                if result.get('details', {}).get('suggestions'):
                                    st.warning("ğŸ’¡ å»ºè®®è§£å†³æ–¹æ¡ˆ:")
                                    for suggestion in result['details']['suggestions']:
                                        st.write(f"â€¢ {suggestion}")
                                        
                        except ImportError:
                            st.error("âŒ ç¼ºå°‘ä¾èµ–åº“ï¼Œè¯·å®‰è£…: pip install pymysql sqlalchemy")
                        except Exception as e:
                            st.error(f"âŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}")
                else:
                    st.warning("âš ï¸ è¯·å¡«å†™å®Œæ•´çš„MySQLè¿æ¥ä¿¡æ¯")
            
            if host and db_name:
                uri = f"mysql+pymysql://{user}:{pwd}@{host}:{port}/{db_name}"
                final_uris = [uri]; db_path_val = uri 

    with st.expander("ğŸ“š çŸ¥è¯†ä¸ç­–ç•¥", expanded=False):
        # æ ¹æ®å½“å‰æ•°æ®åº“ç±»å‹è‡ªåŠ¨é€‚é…çŸ¥è¯†åº“é…ç½®
        current_db_type = st.session_state.config.get("db_type", "SQLite")
        
        if current_db_type == "SQLite":
            sqlite_config = st.session_state.config.get("sqlite_config", {})
            default_schema_path = sqlite_config.get("schema_path", "data/schema_northwind.json")
            st.info("ğŸ’¡ å½“å‰ä½¿ç”¨SQLiteæ•°æ®åº“ï¼Œå»ºè®®ä½¿ç”¨JSONæ ¼å¼çš„Schemaæ–‡ä»¶")
            help_text = "SQLite: æ¨èä½¿ç”¨JSONæ ¼å¼çš„Schemaæ–‡ä»¶ï¼ˆå¦‚data/schema_northwind.jsonï¼‰"
        else:
            mysql_config = st.session_state.config.get("mysql_config", {})
            default_schema_path = mysql_config.get("schema_path", "")
            st.info("ğŸ’¡ å½“å‰ä½¿ç”¨MySQLæ•°æ®åº“ï¼Œå¯ä»¥ç•™ç©ºè®©ç³»ç»Ÿè‡ªåŠ¨ä»æ•°æ®åº“è·å–Schema")
            help_text = "MySQL: å¯ç•™ç©ºè‡ªåŠ¨è·å–Schemaï¼Œæˆ–æŒ‡å®šè‡ªå®šä¹‰Schemaæ–‡ä»¶"
        
        # ä½¿ç”¨keyå‚æ•°ç¡®ä¿åœ¨æ•°æ®åº“ç±»å‹åˆ‡æ¢æ—¶é‡æ–°æ¸²æŸ“
        kb_input = st.text_area(
            "çŸ¥è¯†åº“è·¯å¾„", 
            value=default_schema_path,
            help=help_text,
            key=f"kb_input_{current_db_type}"  # å…³é”®ï¼šä½¿ç”¨æ•°æ®åº“ç±»å‹ä½œä¸ºkeyçš„ä¸€éƒ¨åˆ†
        )
        
        uploaded_files = st.file_uploader("ä¸Šä¼ æ–‡ä»¶", accept_multiple_files=True)
        log_path = st.text_input("æ—¥å¿—è·¯å¾„", st.session_state.config.get("log_file", "data/agent.log"))
        max_retries = st.slider("æœ€å¤§é‡è¯•", 1, 10, st.session_state.config.get("max_retries", 3))
        max_candidates = st.slider("å¯èƒ½æ€§æ¢ç´¢ (æ¡)", 1, 5, st.session_state.config.get("max_candidates", 3))
        
        # æ–°å¢ï¼šç©ºç»“æœå¤„ç†é…ç½®
        st.markdown("**ç©ºç»“æœå¤„ç†ç­–ç•¥**")
        allow_empty_results = st.checkbox(
            "å…è®¸SQLæŸ¥è¯¢ç»“æœä¸ºç©º", 
            value=st.session_state.config.get("allow_empty_results", True),
            help="å¦‚æœç¦ç”¨ï¼Œå½“æŸ¥è¯¢ç»“æœä¸ºç©ºæ—¶å°†æ ¹æ®é‡è¯•æœºåˆ¶è‡ªåŠ¨é‡è¯•"
        )

    if st.button("ğŸ’¾ ä¿å­˜é…ç½®", type="primary", use_container_width=True):
        saved_paths = []
        if uploaded_files:
            os.makedirs("data/uploads", exist_ok=True)
            for uf in uploaded_files:
                path = f"data/uploads/{uf.name}"
                with open(path, "wb") as f: f.write(uf.getbuffer())
                saved_paths.append(path)
        kb_paths = list(set([p.strip() for p in kb_input.split('\n') if p.strip()] + saved_paths))
        
        # æ›´æ–°åŸºç¡€é…ç½®
        st.session_state.config.update({
            "api_base": api_url, "api_key": api_key, "model_name": model,
            "db_type": db_type, "db_path": db_path_val, "db_uris": final_uris,
            "schema_path": "\n".join(kb_paths), "kb_paths_list": kb_paths,
            "model_path": rag_path, "log_file": log_path,
            "max_retries": max_retries, "max_candidates": max_candidates,
            "allow_empty_results": allow_empty_results,
            "enable_ai_recommendations": enable_ai_recommendations,
            "recommendation_use_separate_api": use_separate_api,
            "recommendation_api_base": rec_api_url,
            "recommendation_api_key": rec_api_key,
            "recommendation_model_name": rec_model
        })
        
        # åˆ†åˆ«ä¿å­˜SQLiteå’ŒMySQLçš„é…ç½®
        if db_type == "SQLite":
            st.session_state.config["sqlite_config"] = {
                "db_path": db_path_val,
                "schema_path": "\n".join(kb_paths)
            }
        else:  # MySQL
            st.session_state.config["mysql_config"] = {
                "host": host,
                "port": port,
                "user": user,
                "password": pwd,
                "database": db_name,
                "schema_path": "\n".join(kb_paths)
            }
        
        save_config(st.session_state.config)
        st.success("âœ… é…ç½®å·²ä¿å­˜ï¼æ•°æ®åº“é…ç½®å·²åˆ†åˆ«ä¿å­˜ï¼Œåˆ‡æ¢æ•°æ®åº“ç±»å‹æ—¶ä¼šè‡ªåŠ¨æ¢å¤å¯¹åº”é…ç½®ã€‚")
        st.cache_resource.clear(); st.rerun()

    st.markdown("---")
    st.markdown("### ğŸ’¬ ä¼šè¯ç®¡ç†")
    ids = list(st.session_state.history.keys())[::-1]
    titles = [st.session_state.history[i]["title"] for i in ids]
    try: curr_idx = ids.index(st.session_state.current_session_id)
    except ValueError: curr_idx = 0
    sel = st.selectbox("å†å²è®°å½•", titles, index=curr_idx, key="history_selector")
    if sel:
        tid = ids[titles.index(sel)]
        if tid != st.session_state.current_session_id:
            st.session_state.current_session_id = tid
            st.rerun()
    
    # ä¼šè¯æ“ä½œæŒ‰é’®
    c1, c2 = st.columns(2)
    if c1.button("â• æ–°å»º", use_container_width=True):
        sid, hist = create_new_session(st.session_state.history)
        st.session_state.history = hist
        st.session_state.current_session_id = sid
        st.rerun()
    if c2.button("ğŸ—‘ï¸ åˆ é™¤", type="secondary", use_container_width=True):
        hist = delete_session(st.session_state.history, st.session_state.current_session_id)
        st.session_state.history = hist
        if not st.session_state.history:
            sid, hist = create_new_session(st.session_state.history)
            st.session_state.history = hist
            st.session_state.current_session_id = sid
        else: st.session_state.current_session_id = list(st.session_state.history.keys())[0]
        st.rerun()
    
    # åˆ†äº«å’Œå¯¼å‡ºåŠŸèƒ½
    st.markdown("#### ğŸ“¤ åˆ†äº«ä¸å¯¼å‡º")
    current_session = st.session_state.history.get(st.session_state.current_session_id, {})
    has_messages = len(current_session.get("messages", [])) > 0
    
    if has_messages:
        # PDFæŠ¥å‘Šå¯¼å‡º
        if st.button("ğŸ“„ å¯¼å‡ºPDFæŠ¥å‘Š", use_container_width=True):
            with st.spinner("æ­£åœ¨ç”ŸæˆPDFæŠ¥å‘Š..."):
                pdf_path = export_manager.export_session_to_pdf(
                    current_session, 
                    current_session.get("title", "åˆ†ææŠ¥å‘Š")
                )
                if pdf_path:
                    st.success("PDFæŠ¥å‘Šç”ŸæˆæˆåŠŸï¼")
                    # æä¾›ä¸‹è½½é“¾æ¥
                    with open(pdf_path, "rb") as pdf_file:
                        st.download_button(
                            label="â¬‡ï¸ ä¸‹è½½PDFæŠ¥å‘Š",
                            data=pdf_file.read(),
                            file_name=os.path.basename(pdf_path),
                            mime="application/pdf",
                            use_container_width=True
                        )
                else:
                    st.error("PDFç”Ÿæˆå¤±è´¥ï¼Œè¯·å®‰è£…reportlabåº“")
        
        # DOCXæŠ¥å‘Šå¯¼å‡º
        if st.button("ğŸ“ å¯¼å‡ºWordæŠ¥å‘Š", use_container_width=True):
            with st.spinner("æ­£åœ¨ç”ŸæˆWordæŠ¥å‘Š..."):
                docx_path = export_manager.export_session_to_docx(
                    current_session, 
                    current_session.get("title", "åˆ†ææŠ¥å‘Š")
                )
                if docx_path:
                    st.success("WordæŠ¥å‘Šç”ŸæˆæˆåŠŸï¼")
                    # æä¾›ä¸‹è½½é“¾æ¥
                    with open(docx_path, "rb") as docx_file:
                        st.download_button(
                            label="â¬‡ï¸ ä¸‹è½½WordæŠ¥å‘Š",
                            data=docx_file.read(),
                            file_name=os.path.basename(docx_path),
                            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                            use_container_width=True
                        )
                else:
                    st.error("Wordç”Ÿæˆå¤±è´¥ï¼Œè¯·å®‰è£…python-docxåº“")
        
        # åˆ›å»ºåˆ†äº«é“¾æ¥
        if st.button("ğŸ”— åˆ›å»ºåˆ†äº«é“¾æ¥", use_container_width=True):
            share_id = export_manager.create_shareable_session(
                current_session, 
                st.session_state.current_session_id
            )
            if share_id:
                share_url = f"åˆ†äº«ID: {share_id}"
                st.success("åˆ†äº«é“¾æ¥åˆ›å»ºæˆåŠŸï¼")
                st.code(share_url, language="text")
                st.info("ğŸ’¡ å…¶ä»–ç”¨æˆ·å¯ä»¥ä½¿ç”¨æ­¤åˆ†äº«IDæŸ¥çœ‹æ‚¨çš„åˆ†æç»“æœ")
            else:
                st.error("åˆ†äº«é“¾æ¥åˆ›å»ºå¤±è´¥")
    else:
        st.info("ğŸ’¡ å¼€å§‹å¯¹è¯åå¯ä½¿ç”¨åˆ†äº«å’Œå¯¼å‡ºåŠŸèƒ½")

# --- åŠ¨æ€ç›‘æ§åˆ·æ–°å‡½æ•° ---
def update_monitor():
    cpu = psutil.cpu_percent()
    mem = psutil.virtual_memory().percent
    total_lat = st.session_state.last_total_latency
    rag_lat = st.session_state.last_rag_latency
    lat_color = "#28a745" if total_lat < 1000 else "#ffc107" if total_lat < 3000 else "#dc3545"
    
    # æ”¶é›†å¹¶ä¿å­˜æ€§èƒ½æŒ‡æ ‡
    current_metrics = performance_monitor.collect_current_metrics(rag_lat, total_lat)
    if current_metrics:
        performance_monitor.save_metrics(current_metrics)
    
    # æ£€æµ‹å¼‚å¸¸
    anomalies = performance_monitor.detect_anomalies(current_metrics)
    suggestions = performance_monitor.get_optimization_suggestions(current_metrics, anomalies)
    
    # è·å–æ€§èƒ½æ‘˜è¦
    summary = performance_monitor.get_performance_summary()
    
    # æ„å»ºç›‘æ§é¢æ¿å†…å®¹ - åªæ˜¾ç¤ºåŸºæœ¬æ€§èƒ½æŒ‡æ ‡
    summary_content = ""
    if summary:
        avg_cpu = summary.get('avg_cpu', 0)
        total_queries = summary.get('total_queries', 0)
        summary_content = f"ğŸ“ˆ **1å°æ—¶æ‘˜è¦**: å¹³å‡CPU: {avg_cpu}% | æŸ¥è¯¢æ•°: {total_queries}"
    
    # ä½¿ç”¨StreamlitåŸç”Ÿç»„ä»¶æ˜¾ç¤ºåŸºæœ¬æ€§èƒ½æŒ‡æ ‡
    with monitor_placeholder.container():
        st.markdown("**ğŸ“Š å®æ—¶æ€§èƒ½ç›‘æ§**")
        
        # æ€§èƒ½æŒ‡æ ‡
        col1, col2 = st.columns(2)
        with col1:
            st.metric("CPU å ç”¨", f"{cpu}%")
            st.metric("OpenVINO", f"{rag_lat:.1f} ms")
        with col2:
            st.metric("å†…å­˜å ç”¨", f"{mem}%")
            st.metric("ç«¯åˆ°ç«¯å»¶è¿Ÿ", f"{total_lat:.0f} ms")
        
        # åªæ˜¾ç¤ºæ‘˜è¦ä¿¡æ¯ï¼Œä¸æ˜¾ç¤ºè­¦å‘Šå’Œå»ºè®®
        if summary_content:
            st.caption(summary_content)

update_monitor()

# --- æ¨èå¼•æ“å®¢æˆ·ç«¯åˆ›å»ºå‡½æ•° ---
@st.cache_resource
def get_recommendation_client(cfg):
    """è·å–æ¨èå¼•æ“çš„LLMå®¢æˆ·ç«¯"""
    if not cfg.get("enable_ai_recommendations", True):
        return None, None, "AIæ¨èå·²ç¦ç”¨"
    
    # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ç‹¬ç«‹çš„æ¨èAPIé…ç½®
    use_separate_api = cfg.get("recommendation_use_separate_api", False)
    
    if use_separate_api:
        # ä½¿ç”¨ç‹¬ç«‹çš„æ¨èAPIé…ç½®
        api_key = cfg.get("recommendation_api_key", "")
        api_base = cfg.get("recommendation_api_base", "https://api.deepseek.com")
        model_name = cfg.get("recommendation_model_name", "deepseek-reasoner")
        
        if not api_key:
            return None, None, "æ¨èAPI Keyæœªé…ç½®"
    else:
        # ä½¿ç”¨SQLç”Ÿæˆçš„APIé…ç½®
        api_key = cfg.get("api_key", "")
        api_base = cfg.get("api_base", "https://api.deepseek.com")
        model_name = cfg.get("model_name", "deepseek-reasoner")
        
        if not api_key:
            return None, None, "API Keyæœªé…ç½®"
    
    try:
        from openai import OpenAI
        import httpx
        
        # å¤„ç†URLæ ¼å¼
        clean_url = api_base.rstrip('/')
        if not clean_url.endswith('/v1'):
            clean_url += "/v1"
        
        client = create_openai_client_safe(api_key, clean_url, 60.0)
        
        return client, model_name, None
        
    except Exception as e:
        return None, None, f"æ¨èå®¢æˆ·ç«¯åˆ›å»ºå¤±è´¥: {str(e)}"

# --- æ‡’åŠ è½½ Agent ---
@st.cache_resource
def get_agent(cfg):
    if not cfg["api_key"]: return None, "è¯·é…ç½® API Key"
    try:
        rag = IntelRAG(model_path=cfg.get("model_path"), db_uris=cfg.get("db_uris", []), kb_paths=cfg.get("kb_paths_list", []))
        
        agent = Text2SQLAgent(
            api_key=cfg["api_key"], base_url=cfg["api_base"], model_name=cfg["model_name"], 
            db_uris=cfg.get("db_uris", []), rag_engine=rag, 
            max_retries=cfg.get("max_retries", 3), max_candidates=cfg.get("max_candidates", 1),
            log_file=cfg.get("log_file", "data/agent.log"),
            config=cfg  # ğŸ§  ä¼ é€’å®Œæ•´é…ç½®ç»™Promptæ¨¡æ¿ç³»ç»Ÿ
        )
        
        return agent, None
    except Exception as e: return None, str(e)

# --- é¡µé¢ä¸»é€»è¾‘ ---
current_data = st.session_state.history[st.session_state.current_session_id]
messages = current_data["messages"]

# å¤„ç†æŒ‰é’®è¾“å…¥
prompt_input = None
if st.session_state.prompt_trigger:
    prompt_input = st.session_state.prompt_trigger
    st.session_state.prompt_trigger = None
elif user_input := st.chat_input("è¾“å…¥ä¸šåŠ¡é—®é¢˜ (æ”¯æŒä¸­è‹±æ–‡)..."):
    prompt_input = user_input

# --- æ¬¢è¿é¡µ ---
if len(messages) == 0:
    # ä¸»æ ‡é¢˜åŒºåŸŸ - æ•´ä½“ä¸Šç§»å¹¶ç¾åŒ–
    st.markdown("""
    <div style="text-align: center; margin-top: -10px; margin-bottom: 25px;">
        <h1 style="color: #0068B5; margin: 0; font-weight: 600; font-size: 2.8rem; letter-spacing: -0.5px;">IntelÂ® DeepInsight</h1>
        <p style="font-size: 1.1em; color: #666; margin-top: 12px; line-height: 1.6;">
            åŸºäº OpenVINOâ„¢ çš„æœ¬åœ°åŒ–æ™ºèƒ½é›¶å”®å†³ç­–ç³»ç»Ÿ<br>
            <span style="font-size: 0.85em; color: #888; font-weight: 500;">å…¨æœ¬åœ°è¿è¡Œ Â· éšç§å®‰å…¨ Â· æé€Ÿæ¨ç†</span>
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    # æ˜¾ç¤ºä¸Šä¸‹æ–‡è®°å¿†çŠ¶æ€ - ä½¿ç”¨æœ€æ–°çš„çŠ¶æ€
    if CONTEXT_MEMORY_AVAILABLE:
        current_memory_enabled = st.session_state.get('context_memory_enabled', True)
        if current_memory_enabled:
            st.markdown("""
            <div class="context-status">
                ğŸ§  <strong>ä¸Šä¸‹æ–‡è®°å¿†å·²å¯ç”¨</strong> - AIå°†è®°ä½å¯¹è¯å†å²ï¼Œæä¾›æ›´æ™ºèƒ½çš„å›å¤
            </div>
            """, unsafe_allow_html=True)
        else:
            st.markdown("""
            <div class="context-status context-disabled">
                ğŸ’­ <strong>ä¸Šä¸‹æ–‡è®°å¿†å·²ç¦ç”¨</strong> - AIå°†ä¸ä¼šè®°ä½å¯¹è¯å†å²
            </div>
            """, unsafe_allow_html=True)
    
    # æ™ºèƒ½æ¨èé—®é¢˜æ ‡é¢˜ - ä¼˜åŒ–æ ·å¼
    st.markdown("""
    <div style="margin-bottom: 20px;">
        <h4 style="color: #333; font-weight: 600; margin-bottom: 15px; display: flex; align-items: center;">
            <span style="margin-right: 8px;">ğŸ’¡</span>æ™ºèƒ½æ¨èé—®é¢˜ï¼š
        </h4>
    </div>
    """, unsafe_allow_html=True)
    
    # ä½¿ç”¨å›ºå®šçš„ç¤ºä¾‹é—®é¢˜
    c1, c2, c3, c4 = st.columns(4)
    
    with c1:
        if st.button("ğŸ† 2016å¹´é”€å”®é¢æœ€é«˜çš„5ä¸ªåŸå¸‚æ˜¯å“ªé‡Œï¼Ÿ", use_container_width=True):
            st.session_state.prompt_trigger = "2016å¹´é”€å”®é¢æœ€é«˜5ä¸ªçš„åŸå¸‚æ˜¯å“ªé‡Œ"
            st.rerun()
    with c2:
        if st.button("ğŸ“Š å®¶å…·ç±»äº§å“çš„å¹³å‡åˆ©æ¶¦ç‡æ˜¯å¤šå°‘ï¼Ÿ", use_container_width=True):
            st.session_state.prompt_trigger = "å®¶å…·ç±»äº§å“çš„å¹³å‡åˆ©æ¶¦ç‡æ˜¯å¤šå°‘"
            st.rerun()
    with c3:
        if st.button("ğŸ“ˆ åº“å­˜ç§¯å‹æœ€ä¸¥é‡çš„TOP5äº§å“æ˜¯ï¼Ÿ", use_container_width=True):
            st.session_state.prompt_trigger = "åº“å­˜ç§¯å‹æœ€ä¸¥é‡çš„TOP5äº§å“æ˜¯ï¼Ÿ"
            st.rerun()
    with c4:
        if st.button("ğŸ’» å‘Šè¯‰æˆ‘ï¼Œå“ªå‡ ä¸ªäº§å“å†³å®šäº†æˆ‘ä»¬çš„ç”Ÿæ­»ï¼Ÿ", use_container_width=True):
            st.session_state.prompt_trigger = "å‘Šè¯‰æˆ‘ï¼Œå“ªå‡ ä¸ªäº§å“å†³å®šäº†æˆ‘ä»¬çš„ç”Ÿæ­»ï¼Ÿ"
            st.rerun()

# --- å†å²æ¶ˆæ¯æ¸²æŸ“ (ğŸ”¥ ç»Ÿä¸€æ¸²æŸ“é€»è¾‘ï¼šç¡®ä¿æ‰€æœ‰æ ‡é¢˜å¸¸é©») ---
for msg_index, msg in enumerate(messages):
    with st.chat_message(msg["role"], avatar="ğŸ§‘â€ğŸ’»" if msg["role"]=="user" else "ğŸ¤–"):
        # 1. æ€è€ƒè¿‡ç¨‹ (å¦‚æœ‰)
        if "thought" in msg and msg["thought"]:
            # è·å–é…ç½®çš„æ¨¡å‹åç§°ç”¨äºæ˜¾ç¤º
            model_display_name = st.session_state.config.get("model_name", "AIæ¨¡å‹")
            with st.expander(f"ğŸ¤” æ€è€ƒè¿‡ç¨‹ ({model_display_name})", expanded=False):
                st.markdown(f"<div class='thought-persist'>{msg['thought']}</div>", unsafe_allow_html=True)
        
        # åˆ¤æ–­æ¶ˆæ¯ç±»å‹
        is_sql_result = "data" in msg and msg["data"] is not None
        
        if is_sql_result:
            # === ç±»å‹ A: æ•°æ®æŸ¥è¯¢ç»“æœ (ä¿æŒæ ‡é¢˜é¡ºåº) ===
            
            # 0. è¡¨é€‰æ‹©è¿‡ç¨‹ä¿¡æ¯æŒä¹…åŒ–æ˜¾ç¤º (å†å²æ¶ˆæ¯)
            if "table_selection_info" in msg and msg["table_selection_info"]:
                table_info = msg["table_selection_info"]
                if any(table_info.values()):
                    with st.expander("ğŸ—„ï¸ æ™ºèƒ½è¡¨é€‰æ‹©è¿‡ç¨‹", expanded=False):
                        st.markdown("**ğŸ“‹ è¡¨é€‰æ‹©è¯¦ç»†è¿‡ç¨‹**")
                        
                        # æ˜¾ç¤ºåˆæ­¥ç­›é€‰ç»“æœ
                        if table_info.get("initial_analysis"):
                            st.markdown("**ç¬¬1æ­¥ï¼šè¯­ä¹‰ç›¸ä¼¼åº¦åˆæ­¥ç­›é€‰**")
                            st.info(table_info["initial_analysis"])
                        
                        # æ˜¾ç¤ºAgentæ¨ç†è¿‡ç¨‹
                        if table_info.get("agent_reasoning"):
                            st.markdown("**ç¬¬2æ­¥ï¼šAgentæ™ºèƒ½ç­›é€‰æ¨ç†**")
                            st.success(f"ğŸ§  æ¨ç†è¿‡ç¨‹: {table_info['agent_reasoning']}")
                        
                        # æ˜¾ç¤ºå…³è”åˆ†æ
                        if table_info.get("join_analysis"):
                            st.markdown("**ç¬¬3æ­¥ï¼šè¡¨å…³è”å…³ç³»åˆ†æ**")
                            st.info(table_info["join_analysis"])
                        
                        # æ˜¾ç¤ºæœ€ç»ˆé€‰æ‹©ç»“æœ
                        if table_info.get("final_selection"):
                            final_selection = table_info["final_selection"]
                            selected_tables = final_selection.get("selected_tables", [])
                            analysis = final_selection.get("analysis", {})
                            
                            st.markdown("**ğŸ¯ æœ€ç»ˆé€‰æ‹©ç»“æœ**")
                            
                            if selected_tables:
                                # æ˜¾ç¤ºé€‰æ‹©æ¨ç†
                                selection_reasoning = analysis.get("selection_reasoning", "")
                                if selection_reasoning:
                                    st.info(f"ğŸ§  é€‰æ‹©æ¨ç†: {selection_reasoning}")
                                
                                # æ˜¾ç¤ºæ˜¯å¦ä½¿ç”¨äº†è¯­ä¹‰åŒ¹é…
                                if analysis.get("use_semantic_matching"):
                                    st.success("ğŸš€ ä½¿ç”¨OpenVINOè¯­ä¹‰åŒ¹é…ç®—æ³•")
                                else:
                                    st.warning("âš ï¸ ä½¿ç”¨ä¼ ç»Ÿå…³é”®è¯åŒ¹é…")
                                
                                # æ˜¾ç¤ºå¤„ç†æ—¶é—´
                                processing_time = analysis.get("processing_time_ms", 0)
                                if processing_time > 0:
                                    st.caption(f"â±ï¸ å¤„ç†æ—¶é—´: {processing_time:.1f}ms")
                                
                                # æ˜¾ç¤ºé€‰ä¸­çš„è¡¨ï¼ˆç®€åŒ–ç‰ˆï¼‰
                                st.markdown("**ğŸ“Š ç›¸å…³æ•°æ®è¡¨**:")
                                for i, table_dict in enumerate(selected_tables[:3], 1):
                                    score_emoji = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰"
                                    table_name = table_dict.get("table_name", "æœªçŸ¥è¡¨")
                                    relevance_score = table_dict.get("relevance_score", 0.0)
                                    reasoning = table_dict.get("reasoning", "æ— æ¨ç†ä¿¡æ¯")
                                    st.caption(f"{score_emoji} **{table_name}** (ç›¸å…³æ€§: {relevance_score:.1f}) - {reasoning}")
            
            # 2.1 æ ‡é¢˜ï¼šæŸ¥è¯¢ç»“æœ
            st.markdown("##### ğŸ” æŸ¥è¯¢ç»“æœ")
            df_hist = pd.DataFrame(msg["data"])
            if not df_hist.empty:
                st.write(f"å…±æŸ¥è¯¢åˆ° {len(df_hist)} æ¡æ•°æ®ï¼š")
                
                # æ·»åŠ æ•°æ®ç­›é€‰åŠŸèƒ½
                if len(df_hist) > 10:  # æ•°æ®é‡è¾ƒå¤§æ—¶æä¾›ç­›é€‰
                    with st.expander("ğŸ” æ•°æ®ç­›é€‰ä¸æ’åº", expanded=False):
                        # å¿«é€Ÿç­›é€‰æŒ‰é’®
                        quick_filter = data_filter.create_quick_filter_buttons(df_hist, f"hist_quick_{msg_index}")
                        if quick_filter:
                            df_hist = data_filter.apply_quick_filter(df_hist, quick_filter)
                            st.success(f"å·²åº”ç”¨ç­›é€‰: {quick_filter['name']}")
                        
                        # è¯¦ç»†ç­›é€‰ç•Œé¢
                        filtered_df, filter_config = data_filter.create_filter_interface(df_hist, f"hist_filter_{msg_index}")
                        if filter_config:
                            df_hist = filtered_df
                            
                            # ä¿å­˜ç­›é€‰é…ç½®é€‰é¡¹
                            col1, col2 = st.columns(2)
                            with col1:
                                filter_name = st.text_input("ç­›é€‰é…ç½®åç§°", placeholder="è¾“å…¥åç§°ä¿å­˜ç­›é€‰é…ç½®", key=f"filter_name_hist_{msg_index}")
                            with col2:
                                if st.button("ğŸ’¾ ä¿å­˜ç­›é€‰", key=f"save_filter_hist_{msg_index}") and filter_name:
                                    if data_filter.save_filter_config(filter_config, filter_name):
                                        st.success(f"ç­›é€‰é…ç½® '{filter_name}' å·²ä¿å­˜")
                
                st.dataframe(df_hist, hide_index=True)
                
                # 2.2 æ ‡é¢˜ï¼šå¯è§†åŒ– (å¦‚æœç¬¦åˆæ¡ä»¶)
                numeric_cols = df_hist.select_dtypes(include='number').columns
                if len(df_hist) > 1 and len(numeric_cols) > 0:
                    st.markdown("##### ğŸ“Š å¯è§†åŒ–")
                    
                    # ä½¿ç”¨æ–°çš„å¯è§†åŒ–å¼•æ“
                    chart_options = viz_engine.get_chart_options(df_hist, msg.get('content', ''))
                    
                    # å¦‚æœæœ‰å¤šä¸ªå›¾è¡¨é€‰é¡¹ï¼Œè®©ç”¨æˆ·é€‰æ‹©
                    if len(chart_options) > 2:
                        col1, col2 = st.columns([3, 1])
                        with col2:
                            selected_chart = st.selectbox(
                                "å›¾è¡¨ç±»å‹", 
                                options=[opt["type"] for opt in chart_options],
                                format_func=lambda x: next(opt["icon"] + " " + opt["name"] for opt in chart_options if opt["type"] == x),
                                key=f"hist_chart_select_{msg_index}"
                            )
                        with col1:
                            if selected_chart == "table":
                                # æ˜¾ç¤ºæ•°æ®è¡¨æ ¼
                                st.dataframe(df_hist, use_container_width=True)
                            else:
                                fig = viz_engine.create_interactive_chart(df_hist, selected_chart, msg.get('content', ''))
                                # ç”Ÿæˆå†å²æ¶ˆæ¯å›¾è¡¨çš„å”¯ä¸€key
                                chart_key = generate_history_chart_key(msg_index, selected_chart, df_hist)
                                st.plotly_chart(fig, use_container_width=True, key=chart_key)
                    else:
                        # è‡ªåŠ¨é€‰æ‹©æœ€ä½³å›¾è¡¨ç±»å‹
                        auto_chart_type = viz_engine.detect_chart_type(df_hist, msg.get('content', ''))
                        if auto_chart_type == "table":
                            # æ˜¾ç¤ºæ•°æ®è¡¨æ ¼
                            st.dataframe(df_hist, use_container_width=True)
                        else:
                            fig = viz_engine.create_interactive_chart(df_hist, query_context=msg.get('content', ''))
                            # ç”Ÿæˆå†å²æ¶ˆæ¯å›¾è¡¨çš„å”¯ä¸€keyï¼ˆè‡ªåŠ¨ç±»å‹ï¼‰
                            chart_key = generate_history_chart_key(msg_index, "auto", df_hist)
                            st.plotly_chart(fig, use_container_width=True, key=chart_key)
            
            # 2.3 æ ‡é¢˜ï¼šå•†ä¸šæ´å¯Ÿ (è¿™é‡Œæ˜¾å¼é‡æ–°æ¸²æŸ“æ ‡é¢˜ï¼Œç¡®ä¿ä¸æ¶ˆå¤±ï¼)
            st.markdown("##### ğŸ’¡ å•†ä¸šæ´å¯Ÿ")
            if msg.get("content"):
                st.markdown(msg["content"])
            
            # 2.3.5 å¼‚å¸¸æ£€æµ‹åˆ†æ
            if "data" in msg and msg["data"]:
                df_for_anomaly = pd.DataFrame(msg["data"])
                if not df_for_anomaly.empty and len(df_for_anomaly) > 2:
                    # è·å–åŸå§‹æŸ¥è¯¢
                    user_query = ""
                    msg_index = messages.index(msg)
                    if msg_index > 0:
                        user_query = messages[msg_index - 1].get("content", "")
                    
                    anomaly_analysis = anomaly_detector.analyze_anomalies(df_for_anomaly, user_query)
                    
                    if anomaly_analysis["total_anomalies"] > 0:
                        st.markdown("##### âš ï¸ å¼‚å¸¸æ£€æµ‹")
                        
                        # å¼‚å¸¸æ‘˜è¦
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("æ€»å¼‚å¸¸æ•°", anomaly_analysis["total_anomalies"])
                        with col2:
                            st.metric("é«˜é£é™©", anomaly_analysis["high_severity"], delta=None if anomaly_analysis["high_severity"] == 0 else "éœ€å…³æ³¨")
                        with col3:
                            st.metric("ä¸­é£é™©", anomaly_analysis["medium_severity"])
                        
                        # ä¸»è¦å¼‚å¸¸é¢„è§ˆ - æ–°å¢åŠŸèƒ½
                        if "primary_anomaly" in anomaly_analysis and anomaly_analysis["primary_anomaly"]:
                            primary = anomaly_analysis["primary_anomaly"]
                            
                            # é£é™©ç­‰çº§é¢œè‰²æ˜ å°„
                            risk_colors = {
                                "high": "ğŸ”´",
                                "medium": "ğŸŸ¡", 
                                "low": "ğŸŸ¢"
                            }
                            risk_color = risk_colors.get(primary.impact_level, "ğŸ”µ")
                            
                            # æ˜¾ç¤ºä¸»è¦å¼‚å¸¸é¢„è§ˆå¡ç‰‡
                            with st.container():
                                st.markdown("**ğŸ“‹ ä¸»è¦å¼‚å¸¸é¢„è§ˆ**")
                                
                                # å¼‚å¸¸æ ‡é¢˜è¡Œ
                                col_icon, col_desc = st.columns([1, 5])
                                with col_icon:
                                    st.markdown(f"### {primary.icon}")
                                with col_desc:
                                    st.markdown(f"**{risk_color} {primary.type_name}** ({primary.impact_level}é£é™©)")
                                    st.write(primary.short_description)
                                
                                # å¼‚å¸¸è¯¦æƒ…è¡Œ
                                col_reason, col_sample = st.columns(2)
                                with col_reason:
                                    st.write(f"**åŸå› **: {primary.quick_reason}")
                                    if primary.quick_action:
                                        st.write(f"**å»ºè®®**: {primary.quick_action}")
                                
                                with col_sample:
                                    if primary.sample_data:
                                        st.write("**å¼‚å¸¸æ ·æœ¬**:")
                                        for sample in primary.sample_data[:2]:
                                            st.write(f"â€¢ {sample}")
                                
                                # ç½®ä¿¡åº¦æ˜¾ç¤º
                                confidence_pct = int(primary.confidence * 100)
                                confidence_label = "é«˜" if primary.confidence > 0.8 else "ä¸­" if primary.confidence > 0.6 else "ä½"
                                st.caption(f"ğŸ¯ æ£€æµ‹ç½®ä¿¡åº¦: {confidence_pct}% ({confidence_label})")
                                
                                # å¦‚æœæœ‰å¤šä¸ªå¼‚å¸¸ï¼Œæ˜¾ç¤ºå…¶ä»–å¼‚å¸¸æç¤º
                                if anomaly_analysis["total_anomalies"] > 1:
                                    other_count = anomaly_analysis["total_anomalies"] - 1
                                    st.info(f"ğŸ’¡ è¿˜æœ‰ {other_count} ä¸ªå…¶ä»–å¼‚å¸¸ï¼Œç‚¹å‡»ä¸‹æ–¹æŸ¥çœ‹è¯¦æƒ…")
                        
                        # æ˜¾ç¤ºå‰3ä¸ªæœ€é‡è¦çš„å¼‚å¸¸ï¼ˆä¿æŒåŸæœ‰çš„è¯¦ç»†å±•ç¤ºï¼‰
                        # åœ¨å†å²æ¶ˆæ¯éƒ¨åˆ†å’Œæ–°æ¶ˆæ¯ç”Ÿæˆéƒ¨åˆ†éƒ½ä¿®æ”¹è¿™ä¸ªå¾ªç¯ï¼š
                        for i, anomaly in enumerate(anomaly_analysis["anomalies"][:3]):
                            severity_color = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}.get(anomaly["severity"], "ğŸ”µ")
                            
                            # æ„å»ºå®Œæ•´çš„å¼‚å¸¸ä¿¡æ¯
                            message = f"{severity_color} **{anomaly.get('description', 'å¼‚å¸¸')}**\n\n"
                            
                            # æ·»åŠ ç»Ÿè®¡ä¾æ®
                            if 'statistical_basis' in anomaly:
                                message += f"ğŸ“Š **æ£€æµ‹ä¾æ®**: {anomaly['statistical_basis']}\n\n"
                            
                            # æ·»åŠ å…·ä½“è¯æ®
                            if 'evidence_details' in anomaly:
                                message += f"ğŸ” **å…·ä½“è¯æ®**:\n{anomaly['evidence_details']}\n\n"
                            elif 'details' in anomaly:
                                message += f"ğŸ“ **è¯¦ç»†æƒ…å†µ**: {anomaly['details']}\n\n"
                            
                            # æ·»åŠ å»ºè®®
                            if 'suggestion' in anomaly:
                                message += f"ğŸ’¡ **å¤„ç†å»ºè®®**: {anomaly['suggestion']}"
                            
                            st.warning(message)
                            with st.expander(f"{severity_color} **{anomaly['description']}**", expanded=True):
                                # åŸºæœ¬ä¿¡æ¯
                                col_info1, col_info2 = st.columns(2)
                                with col_info1:
                                    st.write(f"**å¼‚å¸¸ç±»å‹**: {anomaly.get('type', 'unknown')}")
                                    st.write(f"**å½±å“å­—æ®µ**: {anomaly.get('column', 'N/A')}")
                                    st.write(f"**å¼‚å¸¸æ•°é‡**: {anomaly.get('count', 0)}")
                                with col_info2:
                                    st.write(f"**é£é™©ç­‰çº§**: {anomaly.get('severity', 'unknown')}")
                                    if 'ratio' in anomaly:
                                        st.write(f"**å¼‚å¸¸æ¯”ä¾‹**: {anomaly['ratio']:.1%}")
                                    if 'total_loss' in anomaly:
                                        st.write(f"**è´¢åŠ¡å½±å“**: {anomaly['total_loss']:,.2f}")
                                
                                # æ£€æµ‹æ ‡å‡†å’Œä¾æ®
                                if 'criteria' in anomaly:
                                    st.markdown("**ğŸ” æ£€æµ‹æ ‡å‡†**")
                                    criteria = anomaly['criteria']
                                    st.write(f"â€¢ **æ–¹æ³•**: {criteria.get('method', 'N/A')}")
                                    st.write(f"â€¢ **é˜ˆå€¼**: {criteria.get('threshold', 'N/A')}")
                                    if 'calculation' in criteria:
                                        st.write(f"â€¢ **è®¡ç®—å…¬å¼**: {criteria['calculation']}")
                                    
                                    # æ˜¾ç¤ºå…·ä½“çš„æ•°å€¼æ ‡å‡†
                                    if 'lower_bound' in criteria and 'upper_bound' in criteria:
                                        st.write(f"â€¢ **æ­£å¸¸èŒƒå›´**: {criteria['lower_bound']:.2f} - {criteria['upper_bound']:.2f}")
                                    if 'z_threshold' in criteria:
                                        st.write(f"â€¢ **Z-Scoreé˜ˆå€¼**: {criteria['z_threshold']}")
                                
                                # å¼‚å¸¸è¯æ®å’Œå…·ä½“æ•°æ®
                                if 'evidence' in anomaly:
                                    st.markdown("**ğŸ“Š å¼‚å¸¸è¯æ®**")
                                    evidence = anomaly['evidence']
                                    
                                    # æ˜¾ç¤ºå¼‚å¸¸è®°å½•æ ·æœ¬
                                    if 'outlier_records' in evidence and evidence['outlier_records']:
                                        st.write("**å¼‚å¸¸æ•°æ®æ ·æœ¬**:")
                                        for j, record in enumerate(evidence['outlier_records'][:2]):
                                            st.write(f"  {j+1}. è¡Œ{record['row_index']}: å¼‚å¸¸å€¼ = {record['anomaly_value']:.2f}")
                                            if len(record['full_record']) <= 5:
                                                st.json(record['full_record'])
                                    
                                    elif 'negative_records' in evidence and evidence['negative_records']:
                                        st.write("**è´Ÿåˆ©æ¶¦è®°å½•æ ·æœ¬**:")
                                        for j, record in enumerate(evidence['negative_records'][:2]):
                                            st.write(f"  {j+1}. è¡Œ{record['row_index']}: åˆ©æ¶¦ = {record['profit_value']:.2f}")
                                    
                                    elif 'zero_records' in evidence and evidence['zero_records']:
                                        st.write("**é›¶å€¼è®°å½•æ ·æœ¬**:")
                                        for j, record in enumerate(evidence['zero_records'][:2]):
                                            st.write(f"  {j+1}. è¡Œ{record['row_index']}: å­˜åœ¨é›¶å€¼")
                                    
                                    elif 'high_margin_records' in evidence and evidence['high_margin_records']:
                                        st.write("**é«˜åˆ©æ¶¦ç‡è®°å½•æ ·æœ¬**:")
                                        for j, record in enumerate(evidence['high_margin_records'][:2]):
                                            st.write(f"  {j+1}. è¡Œ{record['row_index']}: åˆ©æ¶¦ç‡ = {record['profit_margin']:.1%}")
                                    
                                    elif 'price_anomaly_records' in evidence and evidence['price_anomaly_records']:
                                        st.write("**å¼‚å¸¸å•ä»·è®°å½•æ ·æœ¬**:")
                                        for j, record in enumerate(evidence['price_anomaly_records'][:2]):
                                            st.write(f"  {j+1}. è¡Œ{record['row_index']}: å•ä»· = {record['unit_price']:.2f}")
                                    
                                    elif 'trend_break_points' in evidence and evidence['trend_break_points']:
                                        st.write("**è¶‹åŠ¿çªå˜ç‚¹**:")
                                        for j, point in enumerate(evidence['trend_break_points'][:2]):
                                            st.write(f"  {j+1}. å˜åŒ–: {point['previous_value']:.2f} â†’ {point['current_value']:.2f} ({point['change_percentage']:.1%})")
                                    
                                    elif 'decline_sequence' in evidence and evidence['decline_sequence']:
                                        st.write("**ä¸‹é™è¶‹åŠ¿åºåˆ—**:")
                                        for j, point in enumerate(evidence['decline_sequence'][-3:]):  # æ˜¾ç¤ºæœ€å3ä¸ªç‚¹
                                            st.write(f"  æœŸ{point['period']}: {point['value']:.2f} (ç´¯è®¡ä¸‹é™: {point['cumulative_decline']:.1%})")
                                
                                # å»ºè®®
                                st.markdown("**ğŸ’¡ å¤„ç†å»ºè®®**")
                                st.write(anomaly.get('suggestion', 'å»ºè®®è¿›ä¸€æ­¥åˆ†ææ­¤å¼‚å¸¸'))
                        
                        # æ›´å¤šå¼‚å¸¸è¯¦æƒ…
                        if len(anomaly_analysis["anomalies"]) > 3:
                            with st.expander(f"æŸ¥çœ‹æ›´å¤šå¼‚å¸¸ ({len(anomaly_analysis['anomalies']) - 3} ä¸ª)", expanded=False):
                                for anomaly in anomaly_analysis["anomalies"][3:]:
                                    severity_color = {"high": "ğŸ”´", "medium": "ğŸŸ¡", "low": "ğŸŸ¢"}.get(anomaly["severity"], "ğŸ”µ")
                                    
                                    st.markdown(f"**{severity_color} {anomaly['description']}**")
                                    
                                    # ç®€åŒ–æ˜¾ç¤ºæ£€æµ‹æ ‡å‡†
                                    if 'criteria' in anomaly:
                                        criteria = anomaly['criteria']
                                        st.write(f"â€¢ æ£€æµ‹æ–¹æ³•: {criteria.get('method', 'N/A')}")
                                        st.write(f"â€¢ é˜ˆå€¼æ ‡å‡†: {criteria.get('threshold', 'N/A')}")
                                    
                                    # ç®€åŒ–æ˜¾ç¤ºå¼‚å¸¸æ•°æ®
                                    if 'evidence' in anomaly:
                                        evidence = anomaly['evidence']
                                        if 'statistical_summary' in evidence:
                                            summary = evidence['statistical_summary']
                                            if 'extreme_range' in summary:
                                                st.write(f"â€¢ å¼‚å¸¸å€¼èŒƒå›´: {summary['extreme_range']}")
                                            elif 'affected_percentage' in summary:
                                                st.write(f"â€¢ å½±å“æ¯”ä¾‹: {summary['affected_percentage']:.1f}%")
                                    
                                    st.write(f"â€¢ å»ºè®®: {anomaly.get('suggestion', 'éœ€è¦è¿›ä¸€æ­¥åˆ†æ')}")
                                    st.markdown("---")
            
            # 2.3.7 å…¶ä»–å¯èƒ½çš„ç†è§£æ–¹å¼ (å†å²æ¶ˆæ¯)
            if "alternatives" in msg and msg["alternatives"]:
                st.markdown("##### ğŸ¤” å…¶ä»–å¯èƒ½çš„ç†è§£æ–¹å¼")
                
                with st.expander(f"æŸ¥çœ‹å…¶ä»– {len(msg['alternatives'])} ç§ç†è§£æ–¹å¼", expanded=False):
                    st.markdown("*ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®å¯ä»¥æŒ‰ç…§ä¸åŒçš„ç†è§£æ–¹å¼é‡æ–°æ‰§è¡ŒæŸ¥è¯¢*")
                    
                    for i, alt in enumerate(msg["alternatives"]):
                        with st.container():
                            col1, col2 = st.columns([4, 1])
                            
                            with col1:
                                # å¤„ç†å¯èƒ½æ˜¯å­—å…¸æˆ–å¯¹è±¡çš„æƒ…å†µ
                                if isinstance(alt, dict):
                                    rank = alt.get("rank", i + 1)
                                    natural_desc = alt.get("natural_description", alt.get("description", "æœªçŸ¥ç†è§£æ–¹å¼"))
                                    confidence = alt.get("confidence", 0.0)
                                    key_interpretations = alt.get("key_interpretations", {})
                                else:
                                    rank = getattr(alt, "rank", i + 1)
                                    natural_desc = getattr(alt, "natural_description", getattr(alt, "description", "æœªçŸ¥ç†è§£æ–¹å¼"))
                                    confidence = getattr(alt, "confidence", 0.0)
                                    key_interpretations = getattr(alt, "key_interpretations", {})
                                
                                st.write(f"**ç†è§£æ–¹å¼ {rank}**:")
                                st.write(f"ğŸ“ {natural_desc}")
                                st.write(f"ğŸ¯ ç½®ä¿¡åº¦: {confidence:.1%}")
                                
                                if key_interpretations:
                                    with st.expander("æŸ¥çœ‹æŠ€æœ¯ç»†èŠ‚", expanded=False):
                                        for term, interp in key_interpretations.items():
                                            interp_desc = interp.get('desc', '') if isinstance(interp, dict) else str(interp)
                                            st.caption(f"â€¢ {term}: {interp_desc}")
                            
                            with col2:
                                if st.button(f"ğŸ”„ é€‰æ‹©æ­¤ç†è§£", key=f"select_alt_hist_{msg_index}_{i}"):
                                    # é‡æ–°æ‰§è¡Œè¿™ç§ç†è§£æ–¹å¼
                                    st.session_state.prompt_trigger = natural_desc
                                    st.rerun()
                            
                            st.divider()
            
            # 2.4 æ¨èç›¸å…³é—®é¢˜
            if "data" in msg and msg["data"]:
                st.markdown("##### ğŸ¤” æ‚¨å¯èƒ½è¿˜æƒ³äº†è§£")
                
                # ä¼˜å…ˆä½¿ç”¨ä¿å­˜çš„æ¨èï¼Œå¦‚æœæ²¡æœ‰åˆ™é‡æ–°ç”Ÿæˆï¼ˆå…¼å®¹æ—§æ¶ˆæ¯ï¼‰
                if "recommendations" in msg and msg["recommendations"]:
                    recommendations = msg["recommendations"]
                else:
                    # å…¼å®¹æ—§æ¶ˆæ¯ï¼šé‡æ–°ç”Ÿæˆæ¨è
                    df_for_rec = pd.DataFrame(msg["data"])
                    # è·å–åŸå§‹æŸ¥è¯¢ï¼ˆä»å†å²æ¶ˆæ¯ä¸­æ‰¾åˆ°å¯¹åº”çš„ç”¨æˆ·é—®é¢˜ï¼‰
                    user_query = ""
                    msg_index = messages.index(msg)
                    if msg_index > 0:
                        user_query = messages[msg_index - 1].get("content", "")
                    
                    recommendations = recommendation_engine.generate_recommendations(
                        current_query=user_query,
                        result_df=df_for_rec,
                        num_recommendations=3,
                        llm_client=None,  # å†å²æ¶ˆæ¯ä½¿ç”¨å¤‡ç”¨æ¨è
                        model_name=None
                    )
                
                if recommendations:
                    rec_cols = st.columns(len(recommendations))
                    for i, rec in enumerate(recommendations):
                        with rec_cols[i]:
                            if st.button(f"ğŸ’­ {rec}", use_container_width=True, key=f"rec_hist_{msg_index}_{i}"):
                                recommendation_engine.record_question_click(rec)
                                st.session_state.prompt_trigger = rec
                                st.rerun()
            
            # 2.5 æ ‡é¢˜ï¼šæ•°æ®è¯¦æƒ… & SQL
            with st.expander("ğŸ“ åŸå§‹ SQL ä¸æ•°æ®å¯¼å‡º", expanded=False):
                if not msg["data"]: 
                    st.warning("ç»“æœä¸ºç©º")
                else:
                    # æ•°æ®å¯¼å‡ºåŠŸèƒ½
                    df_export = pd.DataFrame(msg["data"])
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        csv_data = export_manager.export_data_to_csv(df_export, "query_result")
                        if csv_data and os.path.exists(csv_data):
                            with open(csv_data, "rb") as csv_file:
                                st.download_button(
                                    label="ğŸ“Š ä¸‹è½½CSV",
                                    data=csv_file.read(),
                                    file_name=os.path.basename(csv_data),
                                    mime="text/csv",
                                    key=f"csv_download_hist_{msg_index}"
                                )
                    
                    with col2:
                        excel_data = export_manager.export_data_to_excel(df_export, "query_result")
                        if excel_data and os.path.exists(excel_data):
                            with open(excel_data, "rb") as excel_file:
                                st.download_button(
                                    label="ğŸ“ˆ ä¸‹è½½Excel",
                                    data=excel_file.read(),
                                    file_name=os.path.basename(excel_data),
                                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                    key=f"excel_download_hist_{msg_index}"
                                )
                
                if "sql" in msg: 
                    st.code(msg["sql"], language="sql")
                
        else:
            # === ç±»å‹ B: æ™®é€šå¯¹è¯ ===
            if msg.get("content"):
                st.markdown(msg["content"])


# --- æ–°çš„æ¨ç†ä¸ç”Ÿæˆé€»è¾‘ ---
if prompt_input:
    # æ‡’åŠ è½½
    agent = None
    if not st.session_state.agent_loaded:
        with st.status("ğŸš€ é¦–æ¬¡è¿è¡Œï¼Œæ­£åœ¨åŠ è½½ OpenVINO åŠ é€Ÿå¼•æ“...", expanded=True) as status:
            agent, err = get_agent(st.session_state.config)
            if err:
                status.update(label="âŒ åˆå§‹åŒ–å¤±è´¥", state="error")
                st.error(err); st.stop()
            st.session_state.agent_loaded = True
            status.update(label="âœ… å¼•æ“åŠ è½½å®Œæ¯•", state="complete", expanded=False)
    else:
        agent, err = get_agent(st.session_state.config)
        if err: st.error(err); st.stop()
    
    # ç¡®ä¿agentå·²æ­£ç¡®åŠ è½½
    if agent is None:
        st.error("Agent åŠ è½½å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
        st.stop()
    
    # æ¸²æŸ“ç”¨æˆ·æé—®
    st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»").markdown(prompt_input)
    messages.append({"role": "user", "content": prompt_input})
    
    # ç¡¬ä»¶ä¼˜åŒ–é¢„å¤„ç†
    hardware_optimization_result = None
    if HARDWARE_OPTIMIZATION_AVAILABLE:
        try:
            # ä¼°ç®—æŸ¥è¯¢ç»“æœå¤§å°ï¼ˆåŸºäºæŸ¥è¯¢å¤æ‚åº¦ï¼‰
            estimated_result_size = 100
            if any(keyword in prompt_input.lower() for keyword in ['join', 'group by', 'sum', 'count']):
                estimated_result_size = 500
            if any(keyword in prompt_input.lower() for keyword in ['union', 'subquery', 'window']):
                estimated_result_size = 1000
            
            # æ‰§è¡Œç¡¬ä»¶ä¼˜åŒ–
            hardware_optimization_result = optimize_query_performance(prompt_input, estimated_result_size)
            
            if hardware_optimization_result:
                vendor = hardware_optimization_result.vendor.value
                st.info(f"ğŸš€ {vendor}ä¼˜åŒ–å·²å¯ç”¨ - é¢„æœŸåŠ é€Ÿæ¯”: {hardware_optimization_result.overall_speedup:.2f}x")
        except Exception as e:
            st.warning(f"ç¡¬ä»¶ä¼˜åŒ–é¢„å¤„ç†å¤±è´¥: {e}")
    
    # æŠ€æœ¯å“è¶Šæ€§ä¼˜åŒ–é¢„å¤„ç† - åç«¯åŠŸèƒ½å¯ç”¨
    if TECHNICAL_EXCELLENCE_AVAILABLE:
        try:
            # è®°å½•æŸ¥è¯¢å¼€å§‹ï¼Œç”¨äºæ€§èƒ½ç›‘æ§
            query_start_time = time.perf_counter()
            
            # ä¼°ç®—è¾“å…¥å¤§å°
            input_size = len(prompt_input.encode('utf-8'))
            
            # é¢„æµ‹æ€§èƒ½ï¼ˆå¦‚æœæœ‰å†å²æ•°æ®ï¼‰
            tech_status = tech_manager.get_technical_status()
            if tech_status.overall_score >= 70:
                # åç«¯ä¼˜åŒ–å¤„ç†ï¼Œä¸æ˜¾ç¤ºUIä¿¡æ¯
                pass
            
        except Exception as e:
            logger.warning(f"æŠ€æœ¯å“è¶Šæ€§é¢„å¤„ç†å¤±è´¥: {e}")
    
    # AI å›ç­”å®¹å™¨
    with st.chat_message("assistant", avatar="ğŸ¤–"):
        # ğŸ§  é›†æˆä¸Šä¸‹æ–‡è®°å¿†ç³»ç»Ÿ
        if CONTEXT_MEMORY_AVAILABLE and st.session_state.get('context_memory_enabled', True):
            try:
                # ä½¿ç”¨ä¸Šä¸‹æ–‡è®°å¿†ç³»ç»Ÿå¤„ç†è¾“å…¥
                contextual_prompt = integrate_with_messages(
                    messages[:-1],  # ä¸åŒ…æ‹¬åˆšæ·»åŠ çš„ç”¨æˆ·æ¶ˆæ¯
                    prompt_input,
                    system_instruction="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®åˆ†æåŠ©æ‰‹ï¼Œä¸“é—¨å¸®åŠ©ç”¨æˆ·åˆ†æé›¶å”®ä¸šåŠ¡æ•°æ®ã€‚"
                )
                
                # æ˜¾ç¤ºä¸Šä¸‹æ–‡çŠ¶æ€
                st.caption("ğŸ§  å·²åŠ è½½å¯¹è¯ä¸Šä¸‹æ–‡")
                
                # ä½¿ç”¨ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„æç¤ºè¿›è¡Œå¤„ç†
                final_prompt = contextual_prompt
            except Exception as e:
                st.warning(f"âš ï¸ ä¸Šä¸‹æ–‡è®°å¿†ç³»ç»Ÿé‡åˆ°é—®é¢˜ï¼Œä½¿ç”¨åŸºæœ¬æ¨¡å¼: {e}")
                final_prompt = prompt_input
        else:
            # ä¼ ç»Ÿæ–¹å¼å¤„ç†
            final_prompt = prompt_input
        status_box = st.status("ğŸš€ ç³»ç»Ÿå¯åŠ¨...", expanded=True)
        code_ph = None
        thought_ph = None
        curr_sql = ""
        curr_thought = ""
        
        start_time = time.perf_counter()
        
        try:
            # ä½¿ç”¨ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„æç¤ºæˆ–ä¼ ç»Ÿæç¤º
            stream_gen = agent.generate_and_execute_stream(final_prompt, messages[:-1])
            final_resp, df_result, sql_code, mode = "", None, None, "CHAT"
            selected_possibility, alternatives = None, []
            step_count = 0 
            
            # ä¿å­˜è¡¨é€‰æ‹©è¿‡ç¨‹ä¿¡æ¯ï¼Œç”¨äºæŒä¹…åŒ–æ˜¾ç¤º
            table_selection_info = {
                "initial_analysis": "",
                "agent_reasoning": "",
                "join_analysis": "",
                "final_selection": None
            }

            for step in stream_gen:
                step_count += 1
                if step_count % 5 == 0: update_monitor()

                if step["type"] == "step":
                    status_box.write(f"{step['icon']} {step['msg']}")
                    status_box.update(state=step["status"])
                    if "rag_latency" in step:
                        st.session_state.last_rag_latency = step["rag_latency"]
                        update_monitor()
                
                elif step["type"] == "code_start":
                    status_box.markdown(f"**{step.get('label', 'Code')}**")
                    code_ph = status_box.empty()
                    curr_sql = ""
                
                elif step["type"] == "code_chunk":
                    curr_sql += step["content"]
                    code_ph.code(curr_sql, language="sql")
                
                elif step["type"] == "thought_start":
                    # è·å–é…ç½®çš„æ¨¡å‹åç§°ç”¨äºæ˜¾ç¤º
                    model_display_name = st.session_state.config.get("model_name", "AIæ¨¡å‹")
                    status_box.markdown(f"**ğŸ¤” è¯­ä¹‰åˆ†æ ({model_display_name} Thinking)...**")
                    thought_ph = status_box.empty()
                    curr_thought = ""
                
                elif step["type"] == "thought_chunk":
                    curr_thought += step["content"]
                    thought_ph.markdown(f"<div class='thought-box'>{curr_thought}</div>", unsafe_allow_html=True)
                
                elif step["type"] == "error_log":
                    status_box.error(f"âš ï¸ {step['content']}")

                elif step["type"] == "table_analysis":
                    # æ˜¾ç¤ºåˆæ­¥è¡¨ç­›é€‰ç»“æœå¹¶ä¿å­˜
                    status_box.markdown("**ğŸ” åˆæ­¥è¡¨ç­›é€‰ç»“æœ**")
                    status_box.info(step["content"])
                    table_selection_info["initial_analysis"] = step["content"]
                
                elif step["type"] == "agent_reasoning":
                    # æ˜¾ç¤ºAgentæ¨ç†è¿‡ç¨‹å¹¶ä¿å­˜
                    status_box.markdown("**ğŸ¤– Agentæ™ºèƒ½ç­›é€‰æ¨ç†**")
                    status_box.success(f"ğŸ§  æ¨ç†è¿‡ç¨‹: {step['content']}")
                    table_selection_info["agent_reasoning"] = step["content"]
                
                elif step["type"] == "join_analysis":
                    # æ˜¾ç¤ºè¡¨å…³è”åˆ†æå¹¶ä¿å­˜
                    status_box.markdown("**ğŸ”— è¡¨å…³è”å…³ç³»åˆ†æ**")
                    status_box.info(step["content"])
                    table_selection_info["join_analysis"] = step["content"]

                elif step["type"] == "table_selection":
                    # æ˜¾ç¤ºè¡¨é€‰æ‹©ç»“æœå¹¶ä¿å­˜ä¿¡æ¯
                    status_box.markdown("**ğŸ—„ï¸ æ™ºèƒ½è¡¨é€‰æ‹©ç»“æœ**")
                    
                    selected_tables = step.get("selected_tables", [])
                    analysis = step.get("analysis", {})
                    
                    # ä¿å­˜æœ€ç»ˆé€‰æ‹©ä¿¡æ¯
                    table_selection_info["final_selection"] = {
                        "selected_tables": selected_tables,
                        "analysis": analysis
                    }
                    
                    if selected_tables:
                        # æ˜¾ç¤ºé€‰æ‹©æ¨ç†
                        selection_reasoning = analysis.get("selection_reasoning", "")
                        if selection_reasoning:
                            status_box.info(f"ğŸ§  é€‰æ‹©æ¨ç†: {selection_reasoning}")
                        
                        # æ˜¾ç¤ºæ˜¯å¦ä½¿ç”¨äº†è¯­ä¹‰åŒ¹é…
                        if analysis.get("use_semantic_matching"):
                            status_box.success("ğŸš€ ä½¿ç”¨OpenVINOè¯­ä¹‰åŒ¹é…ç®—æ³•")
                        else:
                            status_box.warning("âš ï¸ ä½¿ç”¨ä¼ ç»Ÿå…³é”®è¯åŒ¹é…ï¼ˆå»ºè®®é…ç½®OpenVINOæ¨¡å‹ä»¥è·å¾—æ›´å¥½æ•ˆæœï¼‰")
                        
                        # æ˜¾ç¤ºå¤„ç†æ—¶é—´
                        processing_time = analysis.get("processing_time_ms", 0)
                        if processing_time > 0:
                            status_box.caption(f"â±ï¸ å¤„ç†æ—¶é—´: {processing_time:.1f}ms")
                        
                        # æ˜¾ç¤ºé€‰ä¸­çš„è¡¨
                        table_info = "ğŸ“Š **ç›¸å…³æ•°æ®è¡¨**:\n\n"
                        for i, table_rel in enumerate(selected_tables[:3], 1):  # æ˜¾ç¤ºå‰3ä¸ªæœ€ç›¸å…³çš„è¡¨
                            score_emoji = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰"
                            table_info += f"{score_emoji} **{table_rel.table_name}** (ç›¸å…³æ€§: {table_rel.relevance_score:.1f})\n"
                            table_info += f"   ğŸ“ {table_rel.table_description}\n"
                            table_info += f"   ğŸ’¡ {table_rel.reasoning}\n"
                            
                            # æ˜¾ç¤ºè¯­ä¹‰ç›¸ä¼¼åº¦ï¼ˆå¦‚æœæœ‰ï¼‰
                            if hasattr(table_rel, 'semantic_similarity') and table_rel.semantic_similarity > 0:
                                table_info += f"   ğŸ¯ è¯­ä¹‰ç›¸ä¼¼åº¦: {table_rel.semantic_similarity:.2f}\n"
                            
                            # æ˜¾ç¤ºåŒ¹é…çš„å…³é”®è¯
                            if hasattr(table_rel, 'keyword_matches') and table_rel.keyword_matches:
                                keywords_text = ", ".join(table_rel.keyword_matches[:3])
                                table_info += f"   ğŸ” å…³é”®è¯åŒ¹é…: {keywords_text}\n"
                            
                            # æ˜¾ç¤ºç›¸å…³å­—æ®µ
                            if table_rel.matched_columns:
                                col_names = []
                                for col in table_rel.matched_columns[:3]:
                                    col_name = col.get('col', '')
                                    if 'similarity' in col:
                                        col_name += f" ({col['similarity']:.2f})"
                                    col_names.append(col_name)
                                if col_names:
                                    table_info += f"   ğŸ“‹ ç›¸å…³å­—æ®µ: {', '.join(col_names)}\n"
                            
                            table_info += "\n"
                        
                        status_box.markdown(table_info)
                        
                        # æ˜¾ç¤ºæŸ¥è¯¢æ„å›¾åˆ†æ
                        intent = analysis.get("intent", {})
                        if intent and any(intent.values()):
                            intent_info = "ğŸ¯ **æŸ¥è¯¢ç‰¹å¾åˆ†æ**:\n"
                            intent_features = []
                            if intent.get("has_aggregation"):
                                intent_features.append("èšåˆè®¡ç®—")
                            if intent.get("has_filtering"):
                                intent_features.append("æ¡ä»¶ç­›é€‰")
                            if intent.get("has_grouping"):
                                intent_features.append("åˆ†ç»„ç»Ÿè®¡")
                            if intent.get("has_sorting"):
                                intent_features.append("æ’åºæ’å")
                            if intent.get("has_time"):
                                intent_features.append("æ—¶é—´åˆ†æ")
                            if intent.get("has_geography"):
                                intent_features.append("åœ°ç†åˆ†æ")
                            
                            if intent_features:
                                intent_info += f"â€¢ æ£€æµ‹åˆ°çš„æŸ¥è¯¢ç‰¹å¾: {', '.join(intent_features)}\n"
                                status_box.markdown(intent_info)
                    else:
                        error_msg = analysis.get("error", "æœªæ‰¾åˆ°æ˜ç¡®ç›¸å…³çš„è¡¨ï¼Œå°†ä½¿ç”¨å…¨éƒ¨è¡¨ä¿¡æ¯")
                        status_box.warning(f"âš ï¸ {error_msg}")

                elif step["type"] == "result":
                    mode = "SQL"; df_result = step["df"]; sql_code = step["sql"]
                    # ä¿å­˜å¯èƒ½æ€§ä¿¡æ¯ç”¨äºåç»­æ˜¾ç¤º
                    selected_possibility = step.get("selected_possibility")
                    alternatives = step.get("alternatives", [])
                    status_box.update(label="âœ… æ‰§è¡Œå®Œæˆ", state="complete", expanded=False)
                
                elif step["type"] == "final_chat":
                    mode = "CHAT"
                    status_box.update(label="âœ¨ å¯¹è¯å®Œæˆ", state="complete", expanded=False)
                
                elif step["type"] == "error":
                    status_box.update(label="âŒ å‘ç”Ÿé”™è¯¯", state="error"); st.error(step["msg"]); st.stop()

            # --- ç”Ÿæˆç»“æŸï¼Œå¼€å§‹æ¸²æŸ“æœ€ç»ˆç»“æœ (ä¿æŒä¸å†å²è®°å½•ä¸€è‡´çš„ç»“æ„) ---
            if mode == "SQL":
                # 0. è¡¨é€‰æ‹©è¿‡ç¨‹ä¿¡æ¯æŒä¹…åŒ–æ˜¾ç¤º
                if any(table_selection_info.values()):
                    with st.expander("ğŸ—„ï¸ æ™ºèƒ½è¡¨é€‰æ‹©è¿‡ç¨‹", expanded=False):
                        st.markdown("**ğŸ“‹ è¡¨é€‰æ‹©è¯¦ç»†è¿‡ç¨‹**")
                        
                        # æ˜¾ç¤ºåˆæ­¥ç­›é€‰ç»“æœ
                        if table_selection_info["initial_analysis"]:
                            st.markdown("**ç¬¬1æ­¥ï¼šè¯­ä¹‰ç›¸ä¼¼åº¦åˆæ­¥ç­›é€‰**")
                            st.info(table_selection_info["initial_analysis"])
                        
                        # æ˜¾ç¤ºAgentæ¨ç†è¿‡ç¨‹
                        if table_selection_info["agent_reasoning"]:
                            st.markdown("**ç¬¬2æ­¥ï¼šAgentæ™ºèƒ½ç­›é€‰æ¨ç†**")
                            st.success(f"ğŸ§  æ¨ç†è¿‡ç¨‹: {table_selection_info['agent_reasoning']}")
                        
                        # æ˜¾ç¤ºå…³è”åˆ†æ
                        if table_selection_info["join_analysis"]:
                            st.markdown("**ç¬¬3æ­¥ï¼šè¡¨å…³è”å…³ç³»åˆ†æ**")
                            st.info(table_selection_info["join_analysis"])
                        
                        # æ˜¾ç¤ºæœ€ç»ˆé€‰æ‹©ç»“æœ
                        if table_selection_info["final_selection"]:
                            final_selection = table_selection_info["final_selection"]
                            selected_tables = final_selection.get("selected_tables", [])
                            analysis = final_selection.get("analysis", {})
                            
                            st.markdown("**ğŸ¯ æœ€ç»ˆé€‰æ‹©ç»“æœ**")
                            
                            if selected_tables:
                                # æ˜¾ç¤ºé€‰æ‹©æ¨ç†
                                selection_reasoning = analysis.get("selection_reasoning", "")
                                if selection_reasoning:
                                    st.info(f"ğŸ§  é€‰æ‹©æ¨ç†: {selection_reasoning}")
                                
                                # æ˜¾ç¤ºæ˜¯å¦ä½¿ç”¨äº†è¯­ä¹‰åŒ¹é…
                                if analysis.get("use_semantic_matching"):
                                    st.success("ğŸš€ ä½¿ç”¨OpenVINOè¯­ä¹‰åŒ¹é…ç®—æ³•")
                                else:
                                    st.warning("âš ï¸ ä½¿ç”¨ä¼ ç»Ÿå…³é”®è¯åŒ¹é…")
                                
                                # æ˜¾ç¤ºå¤„ç†æ—¶é—´
                                processing_time = analysis.get("processing_time_ms", 0)
                                if processing_time > 0:
                                    st.caption(f"â±ï¸ å¤„ç†æ—¶é—´: {processing_time:.1f}ms")
                                
                                # æ˜¾ç¤ºé€‰ä¸­çš„è¡¨
                                st.markdown("**ğŸ“Š ç›¸å…³æ•°æ®è¡¨**:")
                                for i, table_rel in enumerate(selected_tables[:3], 1):
                                    score_emoji = "ğŸ¥‡" if i == 1 else "ğŸ¥ˆ" if i == 2 else "ğŸ¥‰"
                                    
                                    with st.container():
                                        st.markdown(f"{score_emoji} **{table_rel.table_name}** (ç›¸å…³æ€§: {table_rel.relevance_score:.1f})")
                                        st.caption(f"ğŸ“ {table_rel.table_description}")
                                        st.caption(f"ğŸ’¡ {table_rel.reasoning}")
                                        
                                        # æ˜¾ç¤ºè¯­ä¹‰ç›¸ä¼¼åº¦ï¼ˆå¦‚æœæœ‰ï¼‰
                                        if hasattr(table_rel, 'semantic_similarity') and table_rel.semantic_similarity > 0:
                                            st.caption(f"ğŸ¯ è¯­ä¹‰ç›¸ä¼¼åº¦: {table_rel.semantic_similarity:.2f}")
                                        
                                        # æ˜¾ç¤ºåŒ¹é…çš„å…³é”®è¯
                                        if hasattr(table_rel, 'keyword_matches') and table_rel.keyword_matches:
                                            keywords_text = ", ".join(table_rel.keyword_matches[:3])
                                            st.caption(f"ğŸ” å…³é”®è¯åŒ¹é…: {keywords_text}")
                                        
                                        # æ˜¾ç¤ºç›¸å…³å­—æ®µ
                                        if table_rel.matched_columns:
                                            col_names = []
                                            for col in table_rel.matched_columns[:3]:
                                                col_name = col.get('col', '')
                                                if 'similarity' in col:
                                                    col_name += f" ({col['similarity']:.2f})"
                                                col_names.append(col_name)
                                            if col_names:
                                                st.caption(f"ğŸ“‹ ç›¸å…³å­—æ®µ: {', '.join(col_names)}")
                                        
                                        if i < len(selected_tables[:3]):
                                            st.divider()
                                
                                # æ˜¾ç¤ºæŸ¥è¯¢æ„å›¾åˆ†æ
                                intent = analysis.get("intent", {})
                                if intent and any(intent.values()):
                                    st.markdown("**ğŸ¯ æŸ¥è¯¢ç‰¹å¾åˆ†æ**:")
                                    intent_features = []
                                    if intent.get("has_aggregation"):
                                        intent_features.append("èšåˆè®¡ç®—")
                                    if intent.get("has_filtering"):
                                        intent_features.append("æ¡ä»¶ç­›é€‰")
                                    if intent.get("has_grouping"):
                                        intent_features.append("åˆ†ç»„ç»Ÿè®¡")
                                    if intent.get("has_sorting"):
                                        intent_features.append("æ’åºæ’å")
                                    if intent.get("has_time"):
                                        intent_features.append("æ—¶é—´åˆ†æ")
                                    if intent.get("has_geography"):
                                        intent_features.append("åœ°ç†åˆ†æ")
                                    
                                    if intent_features:
                                        st.info(f"â€¢ æ£€æµ‹åˆ°çš„æŸ¥è¯¢ç‰¹å¾: {', '.join(intent_features)}")
                
                # 1. æŸ¥è¯¢ç»“æœ
                st.markdown("##### ğŸ” æŸ¥è¯¢ç»“æœ")
                has_data = df_result is not None and not df_result.empty

                if has_data:
                    st.write(f"å…±æŸ¥è¯¢åˆ° {len(df_result)} æ¡æ•°æ®ï¼š")
                    
                    # æ·»åŠ æ•°æ®ç­›é€‰åŠŸèƒ½
                    if len(df_result) > 10:  # æ•°æ®é‡è¾ƒå¤§æ—¶æä¾›ç­›é€‰
                        with st.expander("ğŸ” æ•°æ®ç­›é€‰ä¸æ’åº", expanded=False):
                            # å¿«é€Ÿç­›é€‰æŒ‰é’®
                            quick_filter = data_filter.create_quick_filter_buttons(df_result, "current_quick")
                            if quick_filter:
                                df_result = data_filter.apply_quick_filter(df_result, quick_filter)
                                st.success(f"å·²åº”ç”¨ç­›é€‰: {quick_filter['name']}")
                            
                            # è¯¦ç»†ç­›é€‰ç•Œé¢
                            filtered_df, filter_config = data_filter.create_filter_interface(df_result, "current_filter")
                            if filter_config:
                                df_result = filtered_df
                                
                                # ä¿å­˜ç­›é€‰é…ç½®é€‰é¡¹
                                col1, col2 = st.columns(2)
                                with col1:
                                    filter_name = st.text_input("ç­›é€‰é…ç½®åç§°", placeholder="è¾“å…¥åç§°ä¿å­˜ç­›é€‰é…ç½®", key="filter_name_current")
                                with col2:
                                    if st.button("ğŸ’¾ ä¿å­˜ç­›é€‰", key="save_filter_current") and filter_name:
                                        if data_filter.save_filter_config(filter_config, filter_name):
                                            st.success(f"ç­›é€‰é…ç½® '{filter_name}' å·²ä¿å­˜")
                    
                    st.dataframe(df_result, hide_index=True)
                    
                    # 2. å¯è§†åŒ–
                    numeric_cols = df_result.select_dtypes(include='number').columns
                    if len(df_result) > 1 and len(numeric_cols) > 0:
                        st.markdown("##### ğŸ“Š å¯è§†åŒ–")
                        
                        # ä½¿ç”¨æ–°çš„å¯è§†åŒ–å¼•æ“ï¼Œä¼ å…¥æŸ¥è¯¢ä¸Šä¸‹æ–‡
                        chart_options = viz_engine.get_chart_options(df_result, prompt_input)
                        
                        # å¦‚æœæœ‰å¤šä¸ªå›¾è¡¨é€‰é¡¹ï¼Œè®©ç”¨æˆ·é€‰æ‹©
                        if len(chart_options) > 2:
                            col1, col2 = st.columns([3, 1])
                            with col2:
                                selected_chart = st.selectbox(
                                    "å›¾è¡¨ç±»å‹", 
                                    options=[opt["type"] for opt in chart_options],
                                    format_func=lambda x: next(opt["icon"] + " " + opt["name"] for opt in chart_options if opt["type"] == x),
                                    key="current_chart_select"
                                )
                            with col1:
                                if selected_chart == "table":
                                    # æ˜¾ç¤ºæ•°æ®è¡¨æ ¼
                                    st.dataframe(df_result, use_container_width=True)
                                else:
                                    fig = viz_engine.create_interactive_chart(df_result, selected_chart, prompt_input)
                                    # ç”Ÿæˆæ–°æŸ¥è¯¢å›¾è¡¨çš„å”¯ä¸€keyï¼ˆé€‰å®šç±»å‹ï¼‰
                                    chart_key = generate_query_chart_key(prompt_input, selected_chart, df_result)
                                    st.plotly_chart(fig, use_container_width=True, key=chart_key)
                        else:
                            # è‡ªåŠ¨é€‰æ‹©æœ€ä½³å›¾è¡¨ç±»å‹ï¼Œä¼ å…¥æŸ¥è¯¢ä¸Šä¸‹æ–‡
                            auto_chart_type = viz_engine.detect_chart_type(df_result, prompt_input)
                            if auto_chart_type == "table":
                                # æ˜¾ç¤ºæ•°æ®è¡¨æ ¼
                                st.dataframe(df_result, use_container_width=True)
                            else:
                                fig = viz_engine.create_interactive_chart(df_result, query_context=prompt_input)
                                # ç”Ÿæˆæ–°æŸ¥è¯¢å›¾è¡¨çš„å”¯ä¸€keyï¼ˆè‡ªåŠ¨ç±»å‹ï¼‰
                                chart_key = generate_query_chart_key(prompt_input, "auto", df_result)
                                st.plotly_chart(fig, use_container_width=True, key=chart_key)
                    
                    # 3. å•†ä¸šæ´å¯Ÿ
                    st.markdown("##### ğŸ’¡ å•†ä¸šæ´å¯Ÿ")
                    insight_stream = agent.generate_insight_stream(prompt_input, df_result)
                    final_resp = st.write_stream(insight_stream)
                    
                    # 4. ç¡¬ä»¶ä¼˜åŒ–æŠ¥å‘Š
                    if HARDWARE_OPTIMIZATION_AVAILABLE and hardware_optimization_result:
                        vendor = hardware_optimization_result.vendor.value
                        opt_type = hardware_optimization_result.optimization_type.value
                        
                        # æ ¹æ®ç¡¬ä»¶å‚å•†æ˜¾ç¤ºä¸åŒçš„æ ‡é¢˜å’Œå›¾æ ‡
                        if vendor == 'Intel':
                            report_title = "ğŸš€ Intelå¹³å°ä¼˜åŒ–æŠ¥å‘Š"
                        elif vendor == 'NVIDIA':
                            report_title = "âš¡ NVIDIAå¹³å°ä¼˜åŒ–æŠ¥å‘Š"
                        elif vendor == 'AMD':
                            report_title = "ğŸ”¥ AMDå¹³å°ä¼˜åŒ–æŠ¥å‘Š"
                        else:
                            report_title = "ğŸ”§ ç¡¬ä»¶å¹³å°ä¼˜åŒ–æŠ¥å‘Š"
                        
                        with st.expander(report_title, expanded=False):
                            st.markdown("##### ğŸ“Š æ€§èƒ½ä¼˜åŒ–è¯¦æƒ…")
                            
                            # ä¼˜åŒ–æŒ‡æ ‡å±•ç¤º
                            col1, col2, col3, col4 = st.columns(4)
                            with col1:
                                st.metric(
                                    "CPUæ€§èƒ½æå‡", 
                                    f"{hardware_optimization_result.cpu_performance_gain:.1%}",
                                    help=f"åŸºäº{vendor}å¹³å°çš„CPUä¼˜åŒ–æ€§èƒ½æå‡"
                                )
                            with col2:
                                st.metric(
                                    "GPUåŠ é€Ÿæ¯”", 
                                    f"{hardware_optimization_result.gpu_acceleration_gain:.2f}x",
                                    help=f"{vendor}GPUå¹¶è¡Œè®¡ç®—åŠ é€Ÿæ¯”"
                                )
                            with col3:
                                st.metric(
                                    "å†…å­˜æ•ˆç‡", 
                                    f"{hardware_optimization_result.memory_efficiency:.1%}",
                                    help="å†…å­˜è®¿é—®æ¨¡å¼å’Œç¼“å­˜ä¼˜åŒ–æ•ˆç‡"
                                )
                            with col4:
                                st.metric(
                                    "æ€»ä½“åŠ é€Ÿæ¯”", 
                                    f"{hardware_optimization_result.overall_speedup:.2f}x",
                                    help="ç»¼åˆä¼˜åŒ–åçš„æ•´ä½“æ€§èƒ½æå‡"
                                )
                            
                            # ç¡¬ä»¶åˆ©ç”¨æƒ…å†µ
                            hw_details = hardware_optimization_result.optimization_details
                            if hw_details:
                                st.markdown("**ğŸ”§ ç¡¬ä»¶ä¼˜åŒ–è¯¦æƒ…**")
                                
                                # æ˜¾ç¤ºä¼˜åŒ–ç­–ç•¥
                                st.info(f"ğŸ¯ ä¼˜åŒ–ç­–ç•¥: {opt_type} | ç¡¬ä»¶å¹³å°: {vendor}")
                                
                                # æ˜¾ç¤ºå…·ä½“ä¼˜åŒ–ä¿¡æ¯
                                opt_info = []
                                if hw_details.get('cpu_cores_used', 0) > 0:
                                    opt_info.append(f"CPUæ ¸å¿ƒ: {hw_details['cpu_cores_used']}")
                                if hw_details.get('gpu_devices_used', 0) > 0:
                                    opt_info.append(f"GPUè®¾å¤‡: {hw_details['gpu_devices_used']}")
                                if hw_details.get('vectorization_enabled'):
                                    opt_info.append("å‘é‡åŒ–: âœ…")
                                if hw_details.get('memory_optimization'):
                                    opt_info.append("å†…å­˜ä¼˜åŒ–: âœ…")
                                
                                if opt_info:
                                    st.caption(" | ".join(opt_info))
                                
                                # æ˜¾ç¤ºä¼˜åŒ–å»ºè®®
                                if hardware_optimization_result.recommendations:
                                    st.markdown("**ğŸ’¡ ä¼˜åŒ–å»ºè®®**")
                                    for rec in hardware_optimization_result.recommendations:
                                        st.write(f"â€¢ {rec}")
                    
                    
                    
                    # 3.7 å…¶ä»–å¯èƒ½çš„ç†è§£æ–¹å¼ (å¦‚æœæœ‰)
                    if alternatives and len(alternatives) > 0:
                        st.markdown("##### ğŸ¤” å…¶ä»–å¯èƒ½çš„ç†è§£æ–¹å¼")
                        
                        with st.expander(f"æŸ¥çœ‹å…¶ä»– {len(alternatives)} ç§ç†è§£æ–¹å¼", expanded=False):
                            st.markdown("*ç‚¹å‡»ä¸‹æ–¹æŒ‰é’®å¯ä»¥æŒ‰ç…§ä¸åŒçš„ç†è§£æ–¹å¼é‡æ–°æ‰§è¡ŒæŸ¥è¯¢*")
                            
                            for i, alt in enumerate(alternatives):
                                with st.container():
                                    col1, col2 = st.columns([4, 1])
                                    
                                    with col1:
                                        # å¤„ç†å¯èƒ½æ˜¯å­—å…¸æˆ–å¯¹è±¡çš„æƒ…å†µ
                                        if isinstance(alt, dict):
                                            rank = alt.get("rank", i + 1)
                                            natural_desc = alt.get("natural_description", alt.get("description", "æœªçŸ¥ç†è§£æ–¹å¼"))
                                            confidence = alt.get("confidence", 0.0)
                                            key_interpretations = alt.get("key_interpretations", {})
                                        else:
                                            rank = getattr(alt, "rank", i + 1)
                                            natural_desc = getattr(alt, "natural_description", getattr(alt, "description", "æœªçŸ¥ç†è§£æ–¹å¼"))
                                            confidence = getattr(alt, "confidence", 0.0)
                                            key_interpretations = getattr(alt, "key_interpretations", {})
                                        
                                        st.write(f"**ç†è§£æ–¹å¼ {rank}**:")
                                        st.write(f"ğŸ“ {natural_desc}")
                                        st.write(f"ğŸ¯ ç½®ä¿¡åº¦: {confidence:.1%}")
                                        
                                        if key_interpretations:
                                            with st.expander("æŸ¥çœ‹æŠ€æœ¯ç»†èŠ‚", expanded=False):
                                                for term, interp in key_interpretations.items():
                                                    interp_desc = interp.get('desc', '') if isinstance(interp, dict) else str(interp)
                                                    st.caption(f"â€¢ {term}: {interp_desc}")
                                    
                                    with col2:
                                        if st.button(f"ğŸ”„ é€‰æ‹©æ­¤ç†è§£", key=f"select_alt_current_{i}"):
                                            # é‡æ–°æ‰§è¡Œè¿™ç§ç†è§£æ–¹å¼
                                            st.session_state.prompt_trigger = natural_desc
                                            st.rerun()
                                    
                                    st.divider()
                    
                    # 4. æ¨èç›¸å…³é—®é¢˜
                    st.markdown("##### ğŸ¤” æ‚¨å¯èƒ½è¿˜æƒ³äº†è§£")
                    
                    # æ ¹æ®é…ç½®è·å–æ¨èå¼•æ“å®¢æˆ·ç«¯
                    use_ai_recommendations = st.session_state.config.get("enable_ai_recommendations", True)
                    use_separate_api = st.session_state.config.get("recommendation_use_separate_api", False)
                    
                    llm_client_for_rec = None
                    model_name_for_rec = None
                    rec_status = ""
                    
                    if use_ai_recommendations:
                        if use_separate_api:
                            # ä½¿ç”¨ç‹¬ç«‹çš„æ¨èAPIé…ç½®
                            rec_client, rec_model, rec_error = get_recommendation_client(st.session_state.config)
                            if rec_client:
                                llm_client_for_rec = rec_client
                                model_name_for_rec = rec_model
                                rec_status = "ğŸ¤– AIæ™ºèƒ½æ¨è (ç‹¬ç«‹APIé…ç½®)"
                            else:
                                rec_status = f"ğŸ“‹ è§„åˆ™æ¨è (ç‹¬ç«‹APIé”™è¯¯: {rec_error})"
                        else:
                            # ä½¿ç”¨SQLç”Ÿæˆçš„APIé…ç½®
                            if hasattr(agent, 'client') and agent.client:
                                llm_client_for_rec = agent.client
                                model_name_for_rec = agent.model_name if hasattr(agent, 'model_name') else None
                                rec_status = "ğŸ¤– AIæ™ºèƒ½æ¨è (å…±ç”¨SQL API)"
                            else:
                                rec_status = "ğŸ“‹ è§„åˆ™æ¨è (SQL APIä¸å¯ç”¨)"
                    else:
                        rec_status = "ğŸ“‹ è§„åˆ™æ¨è (AIæ¨èå·²ç¦ç”¨)"
                    
                    recommendations = recommendation_engine.generate_recommendations(
                        current_query=prompt_input,
                        result_df=df_result,
                        num_recommendations=3,
                        llm_client=llm_client_for_rec,
                        model_name=model_name_for_rec
                    )
                    
                    # æ˜¾ç¤ºæ¨èæ¨¡å¼çŠ¶æ€
                    st.caption(rec_status)
                    
                    if recommendations:
                        rec_cols = st.columns(len(recommendations))
                        for i, rec in enumerate(recommendations):
                            with rec_cols[i]:
                                if st.button(f"ğŸ’­ {rec}", use_container_width=True, key=f"rec_current_{i}"):
                                    recommendation_engine.record_question_click(rec)
                                    st.session_state.prompt_trigger = rec
                                    st.rerun()
                    
                    # æ„å»ºå®Œæ•´æ¶ˆæ¯ä½“
                    # å°†QueryPossibilityå¯¹è±¡è½¬æ¢ä¸ºå­—å…¸ä»¥ä¾¿åºåˆ—åŒ–
                    alternatives_dict = []
                    if alternatives:
                        for alt in alternatives:
                            if hasattr(alt, '__dict__'):
                                alternatives_dict.append({
                                    "rank": alt.rank,
                                    "description": alt.description,
                                    "confidence": alt.confidence,
                                    "key_interpretations": alt.key_interpretations,
                                    "ambiguity_resolutions": alt.ambiguity_resolutions,
                                    "natural_description": getattr(alt, 'natural_description', alt.description)
                                })
                            else:
                                alternatives_dict.append(alt)
                    
                    selected_possibility_dict = None
                    if selected_possibility and hasattr(selected_possibility, '__dict__'):
                        selected_possibility_dict = {
                            "rank": selected_possibility.rank,
                            "description": selected_possibility.description,
                            "confidence": selected_possibility.confidence,
                            "key_interpretations": selected_possibility.key_interpretations,
                            "ambiguity_resolutions": selected_possibility.ambiguity_resolutions,
                            "natural_description": getattr(selected_possibility, 'natural_description', selected_possibility.description)
                        }
                    
                    # å°†TableRelevanceå¯¹è±¡è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„å­—å…¸æ ¼å¼
                    serializable_table_info = {}
                    for key, value in table_selection_info.items():
                        if key == "final_selection" and value:
                            # å¤„ç†final_selectionä¸­çš„selected_tables
                            selected_tables = value.get("selected_tables", [])
                            serializable_tables = []
                            for table_rel in selected_tables:
                                if hasattr(table_rel, '__dict__'):
                                    # å°†TableRelevanceå¯¹è±¡è½¬æ¢ä¸ºå­—å…¸
                                    table_dict = {
                                        "table_name": table_rel.table_name,
                                        "table_description": table_rel.table_description,
                                        "relevance_score": table_rel.relevance_score,
                                        "semantic_similarity": getattr(table_rel, 'semantic_similarity', 0.0),
                                        "keyword_matches": getattr(table_rel, 'keyword_matches', []),
                                        "matched_columns": getattr(table_rel, 'matched_columns', []),
                                        "reasoning": table_rel.reasoning,
                                        "is_primary": getattr(table_rel, 'is_primary', False),
                                        "is_join_required": getattr(table_rel, 'is_join_required', False)
                                    }
                                    serializable_tables.append(table_dict)
                                else:
                                    serializable_tables.append(table_rel)
                            
                            serializable_table_info[key] = {
                                "selected_tables": serializable_tables,
                                "analysis": value.get("analysis", {})
                            }
                        else:
                            serializable_table_info[key] = value
                    
                    # ç”Ÿæˆå›¾è¡¨æ•°æ®ç”¨äºå¯¼å‡º
                    chart_export_data = []
                    numeric_cols = df_result.select_dtypes(include='number').columns
                    if len(df_result) > 1 and len(numeric_cols) > 0:
                        # è·å–å›¾è¡¨å¯¼å‡ºæ•°æ®
                        chart_export_data = viz_engine.get_chart_export_data(df_result, query_context=prompt_input)
                    
                    msg_data = {
                        "role": "assistant", 
                        "content": final_resp, 
                        "data": df_result.to_dict(orient="records"), 
                        "sql": sql_code,
                        "thought": curr_thought,
                        "selected_possibility": selected_possibility_dict,
                        "alternatives": alternatives_dict,
                        "table_selection_info": serializable_table_info,  # ä½¿ç”¨å¯åºåˆ—åŒ–çš„ç‰ˆæœ¬
                        "charts": chart_export_data,  # æ·»åŠ å›¾è¡¨æ•°æ®
                        "recommendations": recommendations  # ä¿å­˜æ¨èåˆ°æ¶ˆæ¯ä¸­
                    }
                else:
                    # å¤„ç†ç©ºç»“æœ
                    if not st.session_state.config.get("allow_empty_results", True):
                        st.warning("âš ï¸ æŸ¥è¯¢ç»“æœä¸ºç©ºï¼Œç³»ç»Ÿå°†æ ¹æ®é‡è¯•æœºåˆ¶å°è¯•é‡æ–°ç”ŸæˆæŸ¥è¯¢ã€‚")
                        final_resp = "æŸ¥è¯¢ç»“æœä¸ºç©ºï¼Œå»ºè®®è°ƒæ•´æŸ¥è¯¢æ¡ä»¶æˆ–æ£€æŸ¥æ•°æ®èŒƒå›´ã€‚ç³»ç»Ÿå·²è®°å½•æ­¤æ¬¡æŸ¥è¯¢ï¼Œå¯å°è¯•é‡æ–°æé—®ã€‚"
                    else:
                        st.warning("âš ï¸ æŸ¥è¯¢ç»“æœä¸ºç©ºã€‚")
                        final_resp = "æœªæŸ¥è¯¢åˆ°ç¬¦åˆæ¡ä»¶çš„æ•°æ®ã€‚è¿™å¯èƒ½æ˜¯å› ä¸ºï¼š\n\n1. æŸ¥è¯¢æ¡ä»¶è¿‡äºä¸¥æ ¼\n2. æ•°æ®åº“ä¸­ä¸å­˜åœ¨ç›¸å…³æ•°æ®\n3. æ—¶é—´èŒƒå›´æˆ–ç­›é€‰æ¡ä»¶éœ€è¦è°ƒæ•´\n\nå»ºè®®å°è¯•æ”¾å®½æŸ¥è¯¢æ¡ä»¶æˆ–æ£€æŸ¥æ•°æ®èŒƒå›´ã€‚"
                    
                    # å°†TableRelevanceå¯¹è±¡è½¬æ¢ä¸ºå¯åºåˆ—åŒ–çš„å­—å…¸æ ¼å¼ï¼ˆç©ºç»“æœæƒ…å†µï¼‰
                    serializable_table_info = {}
                    for key, value in table_selection_info.items():
                        if key == "final_selection" and value:
                            # å¤„ç†final_selectionä¸­çš„selected_tables
                            selected_tables = value.get("selected_tables", [])
                            serializable_tables = []
                            for table_rel in selected_tables:
                                if hasattr(table_rel, '__dict__'):
                                    # å°†TableRelevanceå¯¹è±¡è½¬æ¢ä¸ºå­—å…¸
                                    table_dict = {
                                        "table_name": table_rel.table_name,
                                        "table_description": table_rel.table_description,
                                        "relevance_score": table_rel.relevance_score,
                                        "semantic_similarity": getattr(table_rel, 'semantic_similarity', 0.0),
                                        "keyword_matches": getattr(table_rel, 'keyword_matches', []),
                                        "matched_columns": getattr(table_rel, 'matched_columns', []),
                                        "reasoning": table_rel.reasoning,
                                        "is_primary": getattr(table_rel, 'is_primary', False),
                                        "is_join_required": getattr(table_rel, 'is_join_required', False)
                                    }
                                    serializable_tables.append(table_dict)
                                else:
                                    serializable_tables.append(table_rel)
                            
                            serializable_table_info[key] = {
                                "selected_tables": serializable_tables,
                                "analysis": value.get("analysis", {})
                            }
                        else:
                            serializable_table_info[key] = value
                    
                    msg_data = {
                        "role": "assistant", 
                        "content": final_resp, 
                        "data": [], 
                        "sql": sql_code, 
                        "thought": curr_thought,
                        "table_selection_info": serializable_table_info  # ä½¿ç”¨å¯åºåˆ—åŒ–çš„ç‰ˆæœ¬
                    }
                
                # 5. åŸå§‹æ•°æ®æŠ˜å æ  (åœ¨ç”Ÿæˆé˜¶æ®µä¹Ÿæ˜¾ç¤ºå‡ºæ¥)
                with st.expander("ğŸ“ åŸå§‹ SQL ä¸æ•°æ®å¯¼å‡º", expanded=False):
                    st.code(sql_code, language="sql")
                    
                    # æ•°æ®å¯¼å‡ºåŠŸèƒ½
                    if has_data:
                        col1, col2 = st.columns(2)
                        
                        with col1:
                            csv_data = export_manager.export_data_to_csv(df_result, "query_result")
                            if csv_data and os.path.exists(csv_data):
                                with open(csv_data, "rb") as csv_file:
                                    st.download_button(
                                        label="ğŸ“Š ä¸‹è½½CSV",
                                        data=csv_file.read(),
                                        file_name=os.path.basename(csv_data),
                                        mime="text/csv",
                                        key="csv_download_current"
                                    )
                        
                        with col2:
                            excel_data = export_manager.export_data_to_excel(df_result, "query_result")
                            if excel_data and os.path.exists(excel_data):
                                with open(excel_data, "rb") as excel_file:
                                    st.download_button(
                                        label="ğŸ“ˆ ä¸‹è½½Excel",
                                        data=excel_file.read(),
                                        file_name=os.path.basename(excel_data),
                                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                        key="excel_download_current"
                                    )

            else:
                # èŠå¤©æ¨¡å¼ - ä½¿ç”¨ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„æç¤º
                final_resp = st.write_stream(agent.chat_stream(final_prompt, messages[:-1]))
                msg_data = {"role": "assistant", "content": final_resp, "thought": curr_thought}

            end_time = time.perf_counter()
            st.session_state.last_total_latency = (end_time - start_time) * 1000
            
            # æŠ€æœ¯å“è¶Šæ€§åå¤„ç† - åç«¯åŠŸèƒ½å¯ç”¨
            if TECHNICAL_EXCELLENCE_AVAILABLE:
                try:
                    # è®°å½•æ“ä½œæ€§èƒ½
                    total_latency = (end_time - start_time) * 1000
                    
                    # ç¡®å®šæ“ä½œç±»å‹
                    operation_type = "text2sql"
                    if df_result is not None and len(df_result) > 0:
                        operation_type = "sql_execution"
                    elif curr_thought:
                        operation_type = "reasoning"
                    
                    # è®°å½•æ€§èƒ½æ•°æ®ï¼ˆåç«¯å¤„ç†ï¼‰
                    tech_manager.record_operation_performance(
                        operation_type=operation_type,
                        operation_id=f"query_{int(time.time())}",
                        latency_ms=total_latency,
                        error_occurred=False,
                        cache_hit=False,  # å¯ä»¥æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
                        input_size=len(prompt_input.encode('utf-8')),
                        context={
                            'has_sql': sql_code is not None,
                            'has_data': df_result is not None,
                            'result_rows': len(df_result) if df_result is not None else 0,
                            'query_complexity': estimated_result_size if 'estimated_result_size' in locals() else 100
                        }
                    )
                    
                except Exception as e:
                    logger.warning(f"æŠ€æœ¯å“è¶Šæ€§åå¤„ç†å¤±è´¥: {e}")
            
            messages.append(msg_data)
            
            # ğŸ§  æ›´æ–°ä¸Šä¸‹æ–‡è®°å¿†
            if CONTEXT_MEMORY_AVAILABLE and st.session_state.get('context_memory_enabled', True):
                try:
                    # è·å–æœ€ç»ˆçš„å›å¤å†…å®¹
                    final_response = msg_data.get("content", "")
                    update_context_after_response(prompt_input, final_response)
                except Exception as e:
                    # è®°å½•é”™è¯¯ä½†ä¸ä¸­æ–­æµç¨‹
                    logger.warning(f"ä¸Šä¸‹æ–‡è®°å¿†æ›´æ–°å¤±è´¥: {e}")
            
            update_session_messages(st.session_state.current_session_id, messages, st.session_state.history)
            
            update_monitor()
            st.rerun()

        except Exception as e:
            status_box.update(label="âŒ è‡´å‘½é”™è¯¯", state="error")
            st.error(str(e))
            
            # ğŸ§  è·Ÿè¸ªé”™è¯¯
            if CONTEXT_MEMORY_AVAILABLE and st.session_state.get('context_memory_enabled', True):
                try:
                    context_integration = get_context_integration()
                    context_integration.track_error_resolution(
                        str(e), 
                        "æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯ç»™ç”¨æˆ·", 
                        success=False
                    )
                except Exception as context_error:
                    # é¿å…é”™è¯¯å¤„ç†ä¸­çš„é”™è¯¯å¯¼è‡´ç³»ç»Ÿå´©æºƒ
                    logger.warning(f"é”™è¯¯è·Ÿè¸ªå¤±è´¥: {context_error}")