"""
Intel DeepInsight å¢å¼ºæ€§èƒ½ç›‘æ§ç³»ç»Ÿ
å®æ—¶æ€§èƒ½æŒ‡æ ‡æ”¶é›†ã€å†å²è¶‹åŠ¿åˆ†æå’Œå¼‚å¸¸æ£€æµ‹
"""
import psutil
import time
import json
import os
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Tuple
import pandas as pd
import plotly.graph_objects as go
from plotly.subplots import make_subplots

class PerformanceMonitor:
    """å¢å¼ºæ€§èƒ½ç›‘æ§å™¨"""
    
    def __init__(self):
        self.metrics_file = "data/performance_metrics.json"
        self.max_history_hours = 24
        self._ensure_metrics_file()
    
    def _ensure_metrics_file(self):
        """ç¡®ä¿æ€§èƒ½æŒ‡æ ‡æ–‡ä»¶å­˜åœ¨"""
        os.makedirs("data", exist_ok=True)
        if not os.path.exists(self.metrics_file):
            with open(self.metrics_file, 'w', encoding='utf-8') as f:
                json.dump({"metrics": []}, f, indent=2)
    
    def collect_current_metrics(self, rag_latency: float = 0.0, total_latency: float = 0.0) -> Dict:
        """æ”¶é›†å½“å‰æ€§èƒ½æŒ‡æ ‡"""
        try:
            # ç³»ç»ŸæŒ‡æ ‡
            cpu_percent = psutil.cpu_percent(interval=0.1)
            memory = psutil.virtual_memory()
            disk = psutil.disk_usage('/')
            
            # ç½‘ç»œæŒ‡æ ‡ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            try:
                network = psutil.net_io_counters()
                network_sent = network.bytes_sent
                network_recv = network.bytes_recv
            except:
                network_sent = network_recv = 0
            
            metrics = {
                "timestamp": datetime.now().isoformat(),
                "cpu_percent": round(cpu_percent, 1),
                "memory_percent": round(memory.percent, 1),
                "memory_used_gb": round(memory.used / (1024**3), 2),
                "memory_total_gb": round(memory.total / (1024**3), 2),
                "disk_percent": round(disk.percent, 1),
                "disk_free_gb": round(disk.free / (1024**3), 2),
                "rag_latency_ms": round(rag_latency, 2),
                "total_latency_ms": round(total_latency, 2),
                "network_sent_mb": round(network_sent / (1024**2), 2),
                "network_recv_mb": round(network_recv / (1024**2), 2)
            }
            
            return metrics
        except Exception as e:
            print(f"æ€§èƒ½æŒ‡æ ‡æ”¶é›†å¤±è´¥: {e}")
            return {}
    
    def save_metrics(self, metrics: Dict):
        """ä¿å­˜æ€§èƒ½æŒ‡æ ‡åˆ°å†å²è®°å½•"""
        try:
            with open(self.metrics_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            data["metrics"].append(metrics)
            
            # æ¸…ç†è¶…è¿‡24å°æ—¶çš„æ—§æ•°æ®
            cutoff_time = datetime.now() - timedelta(hours=self.max_history_hours)
            data["metrics"] = [
                m for m in data["metrics"] 
                if datetime.fromisoformat(m["timestamp"]) > cutoff_time
            ]
            
            with open(self.metrics_file, 'w', encoding='utf-8') as f:
                json.dump(data, f, indent=2)
        except Exception as e:
            print(f"ä¿å­˜æ€§èƒ½æŒ‡æ ‡å¤±è´¥: {e}")
    
    def get_historical_metrics(self, hours: int = 1) -> List[Dict]:
        """è·å–å†å²æ€§èƒ½æŒ‡æ ‡"""
        try:
            with open(self.metrics_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            cutoff_time = datetime.now() - timedelta(hours=hours)
            recent_metrics = [
                m for m in data["metrics"]
                if datetime.fromisoformat(m["timestamp"]) > cutoff_time
            ]
            
            return recent_metrics
        except Exception as e:
            print(f"è·å–å†å²æŒ‡æ ‡å¤±è´¥: {e}")
            return []
    
    def detect_anomalies(self, current_metrics: Dict) -> List[str]:
        """æ£€æµ‹æ€§èƒ½å¼‚å¸¸"""
        anomalies = []
        
        # CPUå¼‚å¸¸æ£€æµ‹
        if current_metrics.get("cpu_percent", 0) > 80:
            anomalies.append("ğŸ”¥ CPUä½¿ç”¨ç‡è¿‡é«˜ (>80%)")
        
        # å†…å­˜å¼‚å¸¸æ£€æµ‹
        if current_metrics.get("memory_percent", 0) > 85:
            anomalies.append("ğŸ’¾ å†…å­˜ä½¿ç”¨ç‡è¿‡é«˜ (>85%)")
        
        # ç£ç›˜å¼‚å¸¸æ£€æµ‹
        if current_metrics.get("disk_percent", 0) > 90:
            anomalies.append("ğŸ’¿ ç£ç›˜ç©ºé—´ä¸è¶³ (<10%)")
        
        # å»¶è¿Ÿå¼‚å¸¸æ£€æµ‹
        if current_metrics.get("total_latency_ms", 0) > 5000:
            anomalies.append("â±ï¸ å“åº”å»¶è¿Ÿè¿‡é«˜ (>5s)")
        
        if current_metrics.get("rag_latency_ms", 0) > 1000:
            anomalies.append("ğŸ” RAGæ£€ç´¢å»¶è¿Ÿè¿‡é«˜ (>1s)")
        
        return anomalies
    
    def get_optimization_suggestions(self, current_metrics: Dict, anomalies: List[str]) -> List[str]:
        """è·å–ä¼˜åŒ–å»ºè®®"""
        suggestions = []
        
        if any("CPU" in anomaly for anomaly in anomalies):
            suggestions.append("ğŸ’¡ å»ºè®®å…³é—­å…¶ä»–åº”ç”¨ç¨‹åºä»¥é‡Šæ”¾CPUèµ„æº")
            suggestions.append("ğŸ’¡ è€ƒè™‘é™ä½å¹¶å‘æŸ¥è¯¢æ•°é‡")
        
        if any("å†…å­˜" in anomaly for anomaly in anomalies):
            suggestions.append("ğŸ’¡ å»ºè®®é‡å¯åº”ç”¨ä»¥é‡Šæ”¾å†…å­˜")
            suggestions.append("ğŸ’¡ è€ƒè™‘æ¸…ç†æµè§ˆå™¨ç¼“å­˜")
        
        if any("å»¶è¿Ÿ" in anomaly for anomaly in anomalies):
            suggestions.append("ğŸ’¡ æ£€æŸ¥ç½‘ç»œè¿æ¥çŠ¶æ€")
            suggestions.append("ğŸ’¡ å°è¯•ä½¿ç”¨æ›´ç®€å•çš„æŸ¥è¯¢")
        
        if any("RAG" in anomaly for anomaly in anomalies):
            suggestions.append("ğŸ’¡ OpenVINOæ¨¡å‹å¯èƒ½éœ€è¦é‡æ–°åŠ è½½")
            suggestions.append("ğŸ’¡ æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å®Œæ•´")
        
        # é€šç”¨ä¼˜åŒ–å»ºè®®
        if not anomalies:
            if current_metrics.get("cpu_percent", 0) > 50:
                suggestions.append("âœ¨ ç³»ç»Ÿè¿è¡Œè‰¯å¥½ï¼Œå¯è€ƒè™‘å¤„ç†æ›´å¤æ‚çš„æŸ¥è¯¢")
            else:
                suggestions.append("ğŸš€ ç³»ç»Ÿæ€§èƒ½ä¼˜ç§€ï¼Œè¿è¡ŒçŠ¶æ€è‰¯å¥½")
        
        return suggestions
    
    def create_performance_trend_chart(self, hours: int = 1) -> Optional[go.Figure]:
        """åˆ›å»ºæ€§èƒ½è¶‹åŠ¿å›¾"""
        try:
            metrics = self.get_historical_metrics(hours)
            if len(metrics) < 2:
                return None
            
            df = pd.DataFrame(metrics)
            df['timestamp'] = pd.to_datetime(df['timestamp'])
            
            # åˆ›å»ºå­å›¾
            fig = make_subplots(
                rows=2, cols=2,
                subplot_titles=('CPUä½¿ç”¨ç‡', 'å†…å­˜ä½¿ç”¨ç‡', 'RAGå»¶è¿Ÿ', 'æ€»å»¶è¿Ÿ'),
                specs=[[{"secondary_y": False}, {"secondary_y": False}],
                       [{"secondary_y": False}, {"secondary_y": False}]]
            )
            
            # CPUè¶‹åŠ¿
            fig.add_trace(
                go.Scatter(x=df['timestamp'], y=df['cpu_percent'], 
                          name='CPU %', line=dict(color='#FF6B35')),
                row=1, col=1
            )
            
            # å†…å­˜è¶‹åŠ¿
            fig.add_trace(
                go.Scatter(x=df['timestamp'], y=df['memory_percent'], 
                          name='Memory %', line=dict(color='#28A745')),
                row=1, col=2
            )
            
            # RAGå»¶è¿Ÿè¶‹åŠ¿
            fig.add_trace(
                go.Scatter(x=df['timestamp'], y=df['rag_latency_ms'], 
                          name='RAGå»¶è¿Ÿ (ms)', line=dict(color='#0068B5')),
                row=2, col=1
            )
            
            # æ€»å»¶è¿Ÿè¶‹åŠ¿
            fig.add_trace(
                go.Scatter(x=df['timestamp'], y=df['total_latency_ms'], 
                          name='æ€»å»¶è¿Ÿ (ms)', line=dict(color='#FFC107')),
                row=2, col=2
            )
            
            fig.update_layout(
                height=400,
                showlegend=False,
                title_text=f"è¿‡å»{hours}å°æ—¶æ€§èƒ½è¶‹åŠ¿"
            )
            
            return fig
        except Exception as e:
            print(f"åˆ›å»ºè¶‹åŠ¿å›¾å¤±è´¥: {e}")
            return None
    
    def get_performance_summary(self) -> Dict:
        """è·å–æ€§èƒ½æ‘˜è¦"""
        try:
            recent_metrics = self.get_historical_metrics(1)  # è¿‡å»1å°æ—¶
            if not recent_metrics:
                return {}
            
            df = pd.DataFrame(recent_metrics)
            
            summary = {
                "avg_cpu": round(df['cpu_percent'].mean(), 1),
                "max_cpu": round(df['cpu_percent'].max(), 1),
                "avg_memory": round(df['memory_percent'].mean(), 1),
                "max_memory": round(df['memory_percent'].max(), 1),
                "avg_rag_latency": round(df['rag_latency_ms'].mean(), 1),
                "max_rag_latency": round(df['rag_latency_ms'].max(), 1),
                "total_queries": len([m for m in recent_metrics if m.get('total_latency_ms', 0) > 0]),
                "avg_query_latency": round(df[df['total_latency_ms'] > 0]['total_latency_ms'].mean(), 1) if len(df[df['total_latency_ms'] > 0]) > 0 else 0
            }
            
            return summary
        except Exception as e:
            print(f"è·å–æ€§èƒ½æ‘˜è¦å¤±è´¥: {e}")
            return {}
    
    def cleanup_old_metrics(self):
        """æ¸…ç†æ—§çš„æ€§èƒ½æŒ‡æ ‡"""
        try:
            with open(self.metrics_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            cutoff_time = datetime.now() - timedelta(hours=self.max_history_hours)
            original_count = len(data["metrics"])
            
            data["metrics"] = [
                m for m in data["metrics"]
                if datetime.fromisoformat(m["timestamp"]) > cutoff_time
            ]
            
            cleaned_count = original_count - len(data["metrics"])
            if cleaned_count > 0:
                with open(self.metrics_file, 'w', encoding='utf-8') as f:
                    json.dump(data, f, indent=2)
                print(f"å·²æ¸…ç† {cleaned_count} æ¡æ—§æ€§èƒ½è®°å½•")
        except Exception as e:
            print(f"æ¸…ç†æ€§èƒ½æŒ‡æ ‡å¤±è´¥: {e}")

# å…¨å±€å®ä¾‹
performance_monitor = PerformanceMonitor()