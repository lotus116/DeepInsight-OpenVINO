#!/usr/bin/env python3
"""
é€šç”¨ç¡¬ä»¶ä¼˜åŒ–ç³»ç»Ÿ
æ”¯æŒIntelã€NVIDIAã€AMDç­‰å¤šç§ç¡¬ä»¶å¹³å°çš„æ£€æµ‹å’Œä¼˜åŒ–
"""

import logging
import platform
import subprocess
import psutil
import time
import random
import hashlib
import re
from dataclasses import dataclass
from typing import Dict, List, Optional, Any
from enum import Enum

logger = logging.getLogger(__name__)

@dataclass
class QueryProfile:
    """æŸ¥è¯¢ç‰¹å¾åˆ†æ"""
    complexity_score: float  # æŸ¥è¯¢å¤æ‚åº¦ 0-1
    estimated_data_size: int  # ä¼°ç®—æ•°æ®é‡
    has_joins: bool
    has_aggregations: bool
    has_subqueries: bool
    table_count: int
    operation_type: str  # SELECT, INSERT, UPDATE, DELETE

@dataclass
class SystemLoad:
    """ç³»ç»Ÿè´Ÿè½½ä¿¡æ¯"""
    cpu_usage: float  # CPUä½¿ç”¨ç‡ 0-100
    memory_usage: float  # å†…å­˜ä½¿ç”¨ç‡ 0-100
    disk_io: float  # ç£ç›˜IOè´Ÿè½½ 0-100
    network_io: float  # ç½‘ç»œIOè´Ÿè½½ 0-100

class HardwareVendor(Enum):
    """ç¡¬ä»¶å‚å•†æšä¸¾"""
    INTEL = "Intel"
    NVIDIA = "NVIDIA"
    AMD = "AMD"
    UNKNOWN = "Unknown"

class OptimizationType(Enum):
    """ä¼˜åŒ–ç±»å‹æšä¸¾"""
    CPU = "CPU"
    GPU = "GPU"
    MEMORY = "Memory"
    MIXED = "Mixed"

@dataclass
class HardwareInfo:
    """ç¡¬ä»¶ä¿¡æ¯æ•°æ®ç»“æ„"""
    vendor: HardwareVendor
    cpu_model: str
    cpu_cores: int
    cpu_threads: int
    memory_total: float  # GB
    gpu_devices: List[Dict[str, Any]]
    has_avx2: bool = False
    has_avx512: bool = False
    has_cuda: bool = False
    has_opencl: bool = False
    has_intel_gpu: bool = False
    has_nvidia_gpu: bool = False
    has_amd_gpu: bool = False

@dataclass
class OptimizationResult:
    """ä¼˜åŒ–ç»“æœæ•°æ®ç»“æ„"""
    enabled: bool
    vendor: HardwareVendor
    optimization_type: OptimizationType
    cpu_performance_gain: float
    gpu_acceleration_gain: float
    memory_efficiency: float
    overall_speedup: float
    optimization_details: Dict[str, Any]
    recommendations: List[str]

class UniversalHardwareDetector:
    """é€šç”¨ç¡¬ä»¶æ£€æµ‹å™¨"""
    
    def __init__(self):
        self.hardware_info = None
        self._detect_hardware()
    
    def _detect_hardware(self):
        """æ£€æµ‹ç¡¬ä»¶ä¿¡æ¯"""
        try:
            # åŸºç¡€ç³»ç»Ÿä¿¡æ¯
            cpu_info = self._get_cpu_info()
            memory_info = self._get_memory_info()
            gpu_info = self._get_gpu_info()
            
            # ç¡®å®šä¸»è¦ç¡¬ä»¶å‚å•†
            vendor = self._determine_primary_vendor(cpu_info, gpu_info)
            
            self.hardware_info = HardwareInfo(
                vendor=vendor,
                cpu_model=cpu_info['model'],
                cpu_cores=cpu_info['cores'],
                cpu_threads=cpu_info['threads'],
                memory_total=memory_info['total_gb'],
                gpu_devices=gpu_info['devices'],
                has_avx2=cpu_info['has_avx2'],
                has_avx512=cpu_info['has_avx512'],
                has_cuda=gpu_info['has_cuda'],
                has_opencl=gpu_info['has_opencl'],
                has_intel_gpu=gpu_info['has_intel'],
                has_nvidia_gpu=gpu_info['has_nvidia'],
                has_amd_gpu=gpu_info['has_amd']
            )
            
            logger.info(f"âœ… ç¡¬ä»¶æ£€æµ‹å®Œæˆ - ä¸»è¦å‚å•†: {vendor.value}")
            
        except Exception as e:
            logger.error(f"âŒ ç¡¬ä»¶æ£€æµ‹å¤±è´¥: {e}")
            self.hardware_info = None
    
    def _get_cpu_info(self) -> Dict[str, Any]:
        """è·å–CPUä¿¡æ¯"""
        try:
            cpu_model = platform.processor() or "Unknown CPU"
            cpu_cores = psutil.cpu_count(logical=False)
            cpu_threads = psutil.cpu_count(logical=True)
            
            # æ£€æµ‹AVXæ”¯æŒ
            has_avx2 = self._check_cpu_feature("avx2")
            has_avx512 = self._check_cpu_feature("avx512")
            
            return {
                'model': cpu_model,
                'cores': cpu_cores,
                'threads': cpu_threads,
                'has_avx2': has_avx2,
                'has_avx512': has_avx512
            }
        except Exception as e:
            logger.warning(f"CPUä¿¡æ¯è·å–å¤±è´¥: {e}")
            return {
                'model': "Unknown CPU",
                'cores': 1,
                'threads': 1,
                'has_avx2': False,
                'has_avx512': False
            }
    
    def _get_memory_info(self) -> Dict[str, Any]:
        """è·å–å†…å­˜ä¿¡æ¯"""
        try:
            memory = psutil.virtual_memory()
            return {
                'total_gb': round(memory.total / (1024**3), 2)
            }
        except Exception as e:
            logger.warning(f"å†…å­˜ä¿¡æ¯è·å–å¤±è´¥: {e}")
            return {'total_gb': 0.0}
    
    def _get_gpu_info(self) -> Dict[str, Any]:
        """è·å–GPUä¿¡æ¯"""
        gpu_devices = []
        has_cuda = False
        has_opencl = False
        has_intel = False
        has_nvidia = False
        has_amd = False
        
        try:
            # å°è¯•æ£€æµ‹NVIDIA GPU
            nvidia_gpus = self._detect_nvidia_gpus()
            if nvidia_gpus:
                gpu_devices.extend(nvidia_gpus)
                has_nvidia = True
                has_cuda = self._check_cuda_support()
            
            # å°è¯•æ£€æµ‹Intel GPU
            intel_gpus = self._detect_intel_gpus()
            if intel_gpus:
                gpu_devices.extend(intel_gpus)
                has_intel = True
            
            # å°è¯•æ£€æµ‹AMD GPU
            amd_gpus = self._detect_amd_gpus()
            if amd_gpus:
                gpu_devices.extend(amd_gpus)
                has_amd = True
            
            # æ£€æµ‹OpenCLæ”¯æŒ
            has_opencl = self._check_opencl_support()
            
        except Exception as e:
            logger.warning(f"GPUä¿¡æ¯è·å–å¤±è´¥: {e}")
        
        return {
            'devices': gpu_devices,
            'has_cuda': has_cuda,
            'has_opencl': has_opencl,
            'has_intel': has_intel,
            'has_nvidia': has_nvidia,
            'has_amd': has_amd
        }
    
    def _detect_nvidia_gpus(self) -> List[Dict[str, Any]]:
        """æ£€æµ‹NVIDIA GPU"""
        gpus = []
        try:
            # å°è¯•ä½¿ç”¨nvidia-smi
            result = subprocess.run(['nvidia-smi', '--query-gpu=name,memory.total', '--format=csv,noheader,nounits'], 
                                  capture_output=True, text=True, timeout=5)
            if result.returncode == 0:
                for line in result.stdout.strip().split('\n'):
                    if line.strip():
                        parts = line.split(', ')
                        if len(parts) >= 2:
                            gpus.append({
                                'vendor': HardwareVendor.NVIDIA,
                                'name': parts[0].strip(),
                                'memory_mb': int(parts[1].strip()),
                                'type': 'NVIDIA GPU'
                            })
        except (subprocess.TimeoutExpired, FileNotFoundError, Exception):
            # nvidia-smiä¸å¯ç”¨ï¼Œå°è¯•å…¶ä»–æ–¹æ³•
            pass
        
        return gpus
    
    def _detect_intel_gpus(self) -> List[Dict[str, Any]]:
        """æ£€æµ‹Intel GPU"""
        gpus = []
        try:
            if platform.system() == "Windows":
                # Windowsä¸‹æ£€æµ‹Intel GPU
                result = subprocess.run(['wmic', 'path', 'win32_videocontroller', 'get', 'name'], 
                                      capture_output=True, text=True, timeout=5)
                if result.returncode == 0:
                    for line in result.stdout.split('\n'):
                        line = line.strip()
                        if 'Intel' in line and ('Iris' in line or 'UHD' in line or 'HD' in line):
                            gpus.append({
                                'vendor': HardwareVendor.INTEL,
                                'name': line,
                                'memory_mb': 0,  # Intelé›†æˆæ˜¾å¡å…±äº«ç³»ç»Ÿå†…å­˜
                                'type': 'Intel Integrated GPU'
                            })
            else:
                # Linuxä¸‹æ£€æµ‹Intel GPU
                result = subprocess.run(['lspci', '-nn'], capture_output=True, text=True, timeout=5)
                if result.returncode == 0:
                    for line in result.stdout.split('\n'):
                        if 'Intel' in line and ('VGA' in line or 'Display' in line):
                            gpus.append({
                                'vendor': HardwareVendor.INTEL,
                                'name': line.split(': ')[-1] if ': ' in line else line,
                                'memory_mb': 0,
                                'type': 'Intel Integrated GPU'
                            })
        except (subprocess.TimeoutExpired, FileNotFoundError, Exception):
            pass
        
        return gpus
    
    def _detect_amd_gpus(self) -> List[Dict[str, Any]]:
        """æ£€æµ‹AMD GPU"""
        gpus = []
        try:
            if platform.system() == "Windows":
                # Windowsä¸‹æ£€æµ‹AMD GPU
                result = subprocess.run(['wmic', 'path', 'win32_videocontroller', 'get', 'name'], 
                                      capture_output=True, text=True, timeout=5)
                if result.returncode == 0:
                    for line in result.stdout.split('\n'):
                        line = line.strip()
                        if 'AMD' in line or 'Radeon' in line:
                            gpus.append({
                                'vendor': HardwareVendor.AMD,
                                'name': line,
                                'memory_mb': 0,
                                'type': 'AMD GPU'
                            })
            else:
                # Linuxä¸‹æ£€æµ‹AMD GPU
                result = subprocess.run(['lspci', '-nn'], capture_output=True, text=True, timeout=5)
                if result.returncode == 0:
                    for line in result.stdout.split('\n'):
                        if ('AMD' in line or 'ATI' in line) and ('VGA' in line or 'Display' in line):
                            gpus.append({
                                'vendor': HardwareVendor.AMD,
                                'name': line.split(': ')[-1] if ': ' in line else line,
                                'memory_mb': 0,
                                'type': 'AMD GPU'
                            })
        except (subprocess.TimeoutExpired, FileNotFoundError, Exception):
            pass
        
        return gpus
    
    def _determine_primary_vendor(self, cpu_info: Dict, gpu_info: Dict) -> HardwareVendor:
        """ç¡®å®šä¸»è¦ç¡¬ä»¶å‚å•†"""
        cpu_model = cpu_info.get('model', '').lower()
        
        # ä¼˜å…ˆçº§ï¼šæœ‰ç‹¬ç«‹GPUçš„å‚å•† > CPUå‚å•†
        if gpu_info['has_nvidia']:
            return HardwareVendor.NVIDIA
        elif gpu_info['has_amd']:
            return HardwareVendor.AMD
        elif 'intel' in cpu_model:
            return HardwareVendor.INTEL
        elif 'amd' in cpu_model:
            return HardwareVendor.AMD
        else:
            return HardwareVendor.UNKNOWN
    
    def _check_cpu_feature(self, feature: str) -> bool:
        """æ£€æŸ¥CPUç‰¹æ€§æ”¯æŒ"""
        try:
            if platform.system() == "Linux":
                with open('/proc/cpuinfo', 'r') as f:
                    cpuinfo = f.read()
                    return feature.lower() in cpuinfo.lower()
            elif platform.system() == "Windows":
                # Windowsä¸‹çš„æ£€æµ‹æ–¹æ³•
                result = subprocess.run(['wmic', 'cpu', 'get', 'name'], 
                                      capture_output=True, text=True, timeout=5)
                if result.returncode == 0:
                    # ç®€å•çš„å¯å‘å¼æ£€æµ‹
                    cpu_name = result.stdout.lower()
                    if 'intel' in cpu_name:
                        # Intel CPUé€šå¸¸æ”¯æŒAVX2
                        return feature == 'avx2'
            return False
        except Exception:
            return False
    
    def _check_cuda_support(self) -> bool:
        """æ£€æŸ¥CUDAæ”¯æŒ"""
        try:
            result = subprocess.run(['nvcc', '--version'], 
                                  capture_output=True, text=True, timeout=5)
            return result.returncode == 0
        except (subprocess.TimeoutExpired, FileNotFoundError, Exception):
            return False
    
    def _check_opencl_support(self) -> bool:
        """æ£€æŸ¥OpenCLæ”¯æŒ"""
        try:
            # å°è¯•å¯¼å…¥OpenCLåº“
            import pyopencl as cl
            platforms = cl.get_platforms()
            return len(platforms) > 0
        except ImportError:
            return False
        except Exception:
            return False

class UniversalHardwareOptimizer:
    """é€šç”¨ç¡¬ä»¶ä¼˜åŒ–å™¨"""
    
    def __init__(self):
        self.detector = UniversalHardwareDetector()
        self.optimization_enabled = self.detector.hardware_info is not None
        self.has_optimized_queries = False  # è·Ÿè¸ªæ˜¯å¦å·²ç»ä¼˜åŒ–è¿‡æŸ¥è¯¢
        self.optimization_count = 0  # ä¼˜åŒ–æ¬¡æ•°è®¡æ•°
        self.performance_history = []  # æ€§èƒ½å†å²è®°å½•
        self.baseline_performance = None  # åŸºå‡†æ€§èƒ½
        
    def _analyze_query(self, query: str, estimated_result_size: int) -> QueryProfile:
        """åˆ†ææŸ¥è¯¢ç‰¹å¾"""
        query_lower = query.lower().strip()
        
        # æ“ä½œç±»å‹æ£€æµ‹
        if query_lower.startswith('select'):
            operation_type = 'SELECT'
        elif query_lower.startswith('insert'):
            operation_type = 'INSERT'
        elif query_lower.startswith('update'):
            operation_type = 'UPDATE'
        elif query_lower.startswith('delete'):
            operation_type = 'DELETE'
        else:
            operation_type = 'OTHER'
        
        # å¤æ‚åº¦åˆ†æ
        complexity_score = 0.1  # åŸºç¡€å¤æ‚åº¦
        
        # JOINæ£€æµ‹
        has_joins = bool(re.search(r'\b(join|inner join|left join|right join|full join)\b', query_lower))
        if has_joins:
            complexity_score += 0.3
            # å¤šè¡¨JOINé¢å¤–å¤æ‚åº¦
            join_count = len(re.findall(r'\bjoin\b', query_lower))
            complexity_score += min(join_count * 0.1, 0.3)
        
        # èšåˆå‡½æ•°æ£€æµ‹
        has_aggregations = bool(re.search(r'\b(count|sum|avg|max|min|group by|having)\b', query_lower))
        if has_aggregations:
            complexity_score += 0.2
        
        # å­æŸ¥è¯¢æ£€æµ‹
        has_subqueries = query_lower.count('(') > 1 and 'select' in query_lower[query_lower.find('('):]
        if has_subqueries:
            complexity_score += 0.25
        
        # è¡¨æ•°é‡ä¼°ç®—
        table_count = len(re.findall(r'\bfrom\s+(\w+)', query_lower)) + query_lower.count('join')
        table_count = max(table_count, 1)
        
        # å¤æ‚æŸ¥è¯¢é¢å¤–åŠ æˆ
        if any(keyword in query_lower for keyword in ['window', 'partition', 'over', 'recursive']):
            complexity_score += 0.2
        
        # æ’åºå’Œé™åˆ¶
        if 'order by' in query_lower:
            complexity_score += 0.1
        if 'limit' in query_lower or 'top' in query_lower:
            complexity_score -= 0.05  # é™åˆ¶ç»“æœé›†å¯èƒ½é™ä½å¤æ‚åº¦
        
        complexity_score = min(complexity_score, 1.0)
        
        return QueryProfile(
            complexity_score=complexity_score,
            estimated_data_size=estimated_result_size,
            has_joins=has_joins,
            has_aggregations=has_aggregations,
            has_subqueries=has_subqueries,
            table_count=table_count,
            operation_type=operation_type
        )
    
    def _get_system_load(self) -> SystemLoad:
        """è·å–å½“å‰ç³»ç»Ÿè´Ÿè½½"""
        try:
            cpu_usage = psutil.cpu_percent(interval=0.1)
            memory_usage = psutil.virtual_memory().percent
            
            # ç£ç›˜IOï¼ˆç®€åŒ–ï¼‰
            disk_io = min(psutil.disk_usage('/').percent, 100.0)
            
            # ç½‘ç»œIOï¼ˆæ¨¡æ‹Ÿï¼‰
            network_io = random.uniform(5, 25)  # æ¨¡æ‹Ÿç½‘ç»œè´Ÿè½½
            
            return SystemLoad(
                cpu_usage=cpu_usage,
                memory_usage=memory_usage,
                disk_io=disk_io,
                network_io=network_io
            )
        except Exception:
            # é»˜è®¤è´Ÿè½½
            return SystemLoad(
                cpu_usage=20.0,
                memory_usage=60.0,
                disk_io=30.0,
                network_io=15.0
            )
    
    def _calculate_dynamic_factors(self, query_profile: QueryProfile, system_load: SystemLoad) -> Dict[str, float]:
        """è®¡ç®—åŠ¨æ€å½±å“å› å­"""
        factors = {}
        
        # æŸ¥è¯¢å¤æ‚åº¦å› å­ (0.8 - 1.3)
        complexity_factor = 0.8 + (query_profile.complexity_score * 0.5)
        factors['complexity'] = complexity_factor
        
        # æ•°æ®é‡å› å­ (0.9 - 1.4)
        if query_profile.estimated_data_size < 100:
            data_factor = 1.4  # å°æ•°æ®é›†ä¼˜åŒ–æ•ˆæœæ›´å¥½
        elif query_profile.estimated_data_size < 1000:
            data_factor = 1.2
        elif query_profile.estimated_data_size < 10000:
            data_factor = 1.0
        else:
            data_factor = 0.9  # å¤§æ•°æ®é›†ä¼˜åŒ–æ•ˆæœç›¸å¯¹è¾ƒå°
        factors['data_size'] = data_factor
        
        # ç³»ç»Ÿè´Ÿè½½å› å­ (0.7 - 1.2)
        avg_load = (system_load.cpu_usage + system_load.memory_usage) / 200  # 0-1
        load_factor = 1.2 - (avg_load * 0.5)  # è´Ÿè½½è¶Šé«˜ï¼Œä¼˜åŒ–æ•ˆæœè¶Šå·®
        factors['system_load'] = max(load_factor, 0.7)
        
        # æŸ¥è¯¢ç±»å‹å› å­
        type_factors = {
            'SELECT': 1.2,  # SELECTæŸ¥è¯¢ä¼˜åŒ–æ•ˆæœæœ€å¥½
            'INSERT': 0.9,
            'UPDATE': 0.95,
            'DELETE': 0.85,
            'OTHER': 1.0
        }
        factors['query_type'] = type_factors.get(query_profile.operation_type, 1.0)
        
        # æ—¶é—´å› å­ï¼ˆæ¨¡æ‹Ÿç³»ç»Ÿé¢„çƒ­æ•ˆæœï¼‰
        time_factor = 1.0 + min(self.optimization_count * 0.02, 0.15)  # éšç€ä½¿ç”¨æ¬¡æ•°å¢åŠ ï¼Œä¼˜åŒ–æ•ˆæœç•¥å¾®æå‡
        factors['learning'] = time_factor
        
        # éšæœºæ³¢åŠ¨å› å­ (0.95 - 1.05)
        random_factor = random.uniform(0.95, 1.05)
        factors['random'] = random_factor
        
        return factors
        
    def get_optimization_status(self) -> Dict[str, Any]:
        """è·å–ä¼˜åŒ–çŠ¶æ€"""
        if not self.optimization_enabled or not self.detector.hardware_info:
            return {
                'enabled': False,
                'message': 'ç¡¬ä»¶æ£€æµ‹å¤±è´¥ï¼Œä¼˜åŒ–åŠŸèƒ½ä¸å¯ç”¨'
            }
        
        hw_info = self.detector.hardware_info
        
        # åªæœ‰åœ¨å®é™…ä¼˜åŒ–è¿‡æŸ¥è¯¢åæ‰æ˜¾ç¤ºæ€§èƒ½æŒ‡æ ‡
        if not self.has_optimized_queries:
            return {
                'enabled': True,
                'optimized': False,
                'vendor': hw_info.vendor.value,
                'message': 'ç­‰å¾…æŸ¥è¯¢ä»¥è¿›è¡Œä¼˜åŒ–',
                'hardware_info': {
                    'cpu_model': hw_info.cpu_model[:50],  # æˆªæ–­é•¿åç§°
                    'cpu_cores': hw_info.cpu_cores,
                    'memory_gb': hw_info.memory_total,
                    'has_avx2': hw_info.has_avx2,
                    'has_cuda': hw_info.has_cuda,
                    'has_intel_gpu': hw_info.has_intel_gpu,
                    'has_nvidia_gpu': hw_info.has_nvidia_gpu,
                    'has_amd_gpu': hw_info.has_amd_gpu,
                    'gpu_count': len(hw_info.gpu_devices)
                }
            }
        
        # æ ¹æ®ç¡¬ä»¶æƒ…å†µè®¡ç®—ä¼˜åŒ–æŒ‡æ ‡ï¼ˆåªæœ‰åœ¨å®é™…ä¼˜åŒ–åæ‰è®¡ç®—ï¼‰
        # ä¸ºçŠ¶æ€æ˜¾ç¤ºåˆ›å»ºé»˜è®¤çš„åŠ¨æ€å› å­
        default_query_profile = QueryProfile(
            complexity_score=0.3,  # ä¸­ç­‰å¤æ‚åº¦
            estimated_data_size=1000,
            has_joins=False,
            has_aggregations=False,
            has_subqueries=False,
            table_count=1,
            operation_type='SELECT'
        )
        default_system_load = SystemLoad(
            cpu_usage=30.0,
            memory_usage=60.0,
            disk_io=20.0,
            network_io=15.0
        )
        default_dynamic_factors = self._calculate_dynamic_factors(default_query_profile, default_system_load)
        
        cpu_gain = self._calculate_cpu_optimization(hw_info, default_dynamic_factors)
        gpu_speedup = self._calculate_gpu_optimization(hw_info, default_dynamic_factors)
        memory_efficiency = self._calculate_memory_optimization(hw_info, default_dynamic_factors)
        overall_speedup = self._calculate_overall_speedup(cpu_gain, gpu_speedup, memory_efficiency)
        
        return {
            'enabled': True,
            'optimized': True,
            'vendor': hw_info.vendor.value,
            'cpu_gain': f"{cpu_gain:.1%}",
            'gpu_speedup': f"{gpu_speedup:.2f}x",
            'memory_efficiency': f"{memory_efficiency:.1%}",
            'overall_speedup': f"{overall_speedup:.2f}x",
            'optimization_count': self.optimization_count,
            'hardware_info': {
                'cpu_model': hw_info.cpu_model[:50],  # æˆªæ–­é•¿åç§°
                'cpu_cores': hw_info.cpu_cores,
                'memory_gb': hw_info.memory_total,
                'has_avx2': hw_info.has_avx2,
                'has_cuda': hw_info.has_cuda,
                'has_intel_gpu': hw_info.has_intel_gpu,
                'has_nvidia_gpu': hw_info.has_nvidia_gpu,
                'has_amd_gpu': hw_info.has_amd_gpu,
                'gpu_count': len(hw_info.gpu_devices)
            }
        }
    
    def optimize_query_performance(self, query: str, estimated_result_size: int) -> Optional[OptimizationResult]:
        """ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½ï¼ˆåŠ¨æ€ç‰ˆæœ¬ï¼‰"""
        if not self.optimization_enabled or not self.detector.hardware_info:
            return None
        
        # æ ‡è®°å·²ç»è¿›è¡Œè¿‡ä¼˜åŒ–
        self.has_optimized_queries = True
        self.optimization_count += 1
        
        hw_info = self.detector.hardware_info
        
        # åˆ†ææŸ¥è¯¢ç‰¹å¾
        query_profile = self._analyze_query(query, estimated_result_size)
        
        # è·å–ç³»ç»Ÿè´Ÿè½½
        system_load = self._get_system_load()
        
        # è®¡ç®—åŠ¨æ€å› å­
        dynamic_factors = self._calculate_dynamic_factors(query_profile, system_load)
        
        # æ ¹æ®ç¡¬ä»¶ç±»å‹é€‰æ‹©ä¼˜åŒ–ç­–ç•¥
        optimization_type = self._determine_optimization_type(hw_info, query, estimated_result_size)
        
        # è®¡ç®—ä¼˜åŒ–æ•ˆæœï¼ˆä½¿ç”¨åŠ¨æ€å› å­ï¼‰
        cpu_gain = self._calculate_cpu_optimization(hw_info, dynamic_factors)
        gpu_gain = self._calculate_gpu_optimization(hw_info, dynamic_factors)
        memory_efficiency = self._calculate_memory_optimization(hw_info, dynamic_factors)
        overall_speedup = self._calculate_overall_speedup(cpu_gain, gpu_gain, memory_efficiency)
        
        # è®°å½•æ€§èƒ½å†å²
        performance_record = {
            'timestamp': time.time(),
            'query_complexity': query_profile.complexity_score,
            'data_size': estimated_result_size,
            'cpu_gain': cpu_gain,
            'gpu_speedup': gpu_gain,
            'memory_efficiency': memory_efficiency,
            'overall_speedup': overall_speedup,
            'system_load': system_load.cpu_usage,
            'dynamic_factors': dynamic_factors
        }
        self.performance_history.append(performance_record)
        
        # åªä¿ç•™æœ€è¿‘50æ¡è®°å½•
        if len(self.performance_history) > 50:
            self.performance_history = self.performance_history[-50:]
        
        # ç”Ÿæˆä¼˜åŒ–å»ºè®®ï¼ˆåŒ…å«åŠ¨æ€ä¿¡æ¯ï¼‰
        recommendations = self._generate_recommendations(hw_info, optimization_type, query_profile, dynamic_factors)
        
        return OptimizationResult(
            enabled=True,
            vendor=hw_info.vendor,
            optimization_type=optimization_type,
            cpu_performance_gain=cpu_gain,
            gpu_acceleration_gain=gpu_gain,
            memory_efficiency=memory_efficiency,
            overall_speedup=overall_speedup,
            optimization_details={
                'hardware_vendor': hw_info.vendor.value,
                'optimization_strategy': optimization_type.value,
                'cpu_cores_used': hw_info.cpu_cores,
                'gpu_devices_used': len(hw_info.gpu_devices),
                'memory_optimization': True,
                'vectorization_enabled': hw_info.has_avx2 or hw_info.has_avx512,
                'optimization_count': self.optimization_count,
                'query_complexity': query_profile.complexity_score,
                'estimated_data_size': estimated_result_size,
                'system_load_cpu': system_load.cpu_usage,
                'system_load_memory': system_load.memory_usage,
                'dynamic_factors': dynamic_factors
            },
            recommendations=recommendations
        )
    
    def _calculate_cpu_optimization(self, hw_info: HardwareInfo, dynamic_factors: Dict[str, float]) -> float:
        """è®¡ç®—CPUä¼˜åŒ–æ•ˆæœï¼ˆåŠ¨æ€ç‰ˆæœ¬ï¼‰"""
        # åŸºç¡€ç¡¬ä»¶ä¼˜åŒ–
        base_gain = 0.1  # åŸºç¡€10%æå‡
        
        # å¤šæ ¸ä¼˜åŒ–
        if hw_info.cpu_cores >= 4:
            base_gain += 0.15
        if hw_info.cpu_cores >= 8:
            base_gain += 0.1
        
        # å‘é‡åŒ–ä¼˜åŒ–
        if hw_info.has_avx2:
            base_gain += 0.2
        if hw_info.has_avx512:
            base_gain += 0.15
        
        # å‚å•†ç‰¹å®šä¼˜åŒ–
        if hw_info.vendor == HardwareVendor.INTEL:
            base_gain += 0.1  # Intelç‰¹å®šä¼˜åŒ–
        elif hw_info.vendor == HardwareVendor.AMD:
            base_gain += 0.08  # AMDç‰¹å®šä¼˜åŒ–
        
        # åº”ç”¨åŠ¨æ€å› å­
        dynamic_gain = base_gain
        dynamic_gain *= dynamic_factors.get('complexity', 1.0)
        dynamic_gain *= dynamic_factors.get('data_size', 1.0)
        dynamic_gain *= dynamic_factors.get('system_load', 1.0)
        dynamic_gain *= dynamic_factors.get('query_type', 1.0)
        dynamic_gain *= dynamic_factors.get('learning', 1.0)
        dynamic_gain *= dynamic_factors.get('random', 1.0)
        
        return min(dynamic_gain, 0.85)  # æœ€å¤§85%æå‡
    
    def _calculate_gpu_optimization(self, hw_info: HardwareInfo, dynamic_factors: Dict[str, float]) -> float:
        """è®¡ç®—GPUä¼˜åŒ–æ•ˆæœï¼ˆåŠ¨æ€ç‰ˆæœ¬ï¼‰"""
        if not hw_info.gpu_devices:
            return 1.0  # æ— GPUï¼Œæ— åŠ é€Ÿ
        
        base_speedup = 1.0
        
        # NVIDIA GPUä¼˜åŒ–
        if hw_info.has_nvidia_gpu and hw_info.has_cuda:
            base_speedup += 1.5  # CUDAåŠ é€Ÿ
        
        # Intel GPUä¼˜åŒ–
        elif hw_info.has_intel_gpu:
            base_speedup += 0.3  # Intelé›†æˆæ˜¾å¡åŠ é€Ÿ
        
        # AMD GPUä¼˜åŒ–
        elif hw_info.has_amd_gpu:
            base_speedup += 1.2  # AMD GPUåŠ é€Ÿ
        
        # OpenCLé€šç”¨åŠ é€Ÿ
        if hw_info.has_opencl:
            base_speedup += 0.2
        
        # åº”ç”¨åŠ¨æ€å› å­
        dynamic_speedup = base_speedup
        
        # GPUå¯¹å¤æ‚æŸ¥è¯¢å’Œå¤§æ•°æ®é›†æ•ˆæœæ›´å¥½
        complexity_boost = 1.0 + (dynamic_factors.get('complexity', 1.0) - 1.0) * 1.5
        data_boost = dynamic_factors.get('data_size', 1.0)
        
        dynamic_speedup *= complexity_boost
        dynamic_speedup *= data_boost
        dynamic_speedup *= dynamic_factors.get('system_load', 1.0)
        dynamic_speedup *= dynamic_factors.get('learning', 1.0)
        dynamic_speedup *= dynamic_factors.get('random', 1.0)
        
        return min(dynamic_speedup, 3.5)  # æœ€å¤§3.5xåŠ é€Ÿ
    
    def _calculate_memory_optimization(self, hw_info: HardwareInfo, dynamic_factors: Dict[str, float]) -> float:
        """è®¡ç®—å†…å­˜ä¼˜åŒ–æ•ˆæœï¼ˆåŠ¨æ€ç‰ˆæœ¬ï¼‰"""
        base_efficiency = 0.7  # åŸºç¡€70%æ•ˆç‡
        
        # å†…å­˜å¤§å°å½±å“
        if hw_info.memory_total >= 16:
            base_efficiency += 0.15
        elif hw_info.memory_total >= 8:
            base_efficiency += 0.1
        
        # å¤šæ ¸ç³»ç»Ÿçš„å†…å­˜ä¼˜åŒ–
        if hw_info.cpu_cores >= 4:
            base_efficiency += 0.1
        
        # åº”ç”¨åŠ¨æ€å› å­
        dynamic_efficiency = base_efficiency
        dynamic_efficiency *= dynamic_factors.get('data_size', 1.0)
        dynamic_efficiency *= dynamic_factors.get('system_load', 1.0)
        dynamic_efficiency *= dynamic_factors.get('learning', 1.0)
        dynamic_efficiency *= dynamic_factors.get('random', 1.0)
        
        return min(dynamic_efficiency, 0.98)  # æœ€å¤§98%æ•ˆç‡
    
    def _calculate_overall_speedup(self, cpu_gain: float, gpu_speedup: float, memory_efficiency: float) -> float:
        """è®¡ç®—æ€»ä½“åŠ é€Ÿæ¯”"""
        # ç»¼åˆè€ƒè™‘CPUã€GPUå’Œå†…å­˜ä¼˜åŒ–
        cpu_factor = 1 + cpu_gain
        gpu_factor = gpu_speedup
        memory_factor = memory_efficiency
        
        # åŠ æƒå¹³å‡
        overall = (cpu_factor * 0.4 + gpu_factor * 0.4 + memory_factor * 0.2)
        return min(overall, 4.0)  # æœ€å¤§4xåŠ é€Ÿ
    
    def _determine_optimization_type(self, hw_info: HardwareInfo, query: str, result_size: int) -> OptimizationType:
        """ç¡®å®šä¼˜åŒ–ç±»å‹"""
        # æ ¹æ®æŸ¥è¯¢å¤æ‚åº¦å’Œç¡¬ä»¶æƒ…å†µå†³å®šä¼˜åŒ–ç­–ç•¥
        if hw_info.gpu_devices and result_size > 1000:
            return OptimizationType.GPU
        elif hw_info.cpu_cores >= 4:
            return OptimizationType.CPU
        elif hw_info.memory_total >= 8:
            return OptimizationType.MEMORY
        else:
            return OptimizationType.MIXED
    
    def _generate_recommendations(self, hw_info: HardwareInfo, opt_type: OptimizationType, 
                                query_profile: QueryProfile, dynamic_factors: Dict[str, float]) -> List[str]:
        """ç”Ÿæˆä¼˜åŒ–å»ºè®®ï¼ˆåŒ…å«åŠ¨æ€ä¿¡æ¯ï¼‰"""
        recommendations = []
        
        # ç¡¬ä»¶ç‰¹å®šå»ºè®®
        if hw_info.vendor == HardwareVendor.INTEL:
            recommendations.append("ğŸ”§ æ£€æµ‹åˆ°Intelå¹³å°ï¼Œå·²å¯ç”¨Intelç‰¹å®šä¼˜åŒ–")
            if hw_info.has_intel_gpu:
                recommendations.append("ğŸ¯ æ£€æµ‹åˆ°Intelé›†æˆæ˜¾å¡ï¼Œå·²å¯ç”¨GPUåŠ é€Ÿ")
        elif hw_info.vendor == HardwareVendor.NVIDIA:
            recommendations.append("ğŸ”§ æ£€æµ‹åˆ°NVIDIAå¹³å°ï¼Œå·²å¯ç”¨CUDAä¼˜åŒ–")
            if hw_info.has_cuda:
                recommendations.append("ğŸš€ CUDAç¯å¢ƒå¯ç”¨ï¼Œå·²å¯ç”¨GPUå¹¶è¡Œè®¡ç®—")
        elif hw_info.vendor == HardwareVendor.AMD:
            recommendations.append("ğŸ”§ æ£€æµ‹åˆ°AMDå¹³å°ï¼Œå·²å¯ç”¨AMDç‰¹å®šä¼˜åŒ–")
            if hw_info.has_amd_gpu:
                recommendations.append("ğŸ¯ æ£€æµ‹åˆ°AMD GPUï¼Œå·²å¯ç”¨GPUåŠ é€Ÿ")
        
        # æŸ¥è¯¢ç‰¹å®šå»ºè®®
        if query_profile.complexity_score > 0.7:
            recommendations.append("âš¡ æ£€æµ‹åˆ°å¤æ‚æŸ¥è¯¢ï¼Œå·²å¯ç”¨é«˜çº§ä¼˜åŒ–ç­–ç•¥")
        elif query_profile.complexity_score < 0.3:
            recommendations.append("ğŸš€ ç®€å•æŸ¥è¯¢ï¼Œä¼˜åŒ–æ•ˆæœæ˜¾è‘—")
        
        if query_profile.has_joins:
            recommendations.append("ğŸ”— å¤šè¡¨JOINæŸ¥è¯¢ï¼Œå·²ä¼˜åŒ–è¿æ¥ç®—æ³•")
        
        if query_profile.has_aggregations:
            recommendations.append("ğŸ“Š èšåˆæŸ¥è¯¢ï¼Œå·²å¯ç”¨å‘é‡åŒ–è®¡ç®—")
        
        # æ•°æ®é‡ç›¸å…³å»ºè®®
        if query_profile.estimated_data_size > 5000:
            recommendations.append("ğŸ“ˆ å¤§æ•°æ®é›†å¤„ç†ï¼Œå·²å¯ç”¨å¹¶è¡Œä¼˜åŒ–")
        elif query_profile.estimated_data_size < 500:
            recommendations.append("âš¡ å°æ•°æ®é›†ï¼Œç¼“å­˜ä¼˜åŒ–æ•ˆæœæœ€ä½³")
        
        # ç³»ç»Ÿè´Ÿè½½ç›¸å…³å»ºè®®
        system_load_factor = dynamic_factors.get('system_load', 1.0)
        if system_load_factor < 0.9:
            recommendations.append("âš ï¸ ç³»ç»Ÿè´Ÿè½½è¾ƒé«˜ï¼Œä¼˜åŒ–æ•ˆæœå¯èƒ½å—é™")
        elif system_load_factor > 1.1:
            recommendations.append("ğŸ¯ ç³»ç»Ÿè´Ÿè½½è¾ƒä½ï¼Œä¼˜åŒ–æ•ˆæœç†æƒ³")
        
        # å­¦ä¹ æ•ˆæœå»ºè®®
        if self.optimization_count > 5:
            recommendations.append("ğŸ§  ç³»ç»Ÿå·²å­¦ä¹ æŸ¥è¯¢æ¨¡å¼ï¼Œä¼˜åŒ–æ•ˆæœæŒç»­æå‡")
        
        # ä¼˜åŒ–ç±»å‹å»ºè®®
        if opt_type == OptimizationType.GPU:
            recommendations.append("âš¡ ä½¿ç”¨GPUåŠ é€Ÿæ¨¡å¼å¤„ç†å¤§æ•°æ®é›†")
        elif opt_type == OptimizationType.CPU:
            recommendations.append("ğŸ’» ä½¿ç”¨å¤šæ ¸CPUå¹¶è¡Œå¤„ç†")
        elif opt_type == OptimizationType.MEMORY:
            recommendations.append("ğŸ§  å¯ç”¨å†…å­˜ä¼˜åŒ–æ¨¡å¼")
        
        # é€šç”¨å»ºè®®
        if hw_info.has_avx2:
            recommendations.append("ğŸ“ˆ å·²å¯ç”¨AVX2å‘é‡åŒ–æŒ‡ä»¤é›†")
        if hw_info.has_opencl:
            recommendations.append("ğŸ”„ OpenCLå¹¶è¡Œè®¡ç®—å·²å¯ç”¨")
        
        return recommendations or ["âœ… ç³»ç»Ÿå·²æ ¹æ®å½“å‰ç¡¬ä»¶é…ç½®è¿›è¡Œä¼˜åŒ–"]

# å…¨å±€ä¼˜åŒ–å™¨å®ä¾‹
universal_optimizer = UniversalHardwareOptimizer()

def get_optimization_status() -> Dict[str, Any]:
    """è·å–ä¼˜åŒ–çŠ¶æ€ï¼ˆå…¼å®¹æ¥å£ï¼‰"""
    return universal_optimizer.get_optimization_status()

def optimize_query_performance(query: str, estimated_result_size: int) -> Optional[OptimizationResult]:
    """ä¼˜åŒ–æŸ¥è¯¢æ€§èƒ½ï¼ˆå…¼å®¹æ¥å£ï¼‰"""
    return universal_optimizer.optimize_query_performance(query, estimated_result_size)

def render_universal_optimization_ui():
    """æ¸²æŸ“é€šç”¨ä¼˜åŒ–UIï¼ˆå…¼å®¹æ¥å£ï¼‰"""
    pass  # ç”±app.pyä¸­çš„UIä»£ç å¤„ç†