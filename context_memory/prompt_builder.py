"""
æç¤ºæ„å»ºå™¨å®ç°

æ„å»ºåŒ…å«ä¸Šä¸‹æ–‡çš„å®Œæ•´ã€ç»“æ„åŒ–æç¤ºã€‚
"""

import re
from datetime import datetime
from typing import List, Dict, Optional, Tuple
from dataclasses import dataclass

from .models import (
    ContextItem, SectionType, ContextType,
    ContextError
)


@dataclass
class PromptSection:
    """æç¤ºéƒ¨åˆ†æ•°æ®ç»“æ„"""
    type: SectionType
    title: str
    content: str
    metadata: Dict = None
    
    def __post_init__(self):
        if self.metadata is None:
            self.metadata = {}


class PromptBuilder:
    """æç¤ºæ„å»ºå™¨ç±» - è´Ÿè´£æ„å»ºç»“æ„åŒ–çš„æç¤º"""
    
    def __init__(self, max_tokens: int = 8000):
        """
        åˆå§‹åŒ–æç¤ºæ„å»ºå™¨
        
        Args:
            max_tokens: æœ€å¤§tokené™åˆ¶
        """
        self.max_tokens = max_tokens
        self.token_per_char_ratio = 0.25  # ä¼°ç®—ï¼šå¹³å‡4ä¸ªå­—ç¬¦çº¦ç­‰äº1ä¸ªtoken
    
    def build_contextual_prompt(
        self, 
        user_input: str, 
        context: List[ContextItem],
        system_instruction: Optional[str] = None
    ) -> str:
        """
        æ„å»ºåŒ…å«ä¸Šä¸‹æ–‡çš„å®Œæ•´æç¤º
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            context: ä¸Šä¸‹æ–‡é¡¹åˆ—è¡¨
            system_instruction: ç³»ç»ŸæŒ‡ä»¤
            
        Returns:
            ç»“æ„åŒ–çš„å®Œæ•´æç¤º
        """
        try:
            sections = []
            
            # 1. æ·»åŠ ç³»ç»ŸæŒ‡ä»¤éƒ¨åˆ†
            if system_instruction:
                sections.append(PromptSection(
                    type=SectionType.SYSTEM_INSTRUCTION,
                    title="ç³»ç»ŸæŒ‡ä»¤",
                    content=system_instruction
                ))
            
            # 2. æ·»åŠ å†å²ä¸Šä¸‹æ–‡éƒ¨åˆ†
            if context:
                context_content = self.format_context_section(context)
                sections.append(PromptSection(
                    type=SectionType.HISTORICAL_CONTEXT,
                    title="å†å²ä¸Šä¸‹æ–‡",
                    content=context_content
                ))
            
            # 3. æ·»åŠ ç”¨æˆ·è¾“å…¥éƒ¨åˆ†
            sections.append(PromptSection(
                type=SectionType.USER_INPUT,
                title="å½“å‰é—®é¢˜",
                content=user_input
            ))
            
            # 4. æ„å»ºæœ€ç»ˆæç¤º
            prompt = self._build_prompt_from_sections(sections)
            
            # 5. ç¡®ä¿ä¸è¶…è¿‡tokené™åˆ¶
            prompt = self.ensure_token_limits(prompt, self.max_tokens)
            
            return prompt
            
        except Exception as e:
            raise ContextError(f"æ„å»ºä¸Šä¸‹æ–‡æç¤ºå¤±è´¥: {e}")
    
    def format_context_section(self, context: List[ContextItem]) -> str:
        """
        æ ¼å¼åŒ–ä¸Šä¸‹æ–‡éƒ¨åˆ†
        
        Args:
            context: ä¸Šä¸‹æ–‡é¡¹åˆ—è¡¨
            
        Returns:
            æ ¼å¼åŒ–çš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        """
        if not context:
            return ""
        
        formatted_items = []
        
        # æŒ‰ç±»å‹åˆ†ç»„ä¸Šä¸‹æ–‡é¡¹
        grouped_context = self._group_context_by_type(context)
        
        for context_type, items in grouped_context.items():
            type_title = self._get_context_type_title(context_type)
            
            if items:
                formatted_items.append(f"\n### {type_title}\n")
                
                for item in items:
                    formatted_item = self._format_single_context_item(item)
                    formatted_items.append(formatted_item)
        
        return "".join(formatted_items)
    
    def ensure_token_limits(self, prompt: str, max_tokens: int) -> str:
        """
        ç¡®ä¿æç¤ºä¸è¶…è¿‡tokené™åˆ¶
        
        Args:
            prompt: åŸå§‹æç¤º
            max_tokens: æœ€å¤§tokenæ•°
            
        Returns:
            æˆªæ–­åçš„æç¤º
        """
        estimated_tokens = len(prompt) * self.token_per_char_ratio
        
        if estimated_tokens <= max_tokens:
            return prompt
        
        # éœ€è¦æˆªæ–­ï¼Œä¼˜å…ˆä¿ç•™ç”¨æˆ·è¾“å…¥å’Œç³»ç»ŸæŒ‡ä»¤
        sections = self._parse_prompt_sections(prompt)
        
        # è®¡ç®—å¿…éœ€éƒ¨åˆ†çš„tokenæ•°
        essential_tokens = 0
        essential_sections = []
        context_sections = []
        
        for section in sections:
            section_tokens = len(section.content) * self.token_per_char_ratio
            
            if section.type in [SectionType.USER_INPUT, SectionType.SYSTEM_INSTRUCTION]:
                essential_tokens += section_tokens
                essential_sections.append(section)
            else:
                context_sections.append((section, section_tokens))
        
        # è®¡ç®—å¯ç”¨äºä¸Šä¸‹æ–‡çš„tokenæ•°
        available_tokens = max_tokens - essential_tokens - 100  # ä¿ç•™100ä¸ªtokençš„ç¼“å†²
        
        if available_tokens <= 0:
            # å¦‚æœå¿…éœ€éƒ¨åˆ†å·²ç»è¶…å‡ºé™åˆ¶ï¼Œåªä¿ç•™ç”¨æˆ·è¾“å…¥
            user_input_section = next(
                (s for s in essential_sections if s.type == SectionType.USER_INPUT), 
                None
            )
            if user_input_section:
                return self._build_prompt_from_sections([user_input_section])
            return prompt[:int(max_tokens / self.token_per_char_ratio)]
        
        # é€‰æ‹©æœ€é‡è¦çš„ä¸Šä¸‹æ–‡é¡¹
        selected_context_sections = self._select_context_within_limit(
            context_sections, available_tokens
        )
        
        # é‡æ–°æ„å»ºæç¤º
        final_sections = essential_sections + selected_context_sections
        return self._build_prompt_from_sections(final_sections)
    
    def add_section_markers(self, content: str, section_type: SectionType) -> str:
        """
        ä¸ºå†…å®¹æ·»åŠ éƒ¨åˆ†æ ‡è®°
        
        Args:
            content: å†…å®¹
            section_type: éƒ¨åˆ†ç±»å‹
            
        Returns:
            å¸¦æ ‡è®°çš„å†…å®¹
        """
        # ä½¿ç”¨ä¸å¯è§çš„XMLé£æ ¼æ ‡è®°ï¼Œé¿å…åœ¨UIä¸­æ˜¾ç¤º
        markers = {
            SectionType.USER_INPUT: ("<!-- USER_INPUT -->", "<!-- /USER_INPUT -->"),
            SectionType.HISTORICAL_CONTEXT: ("<!-- HISTORICAL_CONTEXT -->", "<!-- /HISTORICAL_CONTEXT -->"),
            SectionType.SYSTEM_INSTRUCTION: ("<!-- SYSTEM_INSTRUCTION -->", "<!-- /SYSTEM_INSTRUCTION -->"),
            SectionType.CODE_CONTEXT: ("<!-- CODE_CONTEXT -->", "<!-- /CODE_CONTEXT -->"),
            SectionType.ERROR_CONTEXT: ("<!-- ERROR_CONTEXT -->", "<!-- /ERROR_CONTEXT -->")
        }
        
        start_marker, end_marker = markers.get(section_type, ("<!-- CONTENT -->", "<!-- /CONTENT -->"))
        
        return f"{start_marker}\n{content}\n{end_marker}"
    
    def _build_prompt_from_sections(self, sections: List[PromptSection]) -> str:
        """ä»éƒ¨åˆ†åˆ—è¡¨æ„å»ºæç¤º"""
        prompt_parts = []
        
        for section in sections:
            marked_content = self.add_section_markers(section.content, section.type)
            prompt_parts.append(marked_content)
        
        return "\n".join(prompt_parts)
    
    def _group_context_by_type(self, context: List[ContextItem]) -> Dict[ContextType, List[ContextItem]]:
        """æŒ‰ç±»å‹åˆ†ç»„ä¸Šä¸‹æ–‡é¡¹"""
        grouped = {}
        
        for item in context:
            if item.type not in grouped:
                grouped[item.type] = []
            grouped[item.type].append(item)
        
        # æŒ‰æ—¶é—´æ’åºæ¯ä¸ªç»„
        for context_type in grouped:
            grouped[context_type].sort(key=lambda x: x.timestamp, reverse=True)
        
        return grouped
    
    def _get_context_type_title(self, context_type: ContextType) -> str:
        """è·å–ä¸Šä¸‹æ–‡ç±»å‹çš„æ ‡é¢˜"""
        titles = {
            ContextType.USER_INPUT: "ç”¨æˆ·è¾“å…¥å†å²",
            ContextType.AGENT_RESPONSE: "åŠ©æ‰‹å“åº”å†å²", 
            ContextType.CODE_SNIPPET: "ç›¸å…³ä»£ç ",
            ContextType.ERROR_INFO: "é”™è¯¯ä¿¡æ¯",
            ContextType.FILE_REFERENCE: "æ–‡ä»¶å¼•ç”¨",
            ContextType.SYSTEM_INFO: "ç³»ç»Ÿä¿¡æ¯"
        }
        
        return titles.get(context_type, "å…¶ä»–ä¿¡æ¯")
    
    def _format_single_context_item(self, item: ContextItem) -> str:
        """æ ¼å¼åŒ–å•ä¸ªä¸Šä¸‹æ–‡é¡¹"""
        timestamp_str = item.timestamp.strftime("%H:%M:%S")
        
        # æ ¹æ®ç±»å‹é€‰æ‹©ä¸åŒçš„æ ¼å¼
        if item.type == ContextType.CODE_SNIPPET:
            return f"\n```\n{item.content}\n```\n*æ—¶é—´: {timestamp_str}*\n"
        elif item.type == ContextType.ERROR_INFO:
            return f"\nâŒ **é”™è¯¯**: {item.content}\n*æ—¶é—´: {timestamp_str}*\n"
        else:
            return f"\n- {item.content}\n  *æ—¶é—´: {timestamp_str}*\n"
    
    def _parse_prompt_sections(self, prompt: str) -> List[PromptSection]:
        """è§£ææç¤ºä¸­çš„éƒ¨åˆ†"""
        sections = []
        
        # ç®€å•çš„éƒ¨åˆ†è§£æï¼ˆåŸºäºæ ‡è®°ï¼‰
        section_patterns = {
            r'ğŸ”µ ç”¨æˆ·è¾“å…¥\n(.*?)\n(?=ğŸ”µ|ğŸ“š|âš™ï¸|ğŸ’»|âŒ|$)': SectionType.USER_INPUT,
            r'ğŸ“š å†å²ä¸Šä¸‹æ–‡\n(.*?)\n(?=ğŸ”µ|ğŸ“š|âš™ï¸|ğŸ’»|âŒ|$)': SectionType.HISTORICAL_CONTEXT,
            r'âš™ï¸ ç³»ç»ŸæŒ‡ä»¤\n(.*?)\n(?=ğŸ”µ|ğŸ“š|âš™ï¸|ğŸ’»|âŒ|$)': SectionType.SYSTEM_INSTRUCTION,
            r'ğŸ’» ä»£ç ä¸Šä¸‹æ–‡\n(.*?)\n(?=ğŸ”µ|ğŸ“š|âš™ï¸|ğŸ’»|âŒ|$)': SectionType.CODE_CONTEXT,
            r'âŒ é”™è¯¯ä¸Šä¸‹æ–‡\n(.*?)\n(?=ğŸ”µ|ğŸ“š|âš™ï¸|ğŸ’»|âŒ|$)': SectionType.ERROR_CONTEXT
        }
        
        for pattern, section_type in section_patterns.items():
            matches = re.findall(pattern, prompt, re.DOTALL)
            for match in matches:
                sections.append(PromptSection(
                    type=section_type,
                    title=section_type.value,
                    content=match.strip()
                ))
        
        return sections
    
    def _select_context_within_limit(
        self, 
        context_sections: List[Tuple[PromptSection, float]], 
        available_tokens: float
    ) -> List[PromptSection]:
        """åœ¨tokené™åˆ¶å†…é€‰æ‹©ä¸Šä¸‹æ–‡éƒ¨åˆ†"""
        selected = []
        used_tokens = 0.0
        
        # æŒ‰é‡è¦æ€§æ’åºï¼ˆè¿™é‡Œç®€å•æŒ‰ç±»å‹ä¼˜å…ˆçº§ï¼‰
        type_priority = {
            SectionType.CODE_CONTEXT: 3,
            SectionType.ERROR_CONTEXT: 2,
            SectionType.HISTORICAL_CONTEXT: 1
        }
        
        context_sections.sort(
            key=lambda x: type_priority.get(x[0].type, 0), 
            reverse=True
        )
        
        for section, tokens in context_sections:
            if used_tokens + tokens <= available_tokens:
                selected.append(section)
                used_tokens += tokens
            else:
                # å°è¯•æˆªæ–­è¿™ä¸ªéƒ¨åˆ†
                remaining_tokens = available_tokens - used_tokens
                if remaining_tokens > 50:  # è‡³å°‘ä¿ç•™50ä¸ªtokençš„å†…å®¹
                    max_chars = int(remaining_tokens / self.token_per_char_ratio)
                    truncated_content = section.content[:max_chars] + "..."
                    truncated_section = PromptSection(
                        type=section.type,
                        title=section.title,
                        content=truncated_content
                    )
                    selected.append(truncated_section)
                break
        
        return selected
    
    def get_prompt_stats(self, prompt: str) -> Dict[str, any]:
        """
        è·å–æç¤ºç»Ÿè®¡ä¿¡æ¯
        
        Args:
            prompt: æç¤ºå­—ç¬¦ä¸²
            
        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        return {
            "character_count": len(prompt),
            "estimated_tokens": int(len(prompt) * self.token_per_char_ratio),
            "line_count": len(prompt.split('\n')),
            "section_count": len(self._parse_prompt_sections(prompt)),
            "within_limit": len(prompt) * self.token_per_char_ratio <= self.max_tokens
        }