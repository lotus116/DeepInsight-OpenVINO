#!/usr/bin/env python3
"""
è‡ªé€‚åº”æ€§èƒ½ä¼˜åŒ–ç³»ç»Ÿ
åŸºäºæœºå™¨å­¦ä¹ å’Œå†å²æ•°æ®çš„æ™ºèƒ½æ€§èƒ½è°ƒä¼˜
ç›®æ ‡ï¼šå®ç°æ™ºèƒ½åŒ–çš„æ€§èƒ½ä¼˜åŒ–ï¼Œä½“ç°æŠ€æœ¯æ–¹æ¡ˆçš„å…ˆè¿›æ€§
"""

import time
import threading
import logging
import json
import pickle
import os
from typing import Dict, Any, List, Optional, Tuple, Callable
from dataclasses import dataclass, field, asdict
from enum import Enum
import numpy as np
import pandas as pd
from collections import deque, defaultdict
import psutil
import hashlib

logger = logging.getLogger(__name__)

class OptimizationStrategy(Enum):
    """ä¼˜åŒ–ç­–ç•¥"""
    CONSERVATIVE = "conservative"    # ä¿å®ˆç­–ç•¥
    BALANCED = "balanced"           # å¹³è¡¡ç­–ç•¥
    AGGRESSIVE = "aggressive"       # æ¿€è¿›ç­–ç•¥
    ADAPTIVE = "adaptive"           # è‡ªé€‚åº”ç­–ç•¥

class PerformanceMetricType(Enum):
    """æ€§èƒ½æŒ‡æ ‡ç±»å‹"""
    LATENCY = "latency"
    THROUGHPUT = "throughput"
    MEMORY_USAGE = "memory_usage"
    CPU_USAGE = "cpu_usage"
    ERROR_RATE = "error_rate"
    CACHE_HIT_RATE = "cache_hit_rate"

@dataclass
class PerformanceSnapshot:
    """æ€§èƒ½å¿«ç…§"""
    timestamp: float
    operation_type: str
    operation_id: str
    latency_ms: float
    memory_mb: float
    cpu_percent: float
    throughput_ops_sec: float
    error_occurred: bool
    cache_hit: bool
    input_size: int
    optimization_params: Dict[str, Any] = field(default_factory=dict)
    context: Dict[str, Any] = field(default_factory=dict)

@dataclass
class OptimizationRecommendation:
    """ä¼˜åŒ–å»ºè®®"""
    parameter: str
    current_value: Any
    recommended_value: Any
    confidence: float
    expected_improvement: float
    reason: str
    strategy: OptimizationStrategy

@dataclass
class PerformanceModel:
    """æ€§èƒ½æ¨¡å‹"""
    operation_type: str
    model_version: str
    training_samples: int
    accuracy_score: float
    last_updated: float
    feature_importance: Dict[str, float] = field(default_factory=dict)
    model_data: Optional[bytes] = None

class PerformancePredictor:
    """æ€§èƒ½é¢„æµ‹å™¨"""
    
    def __init__(self):
        self.models: Dict[str, PerformanceModel] = {}
        self.feature_extractors: Dict[str, Callable] = {}
        self._setup_feature_extractors()
        
        logger.info("âœ… æ€§èƒ½é¢„æµ‹å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _setup_feature_extractors(self):
        """è®¾ç½®ç‰¹å¾æå–å™¨"""
        self.feature_extractors = {
            'input_size': lambda snapshot: snapshot.input_size,
            'hour_of_day': lambda snapshot: time.localtime(snapshot.timestamp).tm_hour,
            'day_of_week': lambda snapshot: time.localtime(snapshot.timestamp).tm_wday,
            'system_load': lambda snapshot: snapshot.cpu_percent,
            'memory_pressure': lambda snapshot: snapshot.memory_mb,
            'cache_efficiency': lambda snapshot: 1.0 if snapshot.cache_hit else 0.0,
        }
    
    def extract_features(self, snapshot: PerformanceSnapshot) -> Dict[str, float]:
        """æå–ç‰¹å¾"""
        features = {}
        
        for feature_name, extractor in self.feature_extractors.items():
            try:
                features[feature_name] = float(extractor(snapshot))
            except Exception as e:
                logger.warning(f"ç‰¹å¾æå–å¤±è´¥ {feature_name}: {e}")
                features[feature_name] = 0.0
        
        return features
    
    def train_model(self, operation_type: str, snapshots: List[PerformanceSnapshot]) -> PerformanceModel:
        """è®­ç»ƒæ€§èƒ½æ¨¡å‹"""
        if len(snapshots) < 10:
            logger.warning(f"è®­ç»ƒæ•°æ®ä¸è¶³: {operation_type} ({len(snapshots)} samples)")
            return None
        
        try:
            # æå–ç‰¹å¾å’Œç›®æ ‡å€¼
            features_list = []
            targets = []
            
            for snapshot in snapshots:
                features = self.extract_features(snapshot)
                features_list.append(list(features.values()))
                targets.append(snapshot.latency_ms)
            
            X = np.array(features_list)
            y = np.array(targets)
            
            # ç®€å•çš„çº¿æ€§å›å½’æ¨¡å‹ï¼ˆå¯ä»¥æ›¿æ¢ä¸ºæ›´å¤æ‚çš„æ¨¡å‹ï¼‰
            model_coefficients = self._fit_linear_regression(X, y)
            
            # è®¡ç®—ç‰¹å¾é‡è¦æ€§
            feature_names = list(self.feature_extractors.keys())
            feature_importance = {
                name: abs(coef) for name, coef in zip(feature_names, model_coefficients[1:])
            }
            
            # è®¡ç®—æ¨¡å‹å‡†ç¡®æ€§
            predictions = self._predict_linear(X, model_coefficients)
            accuracy = self._calculate_r2_score(y, predictions)
            
            model = PerformanceModel(
                operation_type=operation_type,
                model_version="1.0",
                training_samples=len(snapshots),
                accuracy_score=accuracy,
                last_updated=time.time(),
                feature_importance=feature_importance,
                model_data=pickle.dumps(model_coefficients)
            )
            
            self.models[operation_type] = model
            
            logger.info(f"âœ… æ€§èƒ½æ¨¡å‹è®­ç»ƒå®Œæˆ: {operation_type} (å‡†ç¡®ç‡: {accuracy:.3f})")
            
            return model
            
        except Exception as e:
            logger.error(f"æ¨¡å‹è®­ç»ƒå¤±è´¥: {operation_type}: {e}")
            return None
    
    def _fit_linear_regression(self, X: np.ndarray, y: np.ndarray) -> np.ndarray:
        """æ‹Ÿåˆçº¿æ€§å›å½’"""
        # æ·»åŠ åç½®é¡¹
        X_with_bias = np.column_stack([np.ones(X.shape[0]), X])
        
        # æ­£è§„æ–¹ç¨‹æ±‚è§£
        try:
            coefficients = np.linalg.solve(X_with_bias.T @ X_with_bias, X_with_bias.T @ y)
        except np.linalg.LinAlgError:
            # å¦‚æœçŸ©é˜µå¥‡å¼‚ï¼Œä½¿ç”¨ä¼ªé€†
            coefficients = np.linalg.pinv(X_with_bias.T @ X_with_bias) @ X_with_bias.T @ y
        
        return coefficients
    
    def _predict_linear(self, X: np.ndarray, coefficients: np.ndarray) -> np.ndarray:
        """çº¿æ€§é¢„æµ‹"""
        X_with_bias = np.column_stack([np.ones(X.shape[0]), X])
        return X_with_bias @ coefficients
    
    def _calculate_r2_score(self, y_true: np.ndarray, y_pred: np.ndarray) -> float:
        """è®¡ç®—RÂ²åˆ†æ•°"""
        ss_res = np.sum((y_true - y_pred) ** 2)
        ss_tot = np.sum((y_true - np.mean(y_true)) ** 2)
        
        if ss_tot == 0:
            return 0.0
        
        return 1 - (ss_res / ss_tot)
    
    def predict_performance(self, operation_type: str, context: Dict[str, Any]) -> Optional[float]:
        """é¢„æµ‹æ€§èƒ½"""
        if operation_type not in self.models:
            return None
        
        model = self.models[operation_type]
        
        try:
            # åˆ›å»ºä¸´æ—¶å¿«ç…§ç”¨äºç‰¹å¾æå–
            temp_snapshot = PerformanceSnapshot(
                timestamp=time.time(),
                operation_type=operation_type,
                operation_id="prediction",
                latency_ms=0,
                memory_mb=context.get('memory_mb', 0),
                cpu_percent=context.get('cpu_percent', 0),
                throughput_ops_sec=0,
                error_occurred=False,
                cache_hit=context.get('cache_hit', False),
                input_size=context.get('input_size', 0),
                context=context
            )
            
            features = self.extract_features(temp_snapshot)
            X = np.array([list(features.values())])
            
            coefficients = pickle.loads(model.model_data)
            prediction = self._predict_linear(X, coefficients)[0]
            
            return max(0, prediction)  # ç¡®ä¿é¢„æµ‹å€¼éè´Ÿ
            
        except Exception as e:
            logger.error(f"æ€§èƒ½é¢„æµ‹å¤±è´¥: {operation_type}: {e}")
            return None

class AdaptiveOptimizer:
    """è‡ªé€‚åº”ä¼˜åŒ–å™¨"""
    
    def __init__(self):
        self.optimization_params: Dict[str, Dict[str, Any]] = {}
        self.performance_history: deque = deque(maxlen=1000)
        self.optimization_history: List[Dict[str, Any]] = []
        self.predictor = PerformancePredictor()
        
        # ä¼˜åŒ–å‚æ•°èŒƒå›´
        self.param_ranges = {
            'thread_count': (1, psutil.cpu_count()),
            'batch_size': (1, 1000),
            'cache_size': (100, 10000),
            'timeout_ms': (1000, 60000),
            'retry_count': (0, 5),
            'compression_level': (0, 9)
        }
        
        # åˆå§‹åŒ–é»˜è®¤å‚æ•°
        self._initialize_default_params()
        
        logger.info("âœ… è‡ªé€‚åº”ä¼˜åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def _initialize_default_params(self):
        """åˆå§‹åŒ–é»˜è®¤å‚æ•°"""
        default_params = {
            'thread_count': min(4, psutil.cpu_count()),
            'batch_size': 100,
            'cache_size': 1000,
            'timeout_ms': 30000,
            'retry_count': 3,
            'compression_level': 6
        }
        
        self.optimization_params['default'] = default_params
    
    def record_performance(self, snapshot: PerformanceSnapshot):
        """è®°å½•æ€§èƒ½æ•°æ®"""
        self.performance_history.append(snapshot)
        
        # å®šæœŸé‡æ–°è®­ç»ƒæ¨¡å‹
        if len(self.performance_history) % 50 == 0:
            self._retrain_models()
    
    def _retrain_models(self):
        """é‡æ–°è®­ç»ƒæ¨¡å‹"""
        # æŒ‰æ“ä½œç±»å‹åˆ†ç»„
        operation_snapshots = defaultdict(list)
        
        for snapshot in self.performance_history:
            operation_snapshots[snapshot.operation_type].append(snapshot)
        
        # ä¸ºæ¯ç§æ“ä½œç±»å‹è®­ç»ƒæ¨¡å‹
        for operation_type, snapshots in operation_snapshots.items():
            if len(snapshots) >= 10:
                self.predictor.train_model(operation_type, snapshots)
    
    def optimize_parameters(self, operation_type: str, 
                          current_performance: PerformanceSnapshot,
                          strategy: OptimizationStrategy = OptimizationStrategy.ADAPTIVE) -> List[OptimizationRecommendation]:
        """ä¼˜åŒ–å‚æ•°"""
        recommendations = []
        
        # è·å–å½“å‰å‚æ•°
        current_params = self.optimization_params.get(operation_type, self.optimization_params['default'])
        
        # åˆ†æå†å²æ€§èƒ½
        similar_snapshots = self._find_similar_snapshots(current_performance)
        
        if len(similar_snapshots) < 5:
            logger.info(f"å†å²æ•°æ®ä¸è¶³ï¼Œä½¿ç”¨é»˜è®¤ä¼˜åŒ–ç­–ç•¥: {operation_type}")
            return self._get_default_recommendations(current_params, strategy)
        
        # åŸºäºå†å²æ•°æ®ç”Ÿæˆä¼˜åŒ–å»ºè®®
        for param_name, (min_val, max_val) in self.param_ranges.items():
            if param_name in current_params:
                recommendation = self._optimize_single_parameter(
                    param_name, current_params[param_name], 
                    similar_snapshots, min_val, max_val, strategy
                )
                
                if recommendation:
                    recommendations.append(recommendation)
        
        return recommendations
    
    def _find_similar_snapshots(self, target_snapshot: PerformanceSnapshot, 
                               similarity_threshold: float = 0.8) -> List[PerformanceSnapshot]:
        """æŸ¥æ‰¾ç›¸ä¼¼çš„æ€§èƒ½å¿«ç…§"""
        similar_snapshots = []
        
        for snapshot in self.performance_history:
            if snapshot.operation_type != target_snapshot.operation_type:
                continue
            
            similarity = self._calculate_similarity(target_snapshot, snapshot)
            
            if similarity >= similarity_threshold:
                similar_snapshots.append(snapshot)
        
        return similar_snapshots
    
    def _calculate_similarity(self, snapshot1: PerformanceSnapshot, 
                            snapshot2: PerformanceSnapshot) -> float:
        """è®¡ç®—å¿«ç…§ç›¸ä¼¼åº¦"""
        # åŸºäºè¾“å…¥å¤§å°ã€ç³»ç»Ÿè´Ÿè½½ç­‰è®¡ç®—ç›¸ä¼¼åº¦
        factors = [
            ('input_size', 0.3),
            ('cpu_percent', 0.2),
            ('memory_mb', 0.2),
            ('cache_hit', 0.3)
        ]
        
        similarity_score = 0.0
        
        for factor, weight in factors:
            val1 = getattr(snapshot1, factor)
            val2 = getattr(snapshot2, factor)
            
            if isinstance(val1, bool) and isinstance(val2, bool):
                factor_similarity = 1.0 if val1 == val2 else 0.0
            else:
                # æ•°å€¼ç›¸ä¼¼åº¦
                max_val = max(abs(val1), abs(val2), 1)
                factor_similarity = 1.0 - abs(val1 - val2) / max_val
            
            similarity_score += factor_similarity * weight
        
        return similarity_score
    
    def _optimize_single_parameter(self, param_name: str, current_value: Any,
                                 similar_snapshots: List[PerformanceSnapshot],
                                 min_val: Any, max_val: Any,
                                 strategy: OptimizationStrategy) -> Optional[OptimizationRecommendation]:
        """ä¼˜åŒ–å•ä¸ªå‚æ•°"""
        try:
            # åˆ†æå‚æ•°å€¼ä¸æ€§èƒ½çš„å…³ç³»
            param_performance = []
            
            for snapshot in similar_snapshots:
                param_val = snapshot.optimization_params.get(param_name, current_value)
                param_performance.append((param_val, snapshot.latency_ms))
            
            if len(param_performance) < 3:
                return None
            
            # æ‰¾åˆ°æœ€ä½³å‚æ•°å€¼
            param_performance.sort(key=lambda x: x[1])  # æŒ‰å»¶è¿Ÿæ’åº
            best_params = param_performance[:max(1, len(param_performance) // 3)]  # å–å‰1/3
            
            # è®¡ç®—æ¨èå€¼
            best_values = [p[0] for p in best_params]
            recommended_value = np.median(best_values)
            
            # åº”ç”¨ç­–ç•¥è°ƒæ•´
            recommended_value = self._apply_strategy_adjustment(
                recommended_value, current_value, min_val, max_val, strategy
            )
            
            # ç¡®ä¿åœ¨æœ‰æ•ˆèŒƒå›´å†…
            recommended_value = max(min_val, min(max_val, recommended_value))
            
            if abs(recommended_value - current_value) / max(abs(current_value), 1) < 0.1:
                return None  # å˜åŒ–å¤ªå°ï¼Œä¸å€¼å¾—è°ƒæ•´
            
            # ä¼°ç®—æ”¹è¿›æ•ˆæœ
            current_avg_latency = np.mean([p[1] for p in param_performance])
            best_avg_latency = np.mean([p[1] for p in best_params])
            expected_improvement = (current_avg_latency - best_avg_latency) / current_avg_latency
            
            confidence = min(len(similar_snapshots) / 20.0, 1.0)  # åŸºäºæ ·æœ¬æ•°é‡
            
            return OptimizationRecommendation(
                parameter=param_name,
                current_value=current_value,
                recommended_value=recommended_value,
                confidence=confidence,
                expected_improvement=expected_improvement,
                reason=f"åŸºäº{len(similar_snapshots)}ä¸ªç›¸ä¼¼åœºæ™¯çš„åˆ†æ",
                strategy=strategy
            )
            
        except Exception as e:
            logger.error(f"å‚æ•°ä¼˜åŒ–å¤±è´¥ {param_name}: {e}")
            return None
    
    def _apply_strategy_adjustment(self, recommended_value: float, current_value: float,
                                 min_val: float, max_val: float, 
                                 strategy: OptimizationStrategy) -> float:
        """åº”ç”¨ç­–ç•¥è°ƒæ•´"""
        if strategy == OptimizationStrategy.CONSERVATIVE:
            # ä¿å®ˆç­–ç•¥ï¼šåªåšå°å¹…è°ƒæ•´
            max_change = abs(current_value) * 0.2
            change = recommended_value - current_value
            if abs(change) > max_change:
                change = max_change if change > 0 else -max_change
            return current_value + change
            
        elif strategy == OptimizationStrategy.AGGRESSIVE:
            # æ¿€è¿›ç­–ç•¥ï¼šç›´æ¥ä½¿ç”¨æ¨èå€¼
            return recommended_value
            
        elif strategy == OptimizationStrategy.BALANCED:
            # å¹³è¡¡ç­–ç•¥ï¼šå–ä¸­é—´å€¼
            return (current_value + recommended_value) / 2
            
        else:  # ADAPTIVE
            # è‡ªé€‚åº”ç­–ç•¥ï¼šåŸºäºç½®ä¿¡åº¦è°ƒæ•´
            confidence = min(len(self.performance_history) / 100.0, 1.0)
            return current_value + (recommended_value - current_value) * confidence
    
    def _get_default_recommendations(self, current_params: Dict[str, Any],
                                   strategy: OptimizationStrategy) -> List[OptimizationRecommendation]:
        """è·å–é»˜è®¤ä¼˜åŒ–å»ºè®®"""
        recommendations = []
        
        # åŸºäºç³»ç»ŸçŠ¶æ€çš„é»˜è®¤å»ºè®®
        cpu_count = psutil.cpu_count()
        memory_gb = psutil.virtual_memory().total / (1024**3)
        
        if current_params.get('thread_count', 1) < cpu_count // 2:
            recommendations.append(OptimizationRecommendation(
                parameter='thread_count',
                current_value=current_params.get('thread_count', 1),
                recommended_value=min(cpu_count // 2, 4),
                confidence=0.7,
                expected_improvement=0.2,
                reason="åŸºäºCPUæ ¸å¿ƒæ•°çš„é»˜è®¤ä¼˜åŒ–",
                strategy=strategy
            ))
        
        if memory_gb > 8 and current_params.get('cache_size', 1000) < 5000:
            recommendations.append(OptimizationRecommendation(
                parameter='cache_size',
                current_value=current_params.get('cache_size', 1000),
                recommended_value=5000,
                confidence=0.6,
                expected_improvement=0.15,
                reason="åŸºäºå†…å­˜å®¹é‡çš„ç¼“å­˜ä¼˜åŒ–",
                strategy=strategy
            ))
        
        return recommendations
    
    def apply_recommendations(self, operation_type: str, 
                            recommendations: List[OptimizationRecommendation]) -> Dict[str, Any]:
        """åº”ç”¨ä¼˜åŒ–å»ºè®®"""
        if operation_type not in self.optimization_params:
            self.optimization_params[operation_type] = dict(self.optimization_params['default'])
        
        applied_changes = {}
        
        for rec in recommendations:
            if rec.confidence >= 0.5:  # åªåº”ç”¨é«˜ç½®ä¿¡åº¦çš„å»ºè®®
                old_value = self.optimization_params[operation_type].get(rec.parameter)
                self.optimization_params[operation_type][rec.parameter] = rec.recommended_value
                applied_changes[rec.parameter] = {
                    'old_value': old_value,
                    'new_value': rec.recommended_value,
                    'expected_improvement': rec.expected_improvement
                }
                
                logger.info(f"âœ… åº”ç”¨ä¼˜åŒ–: {operation_type}.{rec.parameter} "
                          f"{old_value} -> {rec.recommended_value}")
        
        # è®°å½•ä¼˜åŒ–å†å²
        self.optimization_history.append({
            'timestamp': time.time(),
            'operation_type': operation_type,
            'changes': applied_changes,
            'recommendations': [asdict(rec) for rec in recommendations]
        })
        
        return applied_changes
    
    def get_current_params(self, operation_type: str) -> Dict[str, Any]:
        """è·å–å½“å‰ä¼˜åŒ–å‚æ•°"""
        return self.optimization_params.get(operation_type, self.optimization_params['default']).copy()
    
    def get_optimization_status(self) -> Dict[str, Any]:
        """è·å–ä¼˜åŒ–çŠ¶æ€"""
        return {
            "total_snapshots": len(self.performance_history),
            "trained_models": len(self.predictor.models),
            "optimization_operations": len(self.optimization_params),
            "optimization_history": len(self.optimization_history),
            "model_accuracy": {
                op_type: model.accuracy_score 
                for op_type, model in self.predictor.models.items()
            },
            "recent_optimizations": self.optimization_history[-5:] if self.optimization_history else []
        }

class AdaptivePerformanceManager:
    """è‡ªé€‚åº”æ€§èƒ½ç®¡ç†å™¨"""
    
    def __init__(self):
        self.optimizer = AdaptiveOptimizer()
        self.monitoring_active = False
        self.monitoring_thread: Optional[threading.Thread] = None
        self.performance_callbacks: List[Callable] = []
        
        # æ€§èƒ½é˜ˆå€¼
        self.performance_thresholds = {
            'latency_ms': 5000,      # 5ç§’
            'memory_mb': 1000,       # 1GB
            'cpu_percent': 80,       # 80%
            'error_rate': 0.05       # 5%
        }
        
        logger.info("âœ… è‡ªé€‚åº”æ€§èƒ½ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    
    def start_monitoring(self, interval_seconds: int = 60):
        """å¼€å§‹æ€§èƒ½ç›‘æ§"""
        if self.monitoring_active:
            return
        
        self.monitoring_active = True
        self.monitoring_thread = threading.Thread(
            target=self._monitoring_loop,
            args=(interval_seconds,),
            daemon=True
        )
        self.monitoring_thread.start()
        
        logger.info(f"âœ… æ€§èƒ½ç›‘æ§å·²å¯åŠ¨ (é—´éš”: {interval_seconds}ç§’)")
    
    def stop_monitoring(self):
        """åœæ­¢æ€§èƒ½ç›‘æ§"""
        self.monitoring_active = False
        if self.monitoring_thread:
            self.monitoring_thread.join(timeout=5)
        
        logger.info("æ€§èƒ½ç›‘æ§å·²åœæ­¢")
    
    def _monitoring_loop(self, interval_seconds: int):
        """ç›‘æ§å¾ªç¯"""
        while self.monitoring_active:
            try:
                self._check_system_performance()
                time.sleep(interval_seconds)
            except Exception as e:
                logger.error(f"æ€§èƒ½ç›‘æ§å‡ºé”™: {e}")
                time.sleep(5)
    
    def _check_system_performance(self):
        """æ£€æŸ¥ç³»ç»Ÿæ€§èƒ½"""
        # è·å–ç³»ç»ŸæŒ‡æ ‡
        cpu_percent = psutil.cpu_percent(interval=1)
        memory = psutil.virtual_memory()
        memory_mb = memory.used / (1024 * 1024)
        
        # æ£€æŸ¥æ˜¯å¦è¶…è¿‡é˜ˆå€¼
        alerts = []
        
        if cpu_percent > self.performance_thresholds['cpu_percent']:
            alerts.append(f"CPUä½¿ç”¨ç‡è¿‡é«˜: {cpu_percent:.1f}%")
        
        if memory_mb > self.performance_thresholds['memory_mb']:
            alerts.append(f"å†…å­˜ä½¿ç”¨è¿‡é«˜: {memory_mb:.1f}MB")
        
        if alerts:
            logger.warning(f"âš ï¸ æ€§èƒ½å‘Šè­¦: {'; '.join(alerts)}")
            
            # è§¦å‘è‡ªåŠ¨ä¼˜åŒ–
            self._trigger_auto_optimization()
    
    def _trigger_auto_optimization(self):
        """è§¦å‘è‡ªåŠ¨ä¼˜åŒ–"""
        try:
            # ä¸ºæ‰€æœ‰æ“ä½œç±»å‹ç”Ÿæˆä¼˜åŒ–å»ºè®®
            for operation_type in self.optimizer.optimization_params.keys():
                if operation_type == 'default':
                    continue
                
                # åˆ›å»ºå½“å‰æ€§èƒ½å¿«ç…§
                current_snapshot = PerformanceSnapshot(
                    timestamp=time.time(),
                    operation_type=operation_type,
                    operation_id="auto_optimization",
                    latency_ms=0,
                    memory_mb=psutil.virtual_memory().used / (1024 * 1024),
                    cpu_percent=psutil.cpu_percent(),
                    throughput_ops_sec=0,
                    error_occurred=False,
                    cache_hit=False,
                    input_size=0
                )
                
                # ç”Ÿæˆä¼˜åŒ–å»ºè®®
                recommendations = self.optimizer.optimize_parameters(
                    operation_type, current_snapshot, OptimizationStrategy.CONSERVATIVE
                )
                
                if recommendations:
                    # åº”ç”¨é«˜ç½®ä¿¡åº¦çš„å»ºè®®
                    high_confidence_recs = [r for r in recommendations if r.confidence >= 0.7]
                    if high_confidence_recs:
                        self.optimizer.apply_recommendations(operation_type, high_confidence_recs)
                        logger.info(f"âœ… è‡ªåŠ¨ä¼˜åŒ–å·²åº”ç”¨: {operation_type}")
                        
        except Exception as e:
            logger.error(f"è‡ªåŠ¨ä¼˜åŒ–å¤±è´¥: {e}")
    
    def record_operation_performance(self, operation_type: str, operation_id: str,
                                   latency_ms: float, memory_mb: float = None,
                                   error_occurred: bool = False, cache_hit: bool = False,
                                   input_size: int = 0, context: Dict[str, Any] = None):
        """è®°å½•æ“ä½œæ€§èƒ½"""
        snapshot = PerformanceSnapshot(
            timestamp=time.time(),
            operation_type=operation_type,
            operation_id=operation_id,
            latency_ms=latency_ms,
            memory_mb=memory_mb or psutil.Process().memory_info().rss / (1024 * 1024),
            cpu_percent=psutil.cpu_percent(),
            throughput_ops_sec=1000 / latency_ms if latency_ms > 0 else 0,
            error_occurred=error_occurred,
            cache_hit=cache_hit,
            input_size=input_size,
            optimization_params=self.optimizer.get_current_params(operation_type),
            context=context or {}
        )
        
        self.optimizer.record_performance(snapshot)
        
        # é€šçŸ¥å›è°ƒå‡½æ•°
        for callback in self.performance_callbacks:
            try:
                callback(snapshot)
            except Exception as e:
                logger.error(f"æ€§èƒ½å›è°ƒå¤±è´¥: {e}")
    
    def optimize_operation(self, operation_type: str, 
                          strategy: OptimizationStrategy = OptimizationStrategy.ADAPTIVE) -> List[OptimizationRecommendation]:
        """ä¼˜åŒ–ç‰¹å®šæ“ä½œ"""
        # è·å–æœ€è¿‘çš„æ€§èƒ½å¿«ç…§
        recent_snapshots = [
            s for s in self.optimizer.performance_history 
            if s.operation_type == operation_type
        ]
        
        if not recent_snapshots:
            logger.warning(f"æ²¡æœ‰æ‰¾åˆ°æ“ä½œçš„æ€§èƒ½æ•°æ®: {operation_type}")
            return []
        
        # ä½¿ç”¨æœ€è¿‘çš„å¿«ç…§ä½œä¸ºå½“å‰æ€§èƒ½åŸºå‡†
        current_snapshot = recent_snapshots[-1]
        
        # ç”Ÿæˆä¼˜åŒ–å»ºè®®
        recommendations = self.optimizer.optimize_parameters(
            operation_type, current_snapshot, strategy
        )
        
        logger.info(f"âœ… ç”Ÿæˆäº†{len(recommendations)}ä¸ªä¼˜åŒ–å»ºè®®: {operation_type}")
        
        return recommendations
    
    def apply_optimization(self, operation_type: str, 
                         recommendations: List[OptimizationRecommendation]) -> Dict[str, Any]:
        """åº”ç”¨ä¼˜åŒ–å»ºè®®"""
        return self.optimizer.apply_recommendations(operation_type, recommendations)
    
    def get_performance_summary(self, operation_type: Optional[str] = None) -> Dict[str, Any]:
        """è·å–æ€§èƒ½æ‘˜è¦"""
        snapshots = list(self.optimizer.performance_history)
        
        if operation_type:
            snapshots = [s for s in snapshots if s.operation_type == operation_type]
        
        if not snapshots:
            return {"message": "æ²¡æœ‰æ€§èƒ½æ•°æ®"}
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        latencies = [s.latency_ms for s in snapshots]
        memory_usage = [s.memory_mb for s in snapshots]
        error_rate = sum(1 for s in snapshots if s.error_occurred) / len(snapshots)
        cache_hit_rate = sum(1 for s in snapshots if s.cache_hit) / len(snapshots)
        
        return {
            "total_operations": len(snapshots),
            "avg_latency_ms": np.mean(latencies),
            "p95_latency_ms": np.percentile(latencies, 95),
            "avg_memory_mb": np.mean(memory_usage),
            "error_rate": error_rate,
            "cache_hit_rate": cache_hit_rate,
            "optimization_status": self.optimizer.get_optimization_status(),
            "monitoring_active": self.monitoring_active
        }
    
    def add_performance_callback(self, callback: Callable[[PerformanceSnapshot], None]):
        """æ·»åŠ æ€§èƒ½å›è°ƒ"""
        self.performance_callbacks.append(callback)
    
    def shutdown(self):
        """å…³é—­æ€§èƒ½ç®¡ç†å™¨"""
        self.stop_monitoring()
        logger.info("âœ… è‡ªé€‚åº”æ€§èƒ½ç®¡ç†å™¨å·²å…³é—­")

# å…¨å±€å®ä¾‹
adaptive_performance_manager = AdaptivePerformanceManager()

def get_adaptive_performance_manager() -> AdaptivePerformanceManager:
    """è·å–è‡ªé€‚åº”æ€§èƒ½ç®¡ç†å™¨å®ä¾‹"""
    return adaptive_performance_manager

def record_performance(operation_type: str, operation_id: str, latency_ms: float, **kwargs):
    """è®°å½•æ€§èƒ½ï¼ˆä¾¿æ·æ–¹æ³•ï¼‰"""
    adaptive_performance_manager.record_operation_performance(
        operation_type, operation_id, latency_ms, **kwargs
    )

def optimize_performance(operation_type: str, strategy: OptimizationStrategy = OptimizationStrategy.ADAPTIVE):
    """ä¼˜åŒ–æ€§èƒ½ï¼ˆä¾¿æ·æ–¹æ³•ï¼‰"""
    recommendations = adaptive_performance_manager.optimize_operation(operation_type, strategy)
    if recommendations:
        adaptive_performance_manager.apply_optimization(operation_type, recommendations)
    return recommendations

# æµ‹è¯•å‡½æ•°
def test_adaptive_performance():
    """æµ‹è¯•è‡ªé€‚åº”æ€§èƒ½ä¼˜åŒ–"""
    print("ğŸ§ª æµ‹è¯•è‡ªé€‚åº”æ€§èƒ½ä¼˜åŒ–...")
    
    manager = get_adaptive_performance_manager()
    
    # æ¨¡æ‹Ÿä¸€äº›æ€§èƒ½æ•°æ®
    for i in range(20):
        manager.record_operation_performance(
            operation_type="text2sql",
            operation_id=f"query_{i}",
            latency_ms=1000 + np.random.normal(0, 200),
            input_size=100 + i * 10,
            cache_hit=i % 3 == 0
        )
    
    # ç”Ÿæˆä¼˜åŒ–å»ºè®®
    recommendations = manager.optimize_operation("text2sql")
    print(f"âœ… ç”Ÿæˆäº†{len(recommendations)}ä¸ªä¼˜åŒ–å»ºè®®")
    
    for rec in recommendations:
        print(f"   {rec.parameter}: {rec.current_value} -> {rec.recommended_value} "
              f"(ç½®ä¿¡åº¦: {rec.confidence:.2f})")
    
    # åº”ç”¨ä¼˜åŒ–
    if recommendations:
        changes = manager.apply_optimization("text2sql", recommendations)
        print(f"âœ… åº”ç”¨äº†{len(changes)}ä¸ªä¼˜åŒ–å‚æ•°")
    
    # è·å–æ€§èƒ½æ‘˜è¦
    summary = manager.get_performance_summary("text2sql")
    print(f"âœ… æ€§èƒ½æ‘˜è¦: å¹³å‡å»¶è¿Ÿ {summary['avg_latency_ms']:.1f}ms")
    
    print("ğŸ‰ è‡ªé€‚åº”æ€§èƒ½ä¼˜åŒ–æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    test_adaptive_performance()